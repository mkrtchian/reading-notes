<!DOCTYPE html><html><head><meta charSet="utf-8"/><title>Designing Cloud Data Platforms – Reading notes</title><meta name="robots" content="index,follow"/><meta name="description" content="My detailed reading notes from computer science books"/><meta property="og:title" content="Designing Cloud Data Platforms – Reading notes"/><meta property="og:description" content="My detailed reading notes from computer science books"/><meta name="theme-color" content="#111" media="(prefers-color-scheme: dark)"/><meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover"/><style>
        :root {
          --nextra-primary-hue: 212deg;
          --nextra-primary-saturation: 100%;
          --nextra-navbar-height: 4rem;
          --nextra-menu-height: 3.75rem;
          --nextra-banner-height: 2.5rem;
        }
        
        .dark {
          --nextra-primary-hue: 204deg;
          --nextra-primary-saturation: 100%;
        }
      </style><meta name="msapplication-TileColor" content="#fff"/><meta http-equiv="Content-Language" content="en"/><meta name="description" content="My detailed reading notes from computer science books"/><meta property="og:title" content="Reading notes"/><meta property="og:description" content="My detailed reading notes from computer science books"/><meta name="apple-mobile-web-app-title" content="Reading notes"/><link rel="icon" type="image/x-icon" href="/reading-notes/favicon.ico"/><meta name="next-head-count" content="16"/><link rel="preload" href="/reading-notes/_next/static/css/e0ae992ef9be83da.css" as="style"/><link rel="stylesheet" href="/reading-notes/_next/static/css/e0ae992ef9be83da.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/reading-notes/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/reading-notes/_next/static/chunks/webpack-94b934e1f7075309.js" defer=""></script><script src="/reading-notes/_next/static/chunks/framework-ecc4130bc7a58a64.js" defer=""></script><script src="/reading-notes/_next/static/chunks/main-5d8dfd14beabedbc.js" defer=""></script><script src="/reading-notes/_next/static/chunks/pages/_app-d4e3c889b48849eb.js" defer=""></script><script src="/reading-notes/_next/static/chunks/673-c9f6925171f8c938.js" defer=""></script><script src="/reading-notes/_next/static/chunks/pages/books/designing-cloud-data-platforms-0025060d640c6646.js" defer=""></script><script src="/reading-notes/_next/static/DrK92t89GlVCRkv-RQVRz/_buildManifest.js" defer=""></script><script src="/reading-notes/_next/static/DrK92t89GlVCRkv-RQVRz/_ssgManifest.js" defer=""></script></head><body><div id="__next"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div dir="ltr"><script>document.documentElement.setAttribute('dir','ltr')</script><div class="nextra-nav-container nx-sticky nx-top-0 nx-z-20 nx-w-full nx-bg-transparent print:nx-hidden"><div class="nextra-nav-container-blur nx-pointer-events-none nx-absolute nx-z-[-1] nx-h-full nx-w-full nx-bg-white dark:nx-bg-dark nx-shadow-[0_2px_4px_rgba(0,0,0,.02),0_1px_0_rgba(0,0,0,.06)] dark:nx-shadow-[0_-1px_0_rgba(255,255,255,.1)_inset] contrast-more:nx-shadow-[0_0_0_1px_#000] contrast-more:dark:nx-shadow-[0_0_0_1px_#fff]"></div><nav class="nx-mx-auto nx-flex nx-h-[var(--nextra-navbar-height)] nx-max-w-[90rem] nx-items-center nx-justify-end nx-gap-2 nx-pl-[max(env(safe-area-inset-left),1.5rem)] nx-pr-[max(env(safe-area-inset-right),1.5rem)]"><a class="nx-flex nx-items-center hover:nx-opacity-75 ltr:nx-mr-auto rtl:nx-ml-auto" href="/reading-notes/"><img alt="Reading notes homepage" loading="lazy" width="30" height="30" decoding="async" data-nimg="1" style="color:transparent" src="/reading-notes/logo.png"/></a><div class="nextra-search nx-relative md:nx-w-64 nx-hidden md:nx-inline-block mx-min-w-[200px]"><div class="nx-relative nx-flex nx-items-center nx-text-gray-900 contrast-more:nx-text-gray-800 dark:nx-text-gray-300 contrast-more:dark:nx-text-gray-300"><input spellcheck="false" class="nx-block nx-w-full nx-appearance-none nx-rounded-lg nx-px-3 nx-py-2 nx-transition-colors nx-text-base nx-leading-tight md:nx-text-sm nx-bg-black/[.05] dark:nx-bg-gray-50/10 focus:nx-bg-white dark:focus:nx-bg-dark placeholder:nx-text-gray-500 dark:placeholder:nx-text-gray-400 contrast-more:nx-border contrast-more:nx-border-current" type="search" placeholder="Search documentation…" value=""/></div></div><a href="https://github.com/mkrtchian/reading-notes" target="_blank" rel="noreferrer" class="nx-p-2 nx-text-current"><svg width="24" height="24" fill="currentColor" viewBox="3 3 18 18"><title>GitHub</title><path d="M12 3C7.0275 3 3 7.12937 3 12.2276C3 16.3109 5.57625 19.7597 9.15374 20.9824C9.60374 21.0631 9.77249 20.7863 9.77249 20.5441C9.77249 20.3249 9.76125 19.5982 9.76125 18.8254C7.5 19.2522 6.915 18.2602 6.735 17.7412C6.63375 17.4759 6.19499 16.6569 5.8125 16.4378C5.4975 16.2647 5.0475 15.838 5.80124 15.8264C6.51 15.8149 7.01625 16.4954 7.18499 16.7723C7.99499 18.1679 9.28875 17.7758 9.80625 17.5335C9.885 16.9337 10.1212 16.53 10.38 16.2993C8.3775 16.0687 6.285 15.2728 6.285 11.7432C6.285 10.7397 6.63375 9.9092 7.20749 9.26326C7.1175 9.03257 6.8025 8.08674 7.2975 6.81794C7.2975 6.81794 8.05125 6.57571 9.77249 7.76377C10.4925 7.55615 11.2575 7.45234 12.0225 7.45234C12.7875 7.45234 13.5525 7.55615 14.2725 7.76377C15.9937 6.56418 16.7475 6.81794 16.7475 6.81794C17.2424 8.08674 16.9275 9.03257 16.8375 9.26326C17.4113 9.9092 17.76 10.7281 17.76 11.7432C17.76 15.2843 15.6563 16.0687 13.6537 16.2993C13.98 16.5877 14.2613 17.1414 14.2613 18.0065C14.2613 19.2407 14.25 20.2326 14.25 20.5441C14.25 20.7863 14.4188 21.0746 14.8688 20.9824C16.6554 20.364 18.2079 19.1866 19.3078 17.6162C20.4077 16.0457 20.9995 14.1611 21 12.2276C21 7.12937 16.9725 3 12 3Z"></path></svg><span class="nx-sr-only">GitHub</span><span class="nx-sr-only nx-select-none"> (opens in a new tab)</span></a><button type="button" aria-label="Menu" class="nextra-hamburger -nx-mr-2 nx-rounded nx-p-2 active:nx-bg-gray-400/20 md:nx-hidden"><svg fill="none" width="24" height="24" viewBox="0 0 24 24" stroke="currentColor" class=""><g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16"></path></g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 12h16"></path><g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 18h16"></path></g></svg></button></nav></div><div class="nx-mx-auto nx-flex nx-max-w-[90rem]"><div class="motion-reduce:nx-transition-none [transition:background-color_1.5s_ease] nx-bg-transparent"></div><aside class="nextra-sidebar-container nx-flex nx-flex-col md:nx-top-16 md:nx-shrink-0 motion-reduce:nx-transform-none nx-transform-gpu nx-transition-all nx-ease-in-out print:nx-hidden md:nx-w-64 md:nx-sticky md:nx-self-start max-md:[transform:translate3d(0,-100%,0)]"><div class="nx-px-4 nx-pt-4 md:nx-hidden"><div class="nextra-search nx-relative md:nx-w-64"><div class="nx-relative nx-flex nx-items-center nx-text-gray-900 contrast-more:nx-text-gray-800 dark:nx-text-gray-300 contrast-more:dark:nx-text-gray-300"><input spellcheck="false" class="nx-block nx-w-full nx-appearance-none nx-rounded-lg nx-px-3 nx-py-2 nx-transition-colors nx-text-base nx-leading-tight md:nx-text-sm nx-bg-black/[.05] dark:nx-bg-gray-50/10 focus:nx-bg-white dark:focus:nx-bg-dark placeholder:nx-text-gray-500 dark:placeholder:nx-text-gray-400 contrast-more:nx-border contrast-more:nx-border-current" type="search" placeholder="Search documentation…" value=""/></div></div></div><div class="nx-overflow-y-auto nx-overflow-x-hidden nx-p-4 nx-grow md:nx-h-[calc(100vh-var(--nextra-navbar-height)-var(--nextra-menu-height))] nextra-scrollbar"><div class="nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none"><div class="nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100"><ul class="nx-flex nx-flex-col nx-gap-1 nextra-menu-desktop max-md:nx-hidden"><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/">Introduction</a></li><li class="open"><button class="nx-items-center nx-justify-between nx-gap-2 nx-text-left nx-w-full nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50">Reading notes<svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="nx-h-[18px] nx-min-w-[18px] nx-rounded-sm nx-p-0.5 hover:nx-bg-gray-800/5 dark:hover:nx-bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="nx-origin-center nx-transition-transform rtl:-nx-rotate-180 ltr:nx-rotate-90 rtl:nx-rotate-[-270deg]"></path></svg></button><div class="nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none"><div class="nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100 ltr:nx-pr-0 rtl:nx-pl-0 nx-pt-1"><ul class="nx-flex nx-flex-col nx-gap-1 nx-relative before:nx-absolute before:nx-inset-y-1 before:nx-w-px before:nx-bg-gray-200 before:nx-content-[&quot;&quot;] dark:before:nx-bg-neutral-800 ltr:nx-pl-3 ltr:before:nx-left-0 rtl:nx-pr-3 rtl:before:nx-right-0 ltr:nx-ml-3 rtl:nx-mr-3"><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/accelerate/">Accelerate</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/continuous-discovery-habits/">Continuous Discovery Habits</a></li><li class="nx-flex nx-flex-col nx-gap-1 active"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-bg-primary-100 nx-font-semibold nx-text-primary-800 dark:nx-bg-primary-400/10 dark:nx-text-primary-600 contrast-more:nx-border-primary-500 contrast-more:dark:nx-border-primary-500" href="/reading-notes/books/designing-cloud-data-platforms/">Designing Cloud Data Platforms</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/designing-data-intensive-applications/">Designing Data-Intensive Applications</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/effective-kafka/">Effective Kafka</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/effective-typescript/">Effective TypeScript</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/get-your-hands-dirty-on-clean-architecture/">Get Your Hands Dirty on Clean Architecture</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/learning-domain-driven-design/">Learning Domain-Driven Design</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/learning-to-scale/">Learning to Scale</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/monolith-to-microservices/">Monolith to Microservices</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/no-rules-rules/">No Rules Rules</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/outcomes-over-output/">Outcomes Over Output</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/refactoring/">Refactoring: Improving the Design of Existing Code</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/reinventing-organizations/">Reinventing Organizations</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/team-topologies/">Team Topologies</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/technical-agile-coaching-samman-method/">Technical Agile Coaching with the Samman Method</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/test-driven-development-by-example/">Test-Driven Development: By Example</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/the-design-of-web-apis/">The Design of Web APIs</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/the-five-dysfunctions-of-a-team/">The Five Dysfunctions of a Team</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/turn-the-ship-around/">Turn the Ship Around!</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/unit-testing/">Unit Testing: Principles, Practices, and Patterns</a></li></ul></div></div></li></ul></div></div></div><div class="nx-sticky nx-bottom-0 nx-bg-white dark:nx-bg-dark nx-mx-4 nx-py-4 nx-shadow-[0_-12px_16px_#fff] nx-flex nx-items-center nx-gap-2 dark:nx-border-neutral-800 dark:nx-shadow-[0_-12px_16px_#111] contrast-more:nx-border-neutral-400 contrast-more:nx-shadow-none contrast-more:dark:nx-shadow-none nx-border-t" data-toggle-animation="off"><div class="nx-grow nx-flex nx-flex-col"><button title="Change theme" class="nx-h-7 nx-rounded-md nx-px-2 nx-text-left nx-text-xs nx-font-medium nx-text-gray-600 nx-transition-colors dark:nx-text-gray-400 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50" id="headlessui-listbox-button-:Rlsr6:" type="button" aria-haspopup="listbox" aria-expanded="false" data-headlessui-state=""><div class="nx-flex nx-items-center nx-gap-2 nx-capitalize"><svg fill="none" viewBox="3 3 18 18" width="12" height="12" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" fill="currentColor" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"></path></svg><span class="">Light</span></div></button></div></div></aside><nav class="nextra-toc nx-order-last nx-hidden nx-w-64 nx-shrink-0 xl:nx-block print:nx-hidden nx-px-4" aria-label="table of contents"><div class="nextra-scrollbar nx-sticky nx-top-16 nx-overflow-y-auto nx-pr-4 nx-pt-6 nx-text-sm [hyphens:auto] nx-max-h-[calc(100vh-var(--nextra-navbar-height)-env(safe-area-inset-bottom))] ltr:-nx-mr-4 rtl:-nx-ml-4"><p class="nx-mb-4 nx-font-semibold nx-tracking-tight">On This Page</p><ul><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#1---introducing-the-data-platform" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">1 - Introducing the data platform</a></li><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#2---why-a-data-platform-and-not-just-a-data-warehouse" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">2 - Why a data platform and not just a data warehouse</a></li><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#3---getting-bigger-and-leveraging-the-big-3-amazon-microsoft-and-google" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">3 - Getting bigger and leveraging the Big 3: Amazon, Microsoft, and Google</a></li><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#4---getting-data-into-the-platform" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">4 - Getting data into the platform</a></li><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#5---organizing-and-processing-data" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">5 - Organizing and processing data</a></li><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#6---real-time-data-processing-and-analytics" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">6 - Real-time data processing and analytics</a></li><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#7---metadata-layer-architecture" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">7 - Metadata layer architecture</a></li><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#8---schema-management" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">8 - Schema management</a></li><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#9---data-access-and-security" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">9 - Data access and security</a></li><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#10---fueling-business-value-with-data-platforms" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">10 - Fueling business value with data platforms</a></li></ul><div class="nx-mt-8 nx-border-t nx-bg-white nx-pt-8 nx-shadow-[0_-12px_16px_white] dark:nx-bg-dark dark:nx-shadow-[0_-12px_16px_#111] nx-sticky nx-bottom-0 nx-flex nx-flex-col nx-items-start nx-gap-2 nx-pb-8 dark:nx-border-neutral-800 contrast-more:nx-border-t contrast-more:nx-border-neutral-400 contrast-more:nx-shadow-none contrast-more:dark:nx-border-neutral-400"><a href="https://github.com/mkrtchian/reading-notes/issues/new?title=Feedback%20for%20%E2%80%9CDesigning%20Cloud%20Data%20Platforms%E2%80%9D&amp;labels=feedback" target="_blank" rel="noreferrer" class="nx-text-xs nx-font-medium nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-100 contrast-more:nx-text-gray-800 contrast-more:dark:nx-text-gray-50">Question? Give me feedback →<span class="nx-sr-only nx-select-none"> (opens in a new tab)</span></a><a class="nx-text-xs nx-font-medium nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-100 contrast-more:nx-text-gray-800 contrast-more:dark:nx-text-gray-50" href="https://github.com/mkrtchian/reading-notes/blob/main/pages/books/designing-cloud-data-platforms.mdx">Edit this page</a></div></div></nav><div id="reach-skip-nav"></div><article class="nx-w-full nx-break-words nextra-content nx-flex nx-min-h-[calc(100vh-var(--nextra-navbar-height))] nx-min-w-0 nx-justify-center nx-pb-8 nx-pr-[calc(env(safe-area-inset-right)-1.5rem)]"><main class="nx-w-full nx-min-w-0 nx-max-w-6xl nx-px-6 nx-pt-4 md:nx-px-12"><div class="nextra-breadcrumb nx-mt-1.5 nx-flex nx-items-center nx-gap-1 nx-overflow-hidden nx-text-sm nx-text-gray-500 dark:nx-text-gray-400 contrast-more:nx-text-current"><div class="nx-whitespace-nowrap nx-transition-colors nx-min-w-[24px] nx-overflow-hidden nx-text-ellipsis" title="Reading notes">Reading notes</div><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="nx-w-3.5 nx-shrink-0"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg><div class="nx-whitespace-nowrap nx-transition-colors nx-font-medium nx-text-gray-700 contrast-more:nx-font-bold contrast-more:nx-text-current dark:nx-text-gray-100 contrast-more:dark:nx-text-current" title="Designing Cloud Data Platforms">Designing Cloud Data Platforms</div></div><h1 class="nx-mt-2 nx-text-4xl nx-font-bold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100">Designing Cloud Data Platforms</h1>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">1 - Introducing the data platform<a href="#1---introducing-the-data-platform" id="1---introducing-the-data-platform" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les <strong>analytics</strong> permettent essentiellement d&#x27;obtenir des métriques pour faire des choix business.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Avant l&#x27;avènement des ordinateurs, les entreprises utilisaient des moyens manuels, et leur intuition.</li>
<li class="nx-my-2">Dans les années 80 on a vu émerger le concept de <em>data warehouse</em>, qui est une base centralisée de données venant de diverses sources.</li>
</ul>
</li>
<li class="nx-my-2">Les <strong>data warehouses</strong> posent de plus en plus de <strong>problèmes</strong> de nos jours.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les tendances suivantes y contribuent :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les données sont issues de sources de diverses nature, y compris certaines d&#x27;entre-elles non structurées, et leur volume est de plus en plus important.</li>
<li class="nx-my-2">Le découpage des applications en microservices fait que collecter des données revient forcément à devoir agréger de multiples sources.</li>
<li class="nx-my-2">Les data scientists ont aussi besoin d&#x27;accéder à une version brute de la donnée, et cet usage ne peut pas passer par un <em>data warehouse</em>.</li>
</ul>
</li>
<li class="nx-my-2">Elles ont du mal avec les <strong>3V</strong> (Variety, Volume, Velocity).<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Variety</strong> : les <em>data warehouses</em> ne supportent que les <em>structured data</em> dont le schéma est stable, c&#x27;est-à-dire en pratique qui sont issues de DB relationnelles.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Or avec l&#x27;avènement des SaaS, des réseaux sociaux, et de l&#x27;IoT, on se retrouve avec :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Des <em>semistructured data</em> du type JSON, Avro etc, dont le schéma varie souvent.</li>
<li class="nx-my-2">Des <em>unstructured data</em> comme le binaire, le son, la vidéo.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>Volume</strong> : le fait que dans un <em>data warehouse</em>, la puissance de calcul et le stockage doivent se trouver sur <strong>la même machine physique</strong>, implique qu&#x27;on ne peut pas scaler les deux séparément, et donc les coûts explosent.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Même les petites organisations peuvent être amenées à traiter plusieurs TB de données.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Velocity</strong> : les <em>data warehouses</em> ne sont pas adaptées aux analytics en mode real time, elles sont plus orientées batch processing.</li>
<li class="nx-my-2">Le machine learning en particulier pose tous les problèmes en même temps : il nécessite une grande quantité de données variées, et accapare la puissance de calcul du <em>data warehouse</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Les <strong>data lakes</strong> répondent en partie à ces problèmes.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L&#x27;idée principale des <em>data lakes</em> c&#x27;est qu&#x27;on <strong>stocke de la donnée telle quelle</strong> (ou quasi), et qu&#x27;on essayera de la traiter et de lui coller un schéma dès qu&#x27;on en aura besoin.</li>
<li class="nx-my-2">Les <em>data lakes</em> se sont généralisés à partir de 2006 avec l&#x27;arrivée de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Hadoop</em>, qui est un <strong>filesystem distribué sur plusieurs machines</strong> pas chères.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Hadoop répond en partie aux 3V :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">A la <em>Variety</em> par l&#x27;écriture schema-less.</li>
<li class="nx-my-2">Au <em>Volume</em> par le fait que ce soit distribué sur des machines pas chères.</li>
<li class="nx-my-2">A la <em>Velocity</em> par la facilité de streaming à partir du filesystem distribué.</li>
</ul>
</li>
<li class="nx-my-2">Mais il a aussi des problèmes :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">C&#x27;est un système complexe qu&#x27;il faut installer sur un datacenter et gérer par des Ops expérimentés.</li>
<li class="nx-my-2">D&#x27;un point de vue business, c&#x27;est plus difficile de travailler avec les outils qui traitent les données non structurées qu&#x27;avec du SQL comme dans un <em>data warehouse</em>.</li>
<li class="nx-my-2">Bien qu&#x27;il soit distribué sur de petites machines pas chères, le computing et le stockage ne sont pas séparés, ce qui limite quand même la réduction de coût quand on a besoin de beaucoup de l&#x27;un sans l&#x27;autre.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Le <strong>cloud public</strong> vient répondre aux problèmes de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Hadoop</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les <em>data warehouses</em> et les <em>data lakes</em> ont été proposés par les cloud providers, avec de nombreux avantages :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La possibilité de scaler la puissance de calcul et le stockage séparément.</li>
<li class="nx-my-2">Payer uniquement à l&#x27;usage des machines qu&#x27;on emprunte.</li>
<li class="nx-my-2">Ne plus avoir à gérer la complexité de l&#x27;infrastructure.</li>
<li class="nx-my-2">Des outils et frameworks avancés développés par les cloud providers autour de leurs produits.</li>
</ul>
</li>
<li class="nx-my-2">Exemple : <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS EMR</em> permet de lancer un cluster sur lequel on va pouvoir exécuter des jobs <em style="color:#3d85c6;font-weight:bold;font-style:normal">Hadoop</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>,<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On a juste à indiquer le nombre de nœuds qu&#x27;on veut, et les packages qu&#x27;on veut installer dessus.</li>
<li class="nx-my-2">Et on a la possibilité de faire des allers-retours vers <em style="color:#3d85c6;font-weight:bold;font-style:normal">S3</em> pour scaler différemment le calcul et le stockage.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">La <strong>cloud data platform</strong> moderne utilise à la fois le <em>data warehouse</em> et le <em>data lake</em>, hébergés dans un cloud public, chacun d&#x27;entre eux remplissant un usage particulier.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Pour être polyvalente et pas chère, la data platform doit avoir des <strong>4 composants principaux faiblement couplés</strong>, interagissant entre-eux avec une API bien définie.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Ingestion layer</strong> : on va chercher les données chez les différents types de sources (DB relationnelle, DB NoSQL, API externes etc.).<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On va en général utiliser un ensemble d&#x27;outils open source ou commerciaux pour chaque type de données à aller chercher.</li>
<li class="nx-my-2">Il ne faut <strong>surtout pas altérer la donnée à cette étape</strong>, pour que la donnée brute soit disponible pour les data scientists qui en auraient l&#x27;usage.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Storage layer</strong> : on utilise le stockage cloud comme stockage de notre <em>data lake</em>, dans lequel on met ce qu&#x27;on a ingéré.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le stockage cloud a l&#x27;avantage de ne pas avoir besoin de planifier la capacité de stockage : il grossit automatiquement au besoin.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Processing layer</strong> : on transforme la donnée pour la rendre utilisable par la plupart des clients de la plateforme.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">C&#x27;est la partie calcul de notre <em>data lake</em>, il va lire depuis le cloud storage puis écrire à nouveau dedans.</li>
<li class="nx-my-2">Dans le cas du <strong>streaming</strong>, on ne passe pas par le storage layer qui prend trop de temps, mais on envoie la donnée <strong>directement au processing layer</strong>, qui va ensuite la rendre disponible au layer d&#x27;après.</li>
<li class="nx-my-2">Le processing est généralement fait avec des outils open source, les plus connus étant <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Beam</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Flink</em>.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Serving layer</strong> : on rend la donnée disponible sous divers formats, selon les besoins des clients de la plateforme.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les usages peuvent être :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Des analystes qui ont besoin d&#x27;exécuter des requêtes SQL sur la donnée.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut charger la donnée dans un <em>data warehouse</em> chez le cloud provider.</li>
</ul>
</li>
<li class="nx-my-2">Des applications qui ont besoin d&#x27;un accès rapide à la donnée.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut la charger dans une key / value DB, ou une document DB.</li>
</ul>
</li>
<li class="nx-my-2">Des équipes de data scientists / engineers ont besoin de transformer la donnée eux-mêmes.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut leur donner accès au storage du <em>data lake</em>, et les laisser utiliser <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Beam</em> ou <em style="color:#3d85c6;font-weight:bold;font-style:normal">Flink</em>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">La cloud data platform répond aux 3V :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L&#x27;ingestion layer couplé au stockage sans schéma permet une grande <em>Variety</em> des données.</li>
<li class="nx-my-2">La séparation calcul / stockage et le fait de ne payer que ce qu&#x27;on utilise permet d&#x27;optimiser les coûts, et d&#x27;avoir un gros <em>Volume</em>.</li>
<li class="nx-my-2">La possibilité d&#x27;envoyer directement au <em>processing layer</em> permet de la <em>Velocity</em>.</li>
<li class="nx-my-2">On peut aussi prendre en compte deux autres V :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La <em>Veracity</em> qui indique le niveau de <em>data governance</em>, c&#x27;est-à-dire la qualité de la donnée. On l&#x27;obtient itérativement, au cours d&#x27;étapes au sein du <em>data lake</em>.</li>
<li class="nx-my-2">Et la <em>Value</em> qu&#x27;on peut tirer de la donnée, qui peut être plus élevée si on prend plus de données en amont de notre processus de nettoyage.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Il faut comprendre les <strong>cas d&#x27;usages principaux</strong> d&#x27;un <em>data lake</em>, pour éviter de le transformer en <em>data swamp</em>. Parmi les plus courants il y a :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La <strong>vue 360° des clients</strong>, où il s&#x27;agit de récupérer toutes les données d&#x27;interaction avec eux, pour proposer ensuite des services plus personnalisés, vendre plus etc.</li>
<li class="nx-my-2">Les <strong>données venant d&#x27;IoT</strong>, qui ont la particularité d&#x27;être incertaines et d&#x27;avoir un gros volume, ce qui rend l&#x27;utilisation du <em>data warehouse</em> peu intéressante.</li>
<li class="nx-my-2">Le <strong>machine learning</strong> qui a besoin d&#x27;une très grande quantité de données, et qui tire avantage de puissance de calcul séparée des autres use-cases grâce au <em>data lake</em>.</li>
</ul>
</li>
</ul>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">2 - Why a data platform and not just a data warehouse<a href="#2---why-a-data-platform-and-not-just-a-data-warehouse" id="2---why-a-data-platform-and-not-just-a-data-warehouse" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ce chapitre donne des <strong>arguments pour le choix d&#x27;une <em>cloud data platform</em>, plutôt qu&#x27;une simple <em>data warehouse</em></strong>.</li>
<li class="nx-my-2">On implémente les deux solutions pour une situation d&#x27;<strong>exemple</strong> qu&#x27;on va utiliser dans ce chapitre :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Nous sommes l&#x27;équipe data, et le département marketing a besoin que nous récupérions deux sources de données et qu&#x27;on les corrèle régulièrement.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L&#x27;une des sources est une table de campagnes de marketing, issue d&#x27;une DB <em style="color:#3d85c6;font-weight:bold;font-style:normal">MySQL</em> interne.</li>
<li class="nx-my-2">Et l&#x27;autre est constituée de fichiers CSV de clics utilisateurs, issus de logs applicatifs (et donc <em>semistructured</em>).</li>
</ul>
</li>
<li class="nx-my-2">On part sur Microsoft Azure pour les deux solutions.</li>
<li class="nx-my-2">Concernant l&#x27;implémentation <em>data warehouse only</em> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - On va utiliser deux <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Data Factory</em> pour récupérer la donnée dans le serveur de DB et les fichiers CSV dans le serveur SFTP. C&#x27;est notre <em>ingest layer</em>.</li>
<li class="nx-my-2">2 - Ensuite on redirige ça vers l&#x27;<em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Synapse</em>, qui est la <em>data warehouse</em> de chez Azure. Elle va faire office de <em>store layer</em>, <em>process layer</em> et <em>serve layer</em>.</li>
</ul>
</li>
<li class="nx-my-2">Concernant l&#x27;implémentation <em>cloud data platform</em> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - On a notre <em>ingest layer</em> avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Data Factory</em>, qui redirige les données vers le <em>store layer</em>.</li>
<li class="nx-my-2">2 - Le <em>store layer</em> est implémenté avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Blob Storage</em>. Il s&#x27;agit d&#x27;un stockage de type <em>data lake</em>.</li>
<li class="nx-my-2">3 - On a un <em>process layer</em> qui utilise <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Databricks</em>, et qui fait tourner <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>.</li>
<li class="nx-my-2">4 - Le <em>serve layer</em> enfin utilise <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Synapse</em> qui est le <em>data warehouse</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant l&#x27;<strong>ingestion</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Pour la version <em>data warehouse only</em> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La pipeline contient :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Des <em>linked services</em> : ici la <em>data source</em> <em style="color:#3d85c6;font-weight:bold;font-style:normal">MySQL</em> en entrée, et la <em>data sink</em> <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Synapse</em> en sortie.</li>
<li class="nx-my-2">Des <em>data sets</em> : il s&#x27;agit de la description du schéma de données d&#x27;entrée et de sortie, et leur mapping.</li>
</ul>
</li>
<li class="nx-my-2">Si le schéma de la DB source change, il faudra mettre à jour le schéma défini dans la pipeline et le mapping.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Mais surtout il faudra <strong>gérer soi-même la migration</strong> du <em>data sink</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Pour la version <em>cloud data platform</em> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Cette fois le <em>data sink</em> est un <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Blob Storage</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il n&#x27;y a plus besoin de spécifier les schémas et le mapping entre input et output puisque l&#x27;output accueille la donnée telle quelle.</li>
</ul>
</li>
<li class="nx-my-2">Si le schéma de la DB source change, il n&#x27;y a <strong>rien à faire côté ingestion</strong> : on écrira de toute façon la donnée dans un nouveau fichier.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On déplace le problème de mapping plus loin.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant le <strong>processing</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Dans la version <em>data warehouse only</em> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On va charger les deux données :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La DB <em style="color:#3d85c6;font-weight:bold;font-style:normal">MySQL</em> sans charger sa structure parce qu&#x27;elle est déjà relationnelle.</li>
<li class="nx-my-2">La donnée CSV semistructurée dans des rows de type texte qu&#x27;on parsera en JSON avec une fonction SQL built-in.</li>
</ul>
</li>
<li class="nx-my-2">La <strong>requête SQL</strong> qu&#x27;on va écrire aura les désavantages suivants :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Elle sera <strong>peu lisible</strong>, à cause du code de parsing nécessaire.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On pourrait la rendre plus lisible en pré-parsant la donnée, mais ça veut dire plus de temps et des coûts plus élevés.</li>
<li class="nx-my-2">Une autre solution de lisibilité pourrait être d&#x27;ajouter des UDF (User Defined Functions), qu&#x27;il faudrait maintenir et déployer sur chaque instance d&#x27;<em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Synapse</em>.</li>
</ul>
</li>
<li class="nx-my-2">Elle sera <strong>difficile à tester</strong>.</li>
<li class="nx-my-2">Elle risque de ne pas profiter de la <strong>performance</strong> offerte par la structure en colonne du <em>data warehouse</em>, parce que les données texte qu&#x27;on parse en JSON ne sont pas organisables physiquement en colonnes.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Dans la version <em>cloud data platform</em> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On a la possibilité d&#x27;utiliser un <em>distributed data processing engine</em> comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Spark</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On pourra écrire des requêtes SQL pour des expérimentations rapides.</li>
<li class="nx-my-2">Et on pourra aussi écrire du code <strong>lisible, maintenable et testable</strong> dans un langage comme Python ou Scala, quand il s&#x27;agit de projet de plus long terme.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant l&#x27;<strong>accès à la donnée</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il peut y avoir plusieurs types de consommateurs :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Des utilisateurs plutôt <strong>orientés business</strong> comme des équipes marketing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ils vont préférer utiliser des outils de reporting type <em style="color:#3d85c6;font-weight:bold;font-style:normal">Power BI</em>, et donc auront besoin de la donnée sous forme relationnelle, par exemple dans <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Synapse</em>.</li>
</ul>
</li>
<li class="nx-my-2">Des utilisateurs orientés <strong>data analyse / data science</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ils pourront bénéficier de SQL qu&#x27;ils utilisent souvent directement, au travers de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark SQL</em>.</li>
<li class="nx-my-2">Ils pourront avoir accès à des données non filtrées pour leur projets data science, grâce <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> directement.</li>
</ul>
</li>
<li class="nx-my-2">Au final la <em>cloud data platform</em>, qui contient à la fois la donnée sous forme brute dans le <em>data lake</em>, et la donnée dans le <em>data warehouse</em>, est <strong>adaptée à chaque usage</strong>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">A propos des <strong>coûts financiers</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il est difficile de comparer les coûts des services cloud.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">En général on constate que le stockage est plutôt pas cher, et que l&#x27;essentiel des coûts se trouve dans les calculs.</li>
</ul>
</li>
<li class="nx-my-2">L&#x27;<strong>elastic scaling</strong> consiste à pouvoir calibrer le service pour l&#x27;usage exact qu&#x27;on en a, et de ne pas avoir à payer plus.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">C&#x27;est un des éléments qui permet de vraiment optimiser les coûts.</li>
</ul>
</li>
<li class="nx-my-2">Pour la version <em>data warehouse only</em>, l&#x27;essentiel des coûts va aller dans <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Synapse</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le scaling de ce service peut prendre des dizaines de minutes, donc c&#x27;est quelque chose qu&#x27;on ne peut faire que de temps en temps.</li>
</ul>
</li>
<li class="nx-my-2">Pour la version <em>cloud data platform</em>, l&#x27;essentiel des coûts est porté par le <em>processing layer</em>, par exemple <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> est particulièrement élastique, au point où il est commun de démarrer une instance juste le temps d&#x27;une requête.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">3 - Getting bigger and leveraging the Big 3: Amazon, Microsoft, and Google<a href="#3---getting-bigger-and-leveraging-the-big-3-amazon-microsoft-and-google" id="3---getting-bigger-and-leveraging-the-big-3-amazon-microsoft-and-google" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il existe un trade off entre choisir des <strong>services vendor-specific</strong> de type PaaS, et choisir des <strong>services open source</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">D&#x27;un côté on se couple au vendor mais on minimise les coûts d&#x27;Ops, et de l&#x27;autre on permet une meilleure portabilité mais on augmente les coûts d&#x27;Ops.</li>
<li class="nx-my-2">Les auteurs trouvent que <strong>la solution vendor-specific est celle qui a en général le moins de désavantages</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Pour répondre aux problématiques de la data moderne, il faut une <strong>architecture en 6 couches</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>1 - Data ingestion layer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son but est de :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Se connecter aux sources et récupérer la donnée dans le <em>data lake</em> sans trop la modifier.</li>
<li class="nx-my-2">Enregistrer des statistiques et un statut dans le <em>metadata repository</em>.</li>
</ul>
</li>
<li class="nx-my-2">Selon les auteurs, il vaut mieux mettre en place <strong>à la fois un mécanisme de type batch et un mécanisme de type streaming</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L&#x27;industrie est en train de se diriger vers le streaming, mais de nombreuses sources externes fournissent la donnée sous un format de type batch avec des éléments groupés, par exemple CSV, JSON, XML.</li>
<li class="nx-my-2">On pourrait utiliser la partie batch pour ingérer des données par petits batchs, et éviter de faire la version streaming. Mais ça créerait de la <strong>dette technique</strong> parce qu&#x27;on finira par avoir besoin du streaming à un moment ou un autre.</li>
<li class="nx-my-2">La <em>lambda architecture</em> consiste à avoir la donnée qui passe à la fois par le mécanisme de batch et par le mécanisme de streaming.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Cette duplication était nécessaire parce que le streaming n&#x27;était pas fiable dans les débuts de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Hadoop</em>, mais ce n&#x27;est plus le cas.</li>
<li class="nx-my-2">La <em>cloud data platform</em> ne consiste pas à faire une telle duplication : selon la source, la donnée va passer par le mécanisme de streaming ou de batch.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">On entend parfois plusieurs choses différentes quand on parle de <em>real time</em> pour des analytics :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - La <em>real time ingestion</em> consiste à avoir la donnée disponible pour de l&#x27;analyse dès qu&#x27;elle arrive.</li>
<li class="nx-my-2">2 - Le <em>real time analytics</em> consiste à avoir des fonctionnalités d&#x27;analytics qui se mettent à jour à chaque arrivée de donnée.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Cette dernière est plus difficile à faire, donc il vaut mieux bien clarifier les besoins.</li>
<li class="nx-my-2">Exemple : détection de fraude en temps réel.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>2 - Storage layer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son but est de :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Stocker la donnée pour du court terme et du long terme.</li>
<li class="nx-my-2">La rendre disponible pour la consommation streaming et la consommation batch.</li>
</ul>
</li>
<li class="nx-my-2">Le <strong>slow storage</strong> est là pour le mode batch.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La donnée y est persistée pour pas cher, grâce à la possibilité de scaler le stockage sans ajouter de capacité de calcul.</li>
<li class="nx-my-2">Par contre les temps d&#x27;accès sont grands.</li>
</ul>
</li>
<li class="nx-my-2">Le <strong>fast storage</strong> est là pour le mode streaming.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s&#x27;agit d&#x27;utiliser un outil qui est fait pour l&#x27;accès rapide, comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Kafka</em>.</li>
<li class="nx-my-2">Par contre, on n&#x27;a en général pas la possibilité de scaler le stockage sans ajouter de puissance de calcul, et donc les coûts sont plus grands.</li>
<li class="nx-my-2">On va donc purger régulièrement la donnée du fast storage, et de la transférer dans le slow storage.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>3 - Processing layer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son but est de :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Lire la donnée depuis le stockage et y appliquer de la business logic.</li>
<li class="nx-my-2">Persister la donnée modifiée à nouveau dans le stockage pour un usage par les data scientists.</li>
<li class="nx-my-2">Délivrer la donnée aux autres consumers.</li>
</ul>
</li>
<li class="nx-my-2">Il faut un ou plusieurs outils qui permettent de réaliser des transformations de données, y compris avec du calcul distribué.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Un exemple peut être <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Dataflow</em>, qui est une version PaaS d&#x27;<em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Beam</em>, qui supporte à la fois le mode streaming et le mode batch.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>4 - Technical metadata layer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son but est de :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Stocker des informations techniques sur chaque layer.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ça peut être les schémas d&#x27;ingestion, le statut de telle ou telle étape, des statistiques sur les données ou les erreurs, etc.</li>
</ul>
</li>
<li class="nx-my-2">Permettre à chaque layer d&#x27;ajouter/modifier ou consulter des informations.</li>
</ul>
</li>
<li class="nx-my-2">Par exemple, le <em>processing layer</em> peut vérifier dans la <em>technical metadata layer</em> qu&#x27;une certaine donnée est disponible pour aller la chercher, plutôt que de demander à l&#x27;<em>ingestion layer</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ce qui permet un certain <strong>découplage</strong>.</li>
</ul>
</li>
<li class="nx-my-2">D&#x27;autres exemples peuvent impliquer des usages de <strong>monitoring</strong>.</li>
<li class="nx-my-2">La <em>business metadata</em> est une autre notion qui peut avoir son layer, mais qui n&#x27;est pas explorée dans ce livre.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s&#x27;agit d&#x27;identifier l&#x27;usage business qui est fait de chaque donnée qu&#x27;on récupère des sources, et d&#x27;en faire un catalogue.</li>
</ul>
</li>
<li class="nx-my-2">Il n&#x27;y a pas vraiment d&#x27;outil unique qui permette de remplir ce rôle pour le moment, donc on devra sans doute en utiliser plusieurs.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple <em style="color:#3d85c6;font-weight:bold;font-style:normal">Confluent Schema Registry</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Amazon Glue</em> peuvent supporter certains des cas d&#x27;usages.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>5 - Serving layer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son but est de :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Servir les consumers qui ont besoin de données relationnelles via une <em>data warehouse</em>.</li>
<li class="nx-my-2">Servir les consumers qui ont besoin de la donnée brute, en accédant directement au <em>data lake</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les data scientistes vont en général vouloir y accéder via le slow storage.</li>
<li class="nx-my-2">Et l&#x27;accès via le fast storage va plutôt intéresser les applications qui s&#x27;abonnent en mode streaming.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple un système de recommandation ecommerce en temps réel.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>6.1 - Orchestration overlay layer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son but est de :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Coordonner l&#x27;exécution de jobs, sous la forme d&#x27;un graphe de dépendance.</li>
<li class="nx-my-2">Gérer les échecs et les retries.</li>
</ul>
</li>
<li class="nx-my-2">C&#x27;est un peu le complément du <em>technical metadata layer</em> pour permettre le faible couplage entre les layers.</li>
<li class="nx-my-2">L&#x27;outil le plus connu d&#x27;orchestration est <em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Airflow</em>, adopté par Google Cloud Platform sous le nom de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Composer</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">AWS et Azure ont quant à eux choisi d&#x27;inclure des fonctionnalités d&#x27;orchestration dans leur outil d&#x27;ETL.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>6.2 - ETL overlay layer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son but est de :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Prendre en charge les fonctionnalités de certains layers (ingestion, processing, metadata, orchestration) <strong>avec peu ou pas de code</strong>.</li>
</ul>
</li>
<li class="nx-my-2">On pourrait faire l&#x27;ensemble de notre pipeline avec cet outil ETL, la question à se poser c&#x27;est : <strong>à quel point il est ouvert à l&#x27;extension ?</strong>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut vouloir à l&#x27;avenir par exemple utiliser un autre outil de processing, ou s&#x27;interfacer avec un outil open source.</li>
<li class="nx-my-2">Dans le cas où il y a une incompatibilité avec un usage qu&#x27;on a, on peut toujours l&#x27;implémenter à part de l&#x27;outil ETL.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le problème c&#x27;est qu&#x27;au bout d&#x27;un moment, les usages à côté deviennent aussi complexes que la solution entière sans l&#x27;outil ETL, mais avec une <strong>architecture spaghetti</strong>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Parmi les outils ETL il y a <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Glue</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Data Factory</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Cloud Data Fusion</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il existe des solutions commerciales non cloud-natives comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">Talend</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Informatica</em>, mais ce livre se limite au cloud-native et aux outils open source.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Les <strong>couches</strong> doivent être bien <strong>séparées et découplées</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Une première raison est de pouvoir utiliser les outils les plus adaptés aux besoins de chaque couche.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le cloud bougeant très vite, on voudra sans doute pouvoir changer seulement l&#x27;un d&#x27;entre eux quand on a une meilleure alternative pour une couche en particulier.</li>
</ul>
</li>
<li class="nx-my-2">Une autre raison est qu&#x27;on peut avoir plusieurs équipes en charge de la data platform, et il vaut mieux qu&#x27;elles ne se gênent pas.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple, on voudra souvent avoir l&#x27;ingestion plutôt centralisée, et le processing plutôt en mode libre service pour chaque équipe qui en a besoin.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Les <strong>outils</strong> pouvant servir dans une des couches de notre plateforme sont classés en 4 catégories (les auteurs les priorisent dans cet ordre) :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - Solutions <strong>cloud-native PaaS</strong> d&#x27;AWS, GCP ou Azure.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Leur avantage principal c&#x27;est le gain de temps : on n&#x27;a pas à se préoccuper de la compatibilité. On configure très facilement et c&#x27;est en prod.</li>
<li class="nx-my-2">Par contre, c&#x27;est la solution qui va être la moins extensible : si par exemple un connecteur n&#x27;est pas supporté, on aura du mal à l&#x27;ajouter.</li>
<li class="nx-my-2">Elle est aussi peu portable, vu qu&#x27;on n&#x27;a pas les mêmes services d&#x27;un cloud provider à un autre.</li>
</ul>
</li>
<li class="nx-my-2">2 - Solutions <strong>serverless</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s&#x27;agit de pouvoir déployer son code custom, mais sans avoir à se préoccuper des serveurs, de leur configuration, du scaling etc.</li>
<li class="nx-my-2">C&#x27;est une solution intermédiaire d&#x27;un point de vue trade-offs sur la flexibilité, la portabilité et le gain de temps.</li>
</ul>
</li>
<li class="nx-my-2">3 - Solutions <strong>open-source</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Leur avantage c&#x27;est c&#x27;est la flexibilité et la portabilité maximales, mais de l&#x27;autre côté on a à gérer soi-même des VMs dans le cloud donc plus de travail d&#x27;Ops.</li>
</ul>
</li>
<li class="nx-my-2">4 - Solutions <strong>SaaS commerciales</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Elles peuvent avoir un intérêt si elles ont une fonctionnalité non disponible sous forme PaaS ou open source.</li>
</ul>
</li>
<li class="nx-my-2">Dans les faits, on va utiliser un <strong>mix de solutions des 4 catégories</strong> en fonction des layers et des besoins qu&#x27;on a.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On a de plus en plus d&#x27;entreprises qui utilisent des solutions de <strong>plusieurs cloud providers</strong>. Par exemple le gros des services sur AWS, et le use-case machine learning sur GCP.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Outils sur <strong>AWS</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Batch ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Glue</em> supporte l&#x27;ingestion à partir de <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS S3</em>, ou à partir d&#x27;une connexion JDBC.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Database Migration Service</em> sert à la base à transférer ses DBs vers AWS, mais on peut l&#x27;utiliser comme ingestion layer.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS DMS</em> permet d&#x27;implémenter un mécanisme de change data capture à partir d&#x27;une DB.</li>
<li class="nx-my-2">Si aucune des solutions PaaS ne supporte notre data source, on peut utiliser la solution serverless <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Lambda</em> où il faudra écrire et maintenir du code.</li>
</ul>
</li>
<li class="nx-my-2">Streaming ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Kinesis</em> est un message broker pour lequel il faudra écrire du code pour publier dedans. Il a malheureusement très peu de connecteurs entrants.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">En revanche il a des connecteurs sortants appelés <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kinesis Firehose</em>, qui permettent par exemple d&#x27;envoyer la donnée de Kinesis dans un <em style="color:#3d85c6;font-weight:bold;font-style:normal">S3</em> sous format <em style="color:#3d85c6;font-weight:bold;font-style:normal">Parquet</em>.</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Managed Streaming for Apache Kafka (MSK)</em> est une version de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em> entièrement managée.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut l&#x27;utiliser à la place de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kinesis</em>, par exemple si on migre une application avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em> vers AWS.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Storage.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS S3</em> permet de stocker de la donnée de manière scalable, avec la possibilité de choisir entre plusieurs formules avec des latences plus ou moins grandes.</li>
</ul>
</li>
<li class="nx-my-2">Batch processing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Elastic MapReduce (EMR)</em> est une version managée de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On va en général lire la donnée depuis <em style="color:#3d85c6;font-weight:bold;font-style:normal">S3</em>, faire le calcul, puis détruire le cluster <em style="color:#3d85c6;font-weight:bold;font-style:normal">EMR</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Streaming processing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Kinesis Data Analytics</em> permet de se brancher sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kinesis</em>, et de faire du processing en streaming.</li>
<li class="nx-my-2">Si on utilise <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS MSK</em>, on peut brancher dessus <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka Streams</em> pour le processing en streaming.</li>
</ul>
</li>
<li class="nx-my-2">Data warehouse.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Redshift</em> est un <em>data warehouse</em> distributé sur plusieurs noeuds.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Redshift Spectrum</em> permet de faire des requêtes depuis <em style="color:#3d85c6;font-weight:bold;font-style:normal">Redshift</em> pour obtenir des données qui sont en fait sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">S3</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faudra définir des “tables externes”, et la performance de la query sera moins bonne, mais ça permet d&#x27;économiser de la place dans le <em>data warehouse</em>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Direct access.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Athena</em> permet de faire une requête SQL distribuée en utilisant directement la donnée sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">S3</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On lance l&#x27;instance le temps de la requête, puis on détruit l&#x27;instance.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">ETL overlay et metadata repository.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Glue</em> est un outil d&#x27;ETL complet.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il est construit autour de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>, et possède des templates pour faciliter de nombreuses transformations.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il a aussi des add-ons <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> non-standards, ce qui nuit à la portabilité par rapport à un simple <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> managé.</li>
</ul>
</li>
<li class="nx-my-2">Il maintient un <em>Data Catalog</em> à partir des données disponibles sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">S3</em>.</li>
<li class="nx-my-2">Il maintient un ensemble de statistiques sur l&#x27;exécution des jobs.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Orchestration.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Step Functions</em> permet de créer des workflows qui mettent en jeu différents services, y compris ceux qui ne seraient pas gérés par <em style="color:#3d85c6;font-weight:bold;font-style:normal">Glue</em> comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Lambda</em> avec du code custom.</li>
</ul>
</li>
<li class="nx-my-2">Consumers.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Pour les outils comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">Tableau</em> qui ont besoin d&#x27;une connexion JDBC/ODBC qui supporte SQL, elles peuvent se connecter à <em style="color:#3d85c6;font-weight:bold;font-style:normal">Redshift</em> ou <em style="color:#3d85c6;font-weight:bold;font-style:normal">Athena</em>.</li>
<li class="nx-my-2">Pour du streaming avec faible latence, on peut envoyer la donnée dans un key/value store comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">DynamoDB</em>, ou dans une DB comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS RDS</em> ou <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Aurora</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Outils sur <strong>GCP</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Batch ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Cloud Data Fusion</em> est un ETL overlay qui permet d&#x27;ingérer des données depuis une DB relationnelle avec JDBC, des fichiers depuis <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Cloud Storage</em>, et même depuis un FTP ou depuis <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS S3</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il est basé sur un projet open source, et donc supporte des connecteurs custom.</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">BigQuery Data Transfer Service</em> permet d&#x27;ingérer de la donnée depuis les services SaaS de Google, et depuis des centaines d&#x27;autres services SaaS connus grâce à un partenariat avec Fivetran.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par contre, la donnée va directement dans le <em>data warehouse</em>, ce qui ne permet pas vraiment l&#x27;architecture modulaire qu&#x27;on vise.</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Cloud Functions</em> représente l&#x27;équivalent d&#x27;<em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Lambda</em>, avec le désavantage d&#x27;avoir une limite de temps d&#x27;exécution des fonctions serverless.</li>
</ul>
</li>
<li class="nx-my-2">Stream ingrestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Cloud Pub/Sub</em> est un broker équivalent à <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Kinesis</em>.</li>
</ul>
</li>
<li class="nx-my-2">Storage.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Cloud Storage</em> est un équivalent à <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS S3</em>.</li>
</ul>
</li>
<li class="nx-my-2">Batch processing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Dataproc</em> est un <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> managé équivalent à <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS EMR</em>.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Cloud Dataflow</em> est un <em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Beam</em> managé.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Beam</em> a l&#x27;avantage d&#x27;offrir une même API pour le batch processing et le streaming processing, là où <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> ne supporte que le batch mais est une techno plus mature.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Streaming processing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Cloud Dataflow</em> représente la manière cloud-native de faire du streaming sur GCP.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Dataproc</em> avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark Streaming</em> peut représenter une alternative, mais il s&#x27;agit en fait de micro-batch et non pas de traiter les messages un par un.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les auteurs conseillent <em style="color:#3d85c6;font-weight:bold;font-style:normal">Beam</em>, sauf si on a déjà investi en temps ou connaissances sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Data warehouse.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">BigQuery</em> est un équivalent à <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Redshift</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il a l&#x27;avantage de scaler le nombre de nœuds tout seul.</li>
<li class="nx-my-2">Par contre il a un modèle de facturation basé sur la donnée lue par chaque requête, ce qui peut rendre les coûts difficiles à prédire.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Direct access.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">GCP ne propose pas de services pour accéder au <em>data lake</em> directement avec du SQL.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut éventuellement créer des tables vers de la donnée externe (donc dans le <em>data lake</em>) à partir de <em style="color:#3d85c6;font-weight:bold;font-style:normal">BigQuery</em>.</li>
<li class="nx-my-2">On peut aussi utiliser <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark SQL</em> pour identifier et lire de la donnée sur le <em>data lake</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">ETL overlay et metadata repository.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Cloud Data Fusion</em> est un ETL overlay équivalent à <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Glue</em>. Il fournit une UI qui permet de configurer la pipeline.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il met à disposition un moyen d&#x27;analyser quelle partie de la pipeline peut affecter telle ou telle donnée.</li>
<li class="nx-my-2">Il met aussi à disposition des statistiques sur l&#x27;exécution des jobs.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Orchestration.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Cloud Composer</em> permet de créer des flows d&#x27;orchestration entre jobs.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il est basé sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Airflow</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Consumers.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">BigQuery</em> n&#x27;a pas de connexion JDBC/ODBC pour y connecter un outil BI par exemple.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il a une API REST, et il est directement compatible avec certains outils BI.</li>
</ul>
</li>
<li class="nx-my-2">Si on veut consommer la donnée avec une faible latence, on peut la mettre dans le key/value store <em style="color:#3d85c6;font-weight:bold;font-style:normal">Cloud Bigtable</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Outils sur <strong>Azure</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Batch ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Data Factory</em> est un ETL overlay permettant de faire de l&#x27;ingestion depuis diverses sources (DB, SaaS externes, <em style="color:#3d85c6;font-weight:bold;font-style:normal">S3</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">GCS</em> etc.).<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il est celui qui a le plus de connecteurs comparé à <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Glue</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Cloud Data Fusion</em>.</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Functions</em> est l&#x27;équivalent d&#x27;<em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Lambda</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il ne supporte que Java et Python.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Streaming ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Event Hubs</em> est équivalent à <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Kinesis</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il a la particularité d&#x27;être compatible avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Kafka</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Storage.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Blob Storage</em> est équivalent à <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS S3</em>.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Data Lake Storage</em> est une version améliorée qui supporte mieux le calcul distribué avec de grandes quantités de données.</li>
</ul>
</li>
<li class="nx-my-2">Batch processing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Pour le batch processing, Azure a choisi de miser sur un partenariat avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Databricks</em>, qui est un service créé par les créateurs de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La version managée de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Databricks</em> est disponible sur AWS et Azure, mais elle est celle par défaut sur Azure, donc mieux supportée par son écosystème.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Streaming processing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Stream Analytics</em> se branche sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">Event Hubs</em> et permet de faire du streaming processing.</li>
</ul>
</li>
<li class="nx-my-2">Data warehouse.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Synapse</em> est le <em>data warehouse</em> d&#x27;Azure.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il est entre <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Redshift</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google BigQuery</em> dans la mesure où il nécessite de choisir la capacité de calcul, mais il scale l&#x27;espace disque tout seul.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Direct access.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Databricks</em> est la manière privilégiée d&#x27;accéder à la donnée sur le <em>data lake</em>, soit par l&#x27;API native de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>, soit en SQL avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark SQL</em>.</li>
</ul>
</li>
<li class="nx-my-2">ETL overlay et metadata repository.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Data Factory</em> est équivalent à <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Glue</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s&#x27;intègre parfaitement avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Databricks</em> pour les transformations complexes.</li>
<li class="nx-my-2">Il fournit des métriques sur la data pipeline.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Orchestration.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La partie orchestration des jobs est prise en charge par <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Data Factory</em>.</li>
</ul>
</li>
<li class="nx-my-2">Consumers.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Synapse</em> fournit une connexion JDBC/ODBC pour connecter les outils de BI.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Databricks</em> fournit la même chose, mais il faut un cluster <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> toujours allumé, ce qui peut coûter cher.</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Cosmos DB</em> est une DB orientée document où on peut stocker les résultats de processings pour un accès faible latence.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Alternatives <strong>commerciales</strong> ou <strong>open source</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Certains logiciels open source sont trop difficiles à mettre en place, par exemple un <em>data warehouse</em> distribué comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Druid</em>.</li>
<li class="nx-my-2">Batch ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il existe pas mal d&#x27;outils open source et commerciaux qui permettent d&#x27;ingérer des données, leur valeur ajoutée étant en général le grand nombre de sources supportées.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Apachi NiFi</em> est une solution open source qui supporte de nombreuses sources, et permet d&#x27;en ajouter soi-même en Java.</li>
<li class="nx-my-2">Il existe de nombreux outils SaaS commerciaux qui gèrent l&#x27;ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ces outils vont souvent envoyer la donnée directement dans un <em>data warehouse</em>.</li>
<li class="nx-my-2">Il faut bien réfléchir à la problématique de la sécurité.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Streaming ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Kafka</em> est le principal outil utilisé en dehors d&#x27;une solution managée de streaming.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il a l&#x27;avantage de pouvoir se connecter à de nombreuses sources avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka Connect</em>, et il a un moyen d&#x27;implémenter des applications de streaming avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka Streams</em>.</li>
<li class="nx-my-2">Les raisons de choisir <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em> plutôt qu&#x27;une solution cloud-native peuvent être l&#x27;investissement qu&#x27;on a déjà dans <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em> (par exemple connaissances), ou le besoin de performance nécessitant le fine-tuning du serveur <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Orchestration.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Airflow</em> est le principal outil utilisé en dehors d&#x27;une solution managée d&#x27;orchestration.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La raison de l&#x27;utiliser en mode non managé peut être de profiter de sa flexibilité, avec ses fichiers en Python.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">4 - Getting data into the platform<a href="#4---getting-data-into-the-platform" id="4---getting-data-into-the-platform" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le layer d&#x27;ingestion peut avoir besoin d&#x27;ingérer différents types de données :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>1 - Les bases de données relationnelles</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Leurs données sont organisées en colonnes et typées, mais chaque vendor a des types à lui.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il y a donc un <strong>mapping</strong> à faire entre le type de chaque colonne et notre modèle.</li>
<li class="nx-my-2">Ce mapping va changer régulièrement en fonction des évolutions fonctionnelles des applications qui possèdent ces DBs.</li>
</ul>
</li>
<li class="nx-my-2">Vu que la donnée est normalisée, elle se trouve dans des centaines de tables.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faudra donc <strong>automatiser le mapping</strong> pour éviter de le faire à la main.</li>
</ul>
</li>
<li class="nx-my-2">La donnée change régulièrement dans la DB, pour refléter l&#x27;état de l&#x27;application, elle est <strong>volatile</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faudra donc aller chercher régulièrement les derniers changements.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>2 - Les fichiers.</strong>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les fichiers sont structurés selon divers types de format texte ou binaire (CSV, JSON XML, Avro, Protobuf etc.) qui ne contiennent pas d&#x27;information de type.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut donc pouvoir <strong>supporter le parsing de tous ces formats</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Les fichiers ne garantissent aucun schéma, et on voit beaucoup plus souvent des changements dans celui-ci que pour les DB relationnelles.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut donc gérer les <strong>changements de schéma fréquents</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Les fichiers représentent en général de la <strong>donnée figée</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La nouvelle donnée est écrite dans un autre fichier, donc on se retrouve à devoir ingérer <strong>de nombreux fichiers</strong>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>3 - La donnée SaaS via API.</strong>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les données SaaS sont en général disponibles via une API REST, qui renvoie du JSON.</li>
<li class="nx-my-2">Chaque provider a sa propre API, et son propre format. Il faudra donc <strong>implémenter la partie ingestion pour chacun des providers</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faudra faire la validation du schéma à chaque fois.</li>
<li class="nx-my-2">Il faudra la tenir à jour en fonction des changements d&#x27;API.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>4 - Les streams</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les mêmes données peuvent arriver plusieurs fois, donc il faut que notre pipeline puisse <strong>gérer les duplicatas</strong>.</li>
<li class="nx-my-2">Les events des streams sont immutables, et peuvent être corrigés en ajoutant un autre message modifié au stream.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Donc il faut que notre pipeline <strong>gère la réconciliation entre plusieurs versions d&#x27;un même message</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Les données de streaming ont en général un <strong>grand volume</strong>, donc il faut une infrastructure qui le supporte.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant le cas des <strong>bases de données relationnelles</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il y a deux moyens d&#x27;ingérer de la donnée depuis une DB relationnelle :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>1 - L&#x27;utilisation de requêtes SQL</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s&#x27;agit d&#x27;avoir un composant qui va :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - Exécuter la requête vers la DB concernée.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ca peut être un simple :<!-- -->
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="sql" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="sql" data-theme="default"><span class="line"><span style="color:var(--shiki-token-keyword)">SELECT</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-keyword)">*</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-keyword)">FROM</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-keyword)">table</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
</ul>
</li>
<li class="nx-my-2">2 - Récupérer la donnée sous un format qu&#x27;il comprend.</li>
<li class="nx-my-2">3 - Mapper la donnée dans le bon format pour la stocker sur le <em>storage layer</em>.</li>
<li class="nx-my-2">Il y a donc <strong>2 mappings</strong> qui se produisent pendant l&#x27;opération.</li>
</ul>
</li>
<li class="nx-my-2">Alors que la donnée opérationnelle s&#x27;intéresse à l&#x27;état actuel (“Quels sont les articles dans le panier ?”), <strong>la donnée analytique s&#x27;intéresse à l&#x27;évolution de l&#x27;état dans le temps</strong> (“Quels articles ont été ajoutés ou enlevés et dans quel ordre ?”).<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut donc un moyen pour capturer l&#x27;évolution de la donnée dans le temps.</li>
</ul>
</li>
<li class="nx-my-2">Une 1ère solution pour garder l&#x27;évolution dans le temps est de faire une <strong>full table ingestion</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On va récupérer l&#x27;ensemble des données d&#x27;une table à intervals réguliers, sauver ces snapshots dans le <em>data lake</em>, et les charger dans le <em>data warehouse</em>.</li>
<li class="nx-my-2">Pour en tirer quelque chose, il faut <strong>superposer les rows des snapshots</strong> dans la même table du <em>data warehouse</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Pour différencier les rows de chaque snapshot, on peut ajouter une colonne <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">INGEST_DATE</code>.</li>
<li class="nx-my-2">On peut directement utiliser du SQL pour obtenir les données qu&#x27;on veut, mais pour certains usages on aura besoin de faire une transformation dans le <em>processing layer</em>.</li>
</ul>
</li>
<li class="nx-my-2">Parmi les données dérivées qu&#x27;on voudra créer, il peut y avoir :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Créer une <em>view</em> qui ne montre que les rows du dernier snapshot.</li>
<li class="nx-my-2">De la donnée qui <strong>identifie les suppressions</strong>, en identifiant les rows qui existaient dans un snapshot et n&#x27;existaient plus dans le suivant.</li>
<li class="nx-my-2">Une version “compactée”, qui élimine les rows qui n&#x27;ont pas changé par rapport au snapshot précédent.</li>
</ul>
</li>
<li class="nx-my-2">Le problème de la full table ingestion, c&#x27;est la charge sur la machine de DB, et l&#x27;<strong>énorme quantité de données</strong> qu&#x27;on finit par avoir.</li>
</ul>
</li>
<li class="nx-my-2">Une autre solution peut être l&#x27;<strong>incremental table ingestion</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s&#x27;agit toujours de récupérer des snapshots à intervalles réguliers, mais <strong>seulement de la donnée qui a changé</strong> depuis le précédent snapshot.</li>
<li class="nx-my-2">Pour savoir quelle donnée a changé :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La table d&#x27;origine doit avoir un champ <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">LAST_MODIFIED</code>, mis à jour automatiquement par la DB.</li>
<li class="nx-my-2">En retenant le <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">MAX(LAST_MODIFIED)</code> du dernier run d&#x27;ingestion (qu&#x27;on appelle le <em>highest watermark</em>), on peut construire une query qui récupère uniquement les nouvelles données :<!-- -->
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="sql" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="sql" data-theme="default"><span class="line"><span style="color:var(--shiki-token-keyword)">SELECT</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-keyword)">*</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-keyword)">FROM</span><span style="color:var(--shiki-color-text)"> subscriptions </span><span style="color:var(--shiki-token-keyword)">WHERE</span><span style="color:var(--shiki-color-text)"> LAST_MODIFIED </span><span style="color:var(--shiki-token-keyword)">&gt;</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-string-expression)">&quot;2019-05-01 17:01:00&quot;</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
<li class="nx-my-2">On pourra mettre le <em>highest watermark</em> dans le <em>technical metadata layer</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Glue</em> gère nativement le stockage de ce genre de données, mais on peut le mettre dans une DB managée comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Cloud SQL</em> ou <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure SQL Database</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Cette <em>incremental table ingestion</em> permet d&#x27;ingérer moins de données dupliquées, mais elle a encore des inconvénients :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut faire du processing pour faire apparaître les données supprimées, en comparant les snapshots entre eux.</li>
<li class="nx-my-2">Les données qui sont insérées puis supprimées entre deux snapshots ne seront pas capturées par ce mécanisme, donc <strong>on perd des informations</strong>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>2 - Le Change Data Capture (CDC)</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le CDC permet de récupérer <strong>l&#x27;ensemble des opérations</strong> qui ont lieu sur la table, <strong>sans aucun doublon</strong>.</li>
<li class="nx-my-2">Il s&#x27;agit de lire le log de changements créé par la DB, à l&#x27;aide d&#x27;une application qui sait le faire.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L&#x27;application peut être fournie par la DB, ou une application cloud-native comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Database Migration Service</em>, ou une application open source comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">Debezium</em>.</li>
</ul>
</li>
<li class="nx-my-2">Etant donné que les DBs ne gardent pas longtemps leur log de changements, <strong>le CDC nécessite une infrastructure de type streaming</strong> pour être récupéré.</li>
<li class="nx-my-2">Le format des messages récupérés depuis le log de changements contient la valeur du row avant, sa valeur après l&#x27;opération, le type d&#x27;opération, et des metadata.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On va vouloir mettre dans le <em>data warehouse</em> uniquement la valeur après l&#x27;opération et le type d&#x27;opération.</li>
<li class="nx-my-2">La table dans le <em>data warehouse</em> ressemble du coup au cas de l&#x27;<em>incremental table ingestion</em> : on a une entrée par changement.</li>
</ul>
</li>
<li class="nx-my-2">Le CDC sur une DB <em style="color:#3d85c6;font-weight:bold;font-style:normal">Oracle</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Oracle fournit <em style="color:#3d85c6;font-weight:bold;font-style:normal">Oracle GoldenGate</em>, une application qui permet de lire son log de changement et de le transférer vers diverses plateformes.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut acheter la licence pour pouvoir l&#x27;utiliser.</li>
</ul>
</li>
<li class="nx-my-2">On peut mettre en place <em style="color:#3d85c6;font-weight:bold;font-style:normal">Debezium</em> qui est open source, mais il faudra qu&#x27;il puisse se connecter à <em style="color:#3d85c6;font-weight:bold;font-style:normal">Oracle XStream API</em>, qui lui-même nécessite quand même une licence <em style="color:#3d85c6;font-weight:bold;font-style:normal">GoldenGate</em>.</li>
<li class="nx-my-2">Oracle fournit un outil d&#x27;analyse qui s&#x27;appelle <strong>LogMiner</strong>, qui est considéré comme pas 100% fiable.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Certains outils comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Database Migration Service</em> l&#x27;utilisent malgré tout.</li>
</ul>
</li>
<li class="nx-my-2">Une alternative moins chère à <em style="color:#3d85c6;font-weight:bold;font-style:normal">GoldenGate</em> peut être <em style="color:#3d85c6;font-weight:bold;font-style:normal">SharePlex</em>, un produit fait par Quest.</li>
</ul>
</li>
<li class="nx-my-2">Le CDC sur une DB <em style="color:#3d85c6;font-weight:bold;font-style:normal">MySQL</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">MySQL</em> écrit les changements dans un log servant principalement à la réplication, pour ajouter des DBs followers.</li>
<li class="nx-my-2">Vu que c&#x27;est une DB open source, il existe de nombreux outils pour servir d&#x27;application CDC à partir de ce log, par exemple : <em style="color:#3d85c6;font-weight:bold;font-style:normal">Debezium</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache NiFi</em>.</li>
</ul>
</li>
<li class="nx-my-2">Le CDC sur une DB <em style="color:#3d85c6;font-weight:bold;font-style:normal">MS SQL Server</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">MS SQL Server</em> fournit la possibilité de rediriger le log de changements d&#x27;une table vers une table créée spécialement pour ça.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut donc facilement implémenter un outil CDC qui n&#x27;a qu&#x27;à utiliser SQL pour lire cette nouvelle table régulièrement.</li>
</ul>
</li>
<li class="nx-my-2">Parmi les outils qui supportent le CDC sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">MS SQL Server</em>, il y a par exemple: <em style="color:#3d85c6;font-weight:bold;font-style:normal">Debezium</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache NiFi</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Database Migration Service</em>.</li>
</ul>
</li>
<li class="nx-my-2">Le CDC sur une DB <em style="color:#3d85c6;font-weight:bold;font-style:normal">PostgreSQL</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">PostgreSQL</em> supporte le fait de fournir son log de changements sous un format Protobuf ou JSON, ce qui facilite le travail des applications CDC.</li>
<li class="nx-my-2">Il existe de nombreux outils qui savent lire ces données, par exemple : <em style="color:#3d85c6;font-weight:bold;font-style:normal">Debezium</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Database Migration Service</em>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant le <strong>mapping des données</strong> depuis la DB vers le <em>data warehouse</em>, il va falloir faire une <strong>analyse pour vérifier la compatibilité</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - On prépare une liste des types de données supportées par la DB dont on veut capturer les données.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il vaut mieux prendre l&#x27;ensemble des types, en prévision d&#x27;ajout de colonnes avec des types qui n&#x27;étaient pas utilisés jusque là par l&#x27;application.</li>
</ul>
</li>
<li class="nx-my-2">2 - On prépare une liste des types supportés par le <em>data warehouse</em> de destination, et on identifie les différences avec la précédente.</li>
<li class="nx-my-2">3 - On identifie les types qui ne correspondent pas exactement, mais permetteront une conversion sans perte d&#x27;information.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple un type <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">SMALLINT</code> sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">MySQL</em> comme source, et le seul entier disponible sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google BigQuery</em> qui est l&#x27;équivalent d&#x27;un <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">BIGINT</code>.</li>
</ul>
</li>
<li class="nx-my-2">4 - On identifie les types qui n&#x27;ont pas de correspondance satisfaisante, et pourraient mener à une perte d&#x27;information.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On essaye de voir si on ne peut pas trouver un workaround, par exemple transformer des données géospatiales en string, puis utiliser du processing pour les parser au moment de la lecture.</li>
</ul>
</li>
<li class="nx-my-2">5 - Si on est devant une impasse, on essaye de voir s&#x27;il n&#x27;y a pas un outil de <em>data warehouse</em> plus adapté.</li>
<li class="nx-my-2">6 - Dans le cas où notre application d&#x27;ingestion n&#x27;est pas faite à la main, on vérifie les types qu&#x27;elle supporte, et leur compatibilité avec la source et la destination.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les auteurs conseillent de faire plusieurs PoC, et disent de ne pas faire confiance aux documentations de ces outils.</li>
</ul>
</li>
<li class="nx-my-2">7 - Si on écrit l&#x27;application d&#x27;ingestion à la main, il faut vérifier les types supportés par le driver qui nous permet d&#x27;accéder à la DB. Par exemple le driver JDBC.</li>
</ul>
</li>
<li class="nx-my-2">Les DBs <strong>NoSQL</strong> sont à traiter différemment des DBs relationnelles.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Parmi les solutions courantes :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut utiliser un outil SaaS commercial qui supporte notre DB NoSQL : dans ce cas rien de plus à faire.</li>
<li class="nx-my-2">Implémenter l&#x27;application d&#x27;ingestion à la main, en utilisant l&#x27;API de notre DB NoSQL directement pour accéder aux données.</li>
<li class="nx-my-2">Utiliser une application CDC si c&#x27;est disponible.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple <em style="color:#3d85c6;font-weight:bold;font-style:normal">Debezium</em> supporte MongoDB.</li>
</ul>
</li>
<li class="nx-my-2">On peut utiliser l&#x27;outil d&#x27;export de données de notre DB NoSQL, et le faire tourner régulièrement pour avoir un snapshot des données.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">MongoDB</em> permet d&#x27;obtenir les données sous un format CSV ou JSON, et l&#x27;outil permet d&#x27;ajouter des requêtes, donc on peut avoir une colonne qui a la date de la dernière modification, et faire un <em>incremental table ingestion</em>.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Cassandra</em> permet d&#x27;obtenir les données sous un format CSV, mais uniquement en mode <em>full table ingestion</em>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant les <strong>metadata liées à l&#x27;ingestion</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut sauvegarder un certain nombre de statistiques pour pouvoir ensuite faire des vérifications sur la <strong>qualité des données</strong> ingérées, et du <strong>monitoring</strong> de l&#x27;ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On va mettre tout ça dans notre <em>technical metadata layer</em>.</li>
</ul>
</li>
<li class="nx-my-2">Parmi les <strong>statistiques</strong> qu&#x27;on veut :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le nom et l&#x27;adresse IP du serveur de DB.</li>
<li class="nx-my-2">Le nom de la base de données ou du schéma.</li>
<li class="nx-my-2">Le nom de la table.</li>
<li class="nx-my-2">Le type de DB dans le cas où on en gère plusieurs.</li>
<li class="nx-my-2">Pour de l&#x27;ingestion en batch, le nombre de rows ingérées.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On pourra à partir de ça vérifier que l&#x27;ensemble des données sont arrivées à destination.</li>
<li class="nx-my-2">On peut monitorer ce chiffre pour être alerté dans le cas d&#x27;une variation anormale.</li>
</ul>
</li>
<li class="nx-my-2">La durée de chaque job d&#x27;ingestion, de même que le début et la fin de l&#x27;ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">C&#x27;est un moyen de monitorer la santé de la pipeline.</li>
</ul>
</li>
<li class="nx-my-2">Pour de l&#x27;ingestion en streaming, on prend les statistiques par <strong>fenêtre temporelle</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple insérer un row toutes les 5 mn dans notre DB de technical metadata. Plus on a besoin de réagir vite, et plus on va choisir une fenêtre petite.</li>
<li class="nx-my-2">On peut aussi ajouter le nombre d&#x27;inserts, updates, deletes etc. pour chaque fenêtre.</li>
</ul>
</li>
<li class="nx-my-2">Les changements dans le schéma de la DB source, ce qui nous permettra d&#x27;être alerté et d&#x27;adapter la pipeline.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant le cas des <strong>fichiers</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les fichiers (par exemple CSV, JSON) permettent un bon découplage entre deux systèmes.</li>
<li class="nx-my-2">On a en général deux moyens de mettre à disposition des fichiers :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Via un serveur dédié qui expose un protocole <strong>FTP</strong>.</li>
<li class="nx-my-2">Via le service de <strong>storage d&#x27;un cloud provider</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les avantages sont l&#x27;aspect <em>elastic</em>, et les mécanismes de sécurité pré-configurés.</li>
<li class="nx-my-2">Le désavantage principal c&#x27;est que c&#x27;est cloud provider met en place des coûts pour faire sortir la donnée de son infrastructure.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Les fichiers sont <strong>immutables</strong> une fois qu&#x27;ils sont écrits, ce qu&#x27;on aura besoin de tracker c&#x27;est <strong>quels fichiers ont déjà été ingérés</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - Une approche recommandée par les auteurs c&#x27;est d&#x27;avoir <strong>deux dossiers</strong> dans le système source qui met à disposition les fichiers : <strong>incoming</strong> et <strong>processed</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L&#x27;application d&#x27;ingestion va ingérer un fichier depuis <em>incoming</em>, puis une fois que l&#x27;ingestion est terminée, elle va le copier dans <em>processed</em> et le supprimer d&#x27;<em>incoming</em>.</li>
<li class="nx-my-2">On le laisse dans <em>processed</em> pendant quelques jours dans un but de débug et de replay, avant de le supprimer.</li>
<li class="nx-my-2">Parmi les avantages :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On n&#x27;a pas besoin de tracker quels fichiers ont été traités : il suffit de traiter ceux du dossier <em>incoming</em>.</li>
<li class="nx-my-2">On peut facilement rejouer l&#x27;ingestion en replaçant le fichier depuis <em>processed</em> vers <em>incoming</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">2 - Dans le cas où l&#x27;approche des deux dossiers n&#x27;est pas possible, parce que le système source veut organiser autrement ses fichiers, ou qu&#x27;on n&#x27;a pas la possibilité de les modifier, on peut mettre en place l&#x27;approche des <strong>timestamps</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Chaque fichier va avoir un timestamp de la dernière fois qu&#x27;il a été modifié, et on va devoir garder le timestamp le plus récent dont on a ingéré un fichier dans le <em>technical metadata layer</em>.</li>
<li class="nx-my-2">Vu que le filesystem ne fournit pas de système d&#x27;indexation, on va devoir lire à chaque fois les metadata de l&#x27;ensemble des fichiers pour savoir s&#x27;ils sont plus récents ou moins récents que notre timestamp sauvegardé.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut se retrouver face à un problème de performance, surtout avec les stockages cloud de masse.</li>
</ul>
</li>
<li class="nx-my-2">Cette méthode rend plus compliqué le replay des fichiers : on devra possiblement modifier notre dernier timestamp sauvegardé, et on aura du mal avec les fichiers qui ont le même timestamp de modification.</li>
<li class="nx-my-2">Certains outils comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache NiFi</em> implémentent déjà ce mécanisme.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faudra faire attention à faire un backup de ces données pour ne pas avoir à reprocesser tous les fichiers.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">3 - Une variante de l&#x27;approche des timestamps consiste à organiser les fichiers source dans une <strong>arborescence de dossiers représentant la date d&#x27;ajout</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Exemple :<!-- -->
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="bash" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="bash" data-theme="default"><span class="line"><span style="color:var(--shiki-token-function)">/ftp/inventory_data/incoming/2019/05/28/sales_1_081232</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
<li class="nx-my-2">On peut s&#x27;en servir pour ne lire que les metadata des fichiers qui sont à la date qu&#x27;on veut ingérer.</li>
</ul>
</li>
<li class="nx-my-2">4 - Des <strong>outils cloud-native</strong> existent pour copier des fichiers d&#x27;un storage à un autre, et de ne copier que les nouveaux fichiers à chaque fois qu&#x27;il y en a.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">gsutil</em> permet de le faire chez Google Cloud, <em style="color:#3d85c6;font-weight:bold;font-style:normal">blobxfer</em> chez Azure, et <em style="color:#3d85c6;font-weight:bold;font-style:normal">s3 sync</em> chez AWS.</li>
<li class="nx-my-2">Il est compliqué de faire du replay avec ces outils, parce qu&#x27;il n&#x27;y a pas de dernier timestamp stocké à modifier.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant les <strong>metadata techniques à garder</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On ne va pas à ce stade récupérer de statistiques sur le nombre de rows dans le fichier, parce que ce serait techniquement coûteux pour l&#x27;ingestion layer.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On le fait pour les DBs parce que c&#x27;est pas cher.</li>
</ul>
</li>
<li class="nx-my-2">Parmi les <strong>statistiques à récupérer</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Nom permettant d&#x27;identifier la source.</li>
<li class="nx-my-2">Taille du fichier.</li>
<li class="nx-my-2">Durée de l&#x27;ingestion.</li>
<li class="nx-my-2">Le nom du fichier et le path où il était (peut contenir des infos importantes).</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant le cas des <strong>streams</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s&#x27;agit ici de lire de la donnée disponible dans Kafka, ou encore dans un équivalent cloud-native.</li>
<li class="nx-my-2">On parle ici seulement d&#x27;<strong>ingestion en mode streaming</strong>, c&#x27;est-à-dire que la donnée est disponible dans la plateforme dès que possible, mais elle sera exploitée plus tard.</li>
<li class="nx-my-2">Les étapes à mettre en place sont :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - La 1ère étape est de <strong>lire le stream source, et de l&#x27;écrire dans le <em>fast storage</em></strong> de notre <em>cloud data platform</em>, qui est aussi un stream.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut faire ça avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka Connect</em>, qui permet de lire et écrire entre deux topics <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em>, mais aussi de lire depuis <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em> et écrire dans une solution de streaming cloud-native, ou l&#x27;inverse.</li>
<li class="nx-my-2">On peut aussi faire notre propre application <strong>consumer Kafka à la main</strong>, mais il faudra alors s&#x27;occuper de la gestion des erreurs, du logging, et du scaling de notre consumer. Les auteurs le <strong>déconseillent</strong>.</li>
</ul>
</li>
<li class="nx-my-2">2 - On va ensuite <strong>l&#x27;écrire dans le <em>data warehouse</em></strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les auteurs conseillent fortement d&#x27;utiliser une solution <strong>cloud-native</strong> pour ça, en fonction de notre fast storage :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Stream Analytics</em> qui lit depuis <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Event Hubs</em> pour écrire dans <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure SQL Warehouse</em>.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Cloud Dataflow</em> qui lit depuis <em style="color:#3d85c6;font-weight:bold;font-style:normal">Cloud Pub/Sub</em> pour écrire dans <em style="color:#3d85c6;font-weight:bold;font-style:normal">BigQuery</em>.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Kinesis Data Firehose</em> qui lit depuis <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Kinesis</em> pour écrire dans <em style="color:#3d85c6;font-weight:bold;font-style:normal">Redshift</em>.</li>
</ul>
</li>
<li class="nx-my-2">Pour <em style="color:#3d85c6;font-weight:bold;font-style:normal">BigQuery</em> on peut ingérer dans le <em>data warehouse</em> en streaming, mais pour les deux autres, il faudra faire de petits batchs.</li>
</ul>
</li>
<li class="nx-my-2">3 - L&#x27;autre chose à faire en parallèle c&#x27;est d&#x27;écrire la donnée <strong>depuis le <em>fast storage</em> vers le <em>slow storage</em></strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut là aussi utiliser les solutions cloud-natives.</li>
<li class="nx-my-2">Il va falloir écrire la donnée par batchs pour des raisons de performance. Les auteurs recommandent des <strong>batchs de plusieurs centaines de MB</strong> si c&#x27;est possible.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em> (et les solutions cloud-natives similaires) doit faire le commit de son offset, et en général il le fait après avoir traité plusieurs messages pour des raisons de performance;<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ça veut dire que si il y a un crash, les message traités mais non commités seront traités à nouveau. Donc il faut <strong>gérer la duplication</strong>.</li>
<li class="nx-my-2">Un des moyens de le faire c&#x27;est d&#x27;avoir un identifiant unique par message, et ensuite d&#x27;enlever les doublons dans la phase de processing.</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em> a en général une <em>cleanup policy</em> qui est de l&#x27;ordre de la semaine, ce qui fait que pour <strong>rejouer de la donnée</strong>, il faut prévoir une étape qui va la chercher dans le <em>slow storage</em>, et la remet dans le <em>fast storage</em>.</li>
<li class="nx-my-2">Concernant les <strong>metadata techniques à garder</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les metadata à garder ressemblent à ceux du cas CDC depuis les DBs relationnelles.</li>
<li class="nx-my-2">On mesure le nombre de messages ingérés par fenêtre de temps (dont la taille dépendra du type de données ingérées).</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant le cas des <strong>applications SaaS</strong> qui fournissent de la donnée.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les applications SaaS vont en général exposer leurs données via une API REST, le contenu étant formaté en JSON ou parfois en XML.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut d&#x27;abord s&#x27;authentifier, souvent avec OAuth.</li>
<li class="nx-my-2">Et ensuite il faut étudier la documentation du provider SaaS pour savoir quel call faire.</li>
</ul>
</li>
<li class="nx-my-2">Il y a un certain nombre de difficultés.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Chaque provider va <strong>designer son API selon ses contraintes</strong>. Et donc si on veut supporter de nombreux providers, il va falloir adapter l&#x27;<em>ingestion layer</em> pour chacun d&#x27;entre eux.</li>
<li class="nx-my-2">Chaque provider va fournir soit du <strong>full data export</strong> soit de l&#x27;<strong>incremental data export</strong>, et parfois les deux.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le <em>full data export</em> consiste à obtenir une liste d&#x27;objets, puis à aller chercher les données pour chacun d&#x27;entre eux.</li>
<li class="nx-my-2">L&#x27;<em>incremental data export</em> consiste à obtenir une liste d&#x27;objets qui ont changé entre deux timestamps qu&#x27;on fournit, pour ensuite aller chercher leurs données récentes uniquement.</li>
</ul>
</li>
<li class="nx-my-2">Le <em style="color:#3d85c6;font-weight:bold;font-style:normal">JSON</em> reçu est en général <strong>imbriqué sur plusieurs niveaux</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Certains <em>data warehouses</em> gèrent les données imbriquées, mais ce n&#x27;est pas le cas de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Redshift</em> pour lequel il faudra faire une étape de processing pour mettre ces données à plat.</li>
<li class="nx-my-2">De manière générale, mettre les données à plat dans plusieurs tables plus petites est plus pratique pour les data scientists.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Etant donné la difficulté à implémenter et maintenir une pipeline ingérant de la donnée de sources SaaS, les auteurs conseillent de <strong>bien réfléchir à l&#x27;implémenter soi-même</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">S&#x27;il s&#x27;agit d&#x27;une source pas trop compliquée, ça peut passer.</li>
<li class="nx-my-2">Si par contre il s&#x27;agit de nombreuses sources, alors il nous faudra une grande quantité de code et de maintenance.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les auteurs conseillent plutôt une solution off-the-shelf comme <strong>Fivetran</strong> qui supporte la plupart des sources SaaS connues.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant les <strong>metadata techniques à garder</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s&#x27;agit du même type de metadata que pour les sources en batch comme les DBs ou les fichiers.</li>
<li class="nx-my-2">On voudra notamment :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le nom de la source.</li>
<li class="nx-my-2">Le nom de l&#x27;objet qu&#x27;on va chercher dans la source.</li>
<li class="nx-my-2">Les temps de début et fin d&#x27;ingestion.</li>
<li class="nx-my-2">Le nombre de rows qu&#x27;on récupère.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Pour des questions de <strong>sécurité</strong>, il est préférable d&#x27;encapsuler notre cloud data platform dans un <strong>virtual private cloud (VPC)</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Pour faire le lien entre la plateforme dans le VPC et la donnée qu&#x27;on veut aller chercher, on peut utiliser un <strong>VPN Gateway</strong>, qui permet de passer par internet de manière sécurisée.</li>
<li class="nx-my-2">Dans le cas des SaaS comme source, ils fournissent des APIs sécurisées par HTTPS, et disponibles globalement sur internet, donc il n&#x27;est pas nécessaire d&#x27;établir une connexion via <em>VPN Gateway</em>.</li>
<li class="nx-my-2">Dans le cas où on veut transférer des centaines de GB par jour, il vaut mieux mettre en place une <strong>connexion directe</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les solutions cloud-natives ont leur outil de connexion directe : <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Direct Connect</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure ExpressRoute</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Cloud Interconnect</em>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">5 - Organizing and processing data<a href="#5---organizing-and-processing-data" id="5---organizing-and-processing-data" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les architectes de l&#x27;ancienne école ont encore tendance à recommander de <strong>faire le processing dans le data warehouse</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les auteurs du livre suggèrent que la manière moderne est de le faire <strong>sur des machines à part</strong>, par exemple avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>, qui lirait et écrirait dans le <em>data lake</em>.</li>
<li class="nx-my-2">Les arguments sont les suivants ((1) pour faire le calcul dans le <em>data warehouse</em>, et (2) pour utiliser la <em>layered architecture</em>) :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Flexibility</strong> : avec la (1) le résultat du processing n&#x27;est utilisable que dans le <em>data warehouse</em>, avec la (2) on peut facilement le rediriger ailleurs.</li>
<li class="nx-my-2"><strong>Developer productivity</strong> : il y a plus de personnes qui connaissent le SQL, donc le (1) a un avantage court terme, bien que <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> soit plus puissant, il faut souvent former les devs.</li>
<li class="nx-my-2"><strong>Data governance</strong> : la source principale étant le <em>data lake</em>, faire les transformations au même endroit permet d&#x27;être sûr d&#x27;avoir toutes les versions alignées. Dans le cas où on fait ça dans le <em>data warehouse</em>, il est préférable de ne pas le faire dans le <em>data lake</em> pour ne pas avoir de divergence.</li>
<li class="nx-my-2"><strong>Cross-platform portability</strong> : changer de cloud vendor est bien plus simple avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> qu&#x27;avec du code SQL qu&#x27;il faudra au moins tester.</li>
<li class="nx-my-2"><strong>Performance</strong> : avec la (1) le processing impacte le <em>data warehouse</em>, avec le (2) on fait le calcul complètement à part et on n&#x27;impacte personne.</li>
<li class="nx-my-2"><strong>Speed of processing</strong> : avec la (1) on peut faire du <em>real time analytics</em> dans certains cas avec difficulté, avec la (2) ça marche facilement.</li>
<li class="nx-my-2"><strong>Cost</strong> : tous les providers de <em>data warehouse</em> ne le font pas (mais ils vont finir par le faire), mais pour ceux qui font payer le processing ça revient plus cher que de faire le processing sur des machines complètement à part.</li>
<li class="nx-my-2"><strong>Reusability</strong> : avec la (1) on peut parfois utiliser des <em>stored procedures</em>, avec la (2) on a du code qu&#x27;on peut directement réutiliser.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Le processing se décompose en <strong>stages</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Chaque <em>stage</em> contient : une <em>area</em> de stockage dans le <em>data lake</em>, et un job de calcul distribué (par exemple avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>), qui va créer la donnée pour l&#x27;étape suivante.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les jobs sont coordonnés par l&#x27;<em>orchestration layer</em>.</li>
<li class="nx-my-2">Les jobs peuvent être de deux types :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Common</strong> data processing : les transformations communes, par exemple dédupliquer les messages, valider les dates etc.</li>
<li class="nx-my-2"><strong>Business logic specific</strong> processing : les transformations spécifiques à chaque use-case, qui vont par exemple filtrer les campagnes de marketing à succès uniquement si le use-case c&#x27;est d&#x27;afficher les meilleures campagnes.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Avoir un ensemble de <em>stages</em> standardisés est important pour que chacun puisse s&#x27;y retrouver malgré le scale.</li>
<li class="nx-my-2">Les étapes proposés par les auteurs sont :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>1 - Landing area</strong> : c&#x27;est là que la donnée arrive en premier, il ne s&#x27;agit pas d&#x27;un stockage long terme.</li>
<li class="nx-my-2"><strong>2 - Staging area</strong> : la donnée subit des checks basiques de qualité, et on vérifie qu&#x27;elle est conforme au schéma attendu. Elle est stockée sous format <em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em>.</li>
<li class="nx-my-2"><strong>3 - Archive area</strong> : la donnée est copiée depuis la <em>landing area</em> vers l&#x27;<em>archive area</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Cette opération n&#x27;est effectuée qu&#x27;après que la donnée ait pu aller vers la <em>staging area</em> avec succès.</li>
<li class="nx-my-2">On pourra refaire le processing de la donnée simplement en la copiant depuis l&#x27;<em>archive area</em> vers la <em>landing area</em>.</li>
</ul>
</li>
<li class="nx-my-2"><strong>4 - Production area</strong> : la donnée subit la transformation business nécessaire pour un use-case particulier avant d&#x27;aller là.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Elle est aussi transformée du format <em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em> vers <em style="color:#3d85c6;font-weight:bold;font-style:normal">Parquet</em>, qui est plus adapté pour faire de l&#x27;analytics.</li>
<li class="nx-my-2"><strong>4.1 - Pass-through job</strong> : il s&#x27;agit d&#x27;un job qui copie la donnée de la <em>staging area</em> vers la <em>production area</em> sans transformation autre que le format <em style="color:#3d85c6;font-weight:bold;font-style:normal">Parquet</em>, et ensuite la copie dans le <em>data warehouse</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ce use-case “basique” est utile pour débugguer les autres use-cases.</li>
</ul>
</li>
<li class="nx-my-2"><strong>4.2 - Cloud data warehouse and production area</strong> : les use-cases qui ont besoin de la donnée dans le <em>data warehouse</em> passent d&#x27;abord par le processing de la <em>staging area</em> vers la <em>production area</em>.</li>
</ul>
</li>
<li class="nx-my-2"><strong>5 - Failed area</strong> : chaque étape peut faire face à des erreurs, qu&#x27;elles soient liées à la donnée ou à des échecs temporaires de la pipeline.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les messages qui n&#x27;ont pas réussi une étape vont dans cette area où on pourra les examiner et voir ce qu&#x27;il faut corriger.</li>
<li class="nx-my-2">Une fois la correction faite, il suffit de les copier dans l&#x27;area de l&#x27;étape où ils ont échoués.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Chaque <strong>area</strong> doit être dans un <strong>container</strong> du service de stockage de notre cloud provider.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les <em>containers</em> contiennent des <em>folders</em>.</li>
<li class="nx-my-2">Ils sont appelés <em>buckets</em> chez AWS et GCP.</li>
<li class="nx-my-2">C&#x27;est au niveau de ces containers qu&#x27;on peut configurer les droits d&#x27;accès, et choisir le prix qu&#x27;on paye pour les performances qu&#x27;on aura (hot / cold / archive storage).<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Parmi nos 5 areas, toutes sont de type <em>hot</em>, sauf l&#x27;archive area qui peut être <em>cold</em> / <em>archive</em>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">On a besoin d&#x27;une <strong>organisation des folders</strong> claire dans chaque <em>area</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les éléments communs sont :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le <strong>namespace</strong> représente la catégorisation la plus high level, pour les petites organisations ça peut être juste le nom de l&#x27;organisation, mais pour les plus grandes ça peut être le nom du département.</li>
<li class="nx-my-2">Le <strong>pipeline name</strong> représente le nom d&#x27;un job en particulier. Il faut qu&#x27;il soit clair par rapport à ce que fait le job, et utilisé partout pour parler de lui.</li>
<li class="nx-my-2">Le <strong>data source name</strong> identifie une source. C&#x27;est l&#x27;<em>ingestion layer</em> qui choisit ce nom et le note dans le <em>metadata layer</em>.</li>
<li class="nx-my-2">Le <strong>batchId</strong> représente l&#x27;identifiant de chaque batch de donnée écrit dans la <em>landing area</em> par l&#x27;<em>ingestion layer</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut utiliser un UUID pour le représenter, ou encore un ULID, qui a la particularité d&#x27;être plus court et de permettre de savoir facilement si un autre ULID est plus grand ou plus petit.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Pour la <em>landing area</em>, les auteurs proposent la folder structure :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">landing/NAMESPACE/PIPELINE/SOURCE_NAME/BATCH_ID/</code>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em>landing</em> représente le nom du container.</li>
</ul>
</li>
<li class="nx-my-2">Exemple : <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">/landing/my_company/sales_oracle_ingest/customers/01DFTQ028FX89YDFAXREPJTR94/</code></li>
</ul>
</li>
<li class="nx-my-2">Pour la <em>staging area</em>, de même que pour les autres <em>areas</em>, il s&#x27;agit de stocker la donnée sur le long terme, donc on aimerait une structure qui fasse apparaître le <strong>temps</strong>, avec 3 folders supplémentaires :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s&#x27;agit d&#x27;ajouter 3 folders supplémentaires qui viennent de la convention de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Hadoop</em> : <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">year=YYYY/month=MM/day=DD</code>.</li>
<li class="nx-my-2">Exemple : <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">/staging/my_company/sales_oracle_ingest/customers/year=2019/month=07/day=03/01DFTQ028FX89YDFAXREPJTR94/</code></li>
<li class="nx-my-2">De nombreux outils (y compris <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>) vont reconnaître ce format, et si notre batchId est un ULID, les folders les plus récents seront présentés en premier.</li>
</ul>
</li>
<li class="nx-my-2">Pour la <em>production area</em>, on ne peut pas vraiment reporter les sources qui ont servi à la donnée dans le folder name - il y en a potentiellement des dizaines.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On va donc plutôt créer des <strong>sources dérivées</strong> dont on mettra le nom à la place de la source, et on documentera ces sources dérivées dans le <em>metadata layer</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">La donnée qui arrive en <strong>streaming</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Va passer directement vers la version streaming du <em>processing layer</em> sans être stockée d&#x27;abord dans le <em>slow storage</em>. C&#x27;est traité au chapitre 6.</li>
<li class="nx-my-2">Mais on va quand même l&#x27;envoyer dans le slow storage en parallèle pour un but d&#x27;archivage et rejeu si besoin.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Un job va lire depuis le fast storage où arrive la donnée en streaming, par batchs suffisamment gros, et va écrire ça dans la <em>landing area</em>.</li>
<li class="nx-my-2">Les fichiers seront ensuite passés de stage en stage jusqu&#x27;à la production area.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Parmi les <strong>common processing steps</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>File format conversion.</strong>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L&#x27;approche <em>data lake</em> traditionnelle consiste à laisser les données telles quelles, et laisser chaque pipeline parser elle-même la donnée et faire les traitements dont elle a besoin.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Mais cette approche a du mal à scaler.</li>
<li class="nx-my-2">Dans la <em>cloud data platform architecture</em>, on choisit de faire certains traitements en amont, pour éviter d&#x27;avoir à tester et maintenir du code qui fait ça dans chaque pipeline.</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Parquet</em> sont des formats binaires intégrant un schéma.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ils permettent de ne pas répéter le nom des champs, et donc d&#x27;économiser de la place.</li>
<li class="nx-my-2">Ils permettent de garantir le schéma de la donnée.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em> est organisé en blocs de <em>rows</em>, alors que <em style="color:#3d85c6;font-weight:bold;font-style:normal">Parquet</em> est organisé en blocs de <em>columns</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les fichiers organisés en <em>rows</em> sont utiles quand on lit la donnée de toutes les colonnes pour certains <em>rows</em> donnés. La <em>staging area</em> sert principalement à faire des transformations ou de l&#x27;exploration ad-hoc, donc <em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em> est adapté.</li>
<li class="nx-my-2">Les fichiers organisés en <em>columns</em> sont utiles quand on ne veut traiter qu&#x27;une <em>column</em> sur un grand nombre de <em>rows</em>. La production area sert à faire des requêtes d&#x27;analytics, donc <em style="color:#3d85c6;font-weight:bold;font-style:normal">Parquet</em> est adapté.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Pour la conversion depuis le format initial vers <em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em>, puis vers <em style="color:#3d85c6;font-weight:bold;font-style:normal">Parquet</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> permet de lire et écrire ces différents formats.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Exemple :<!-- -->
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="python" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="python" data-theme="default"><span class="line"><span style="color:var(--shiki-color-text)">clicks_df </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> spark</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-color-text)">read</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">json</span><span style="color:var(--shiki-token-punctuation)">(in_path)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">clicks_df </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> spark</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-color-text)">write</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">format</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&quot;avro&quot;</span><span style="color:var(--shiki-token-punctuation)">).</span><span style="color:var(--shiki-token-function)">save</span><span style="color:var(--shiki-token-punctuation)">(out_path)</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>Data deduplication</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On s&#x27;intéresse ici au fait d&#x27;avoir un attribut sur notre donnée qui soit unique dans l&#x27;ensemble des données.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">A partir du moment où on n&#x27;a pas de garanties d&#x27;unicité, on peut se retrouver dans une situation de duplication, par exemple si le <em>metadata repository</em> est corrompu, si la source envoie une donnée dupliquée, ou encore si un dev rejoue certaines données qui avaient déjà marché.</li>
<li class="nx-my-2">Le problème existe aussi avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em>, où des transactions existent si on lit un record et qu&#x27;on écrit dans un topic <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em>, mais pas si on écrit sur un service de storage.</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> a une fonction intégrée <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">dropDuplicates()</code> qui permet de dédupliquer en fonction d&#x27;une ou plusieurs colonnes.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut dédupliquer sur un batch qui arrive dans la <em>landing area</em> pour pas cher :<!-- -->
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="python" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="python" data-theme="default"><span class="line"><span style="color:var(--shiki-color-text)">users_df </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> spark</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-color-text)">read</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">format</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&quot;csv&quot;</span><span style="color:var(--shiki-token-punctuation)">).</span><span style="color:var(--shiki-token-function)">load</span><span style="color:var(--shiki-token-punctuation)">(in_path)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">users_deduplicate_df </span><span style="color:var(--shiki-token-keyword)">=</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">  users_df</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">dropDuplicates</span><span style="color:var(--shiki-token-punctuation)">([</span><span style="color:var(--shiki-token-string-expression)">&quot;user_id&quot;</span><span style="color:var(--shiki-token-punctuation)">])</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
<li class="nx-my-2">Si on veut vraiment dédupliquer sérieusement, il faut aussi joindre l&#x27;ensemble des données déjà présentes dans la <em>staging area</em> au batch courant, et appliquer la déduplication dessus, par exemple avec du SQL qu&#x27;on passe à <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>.<!-- -->
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="python" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="python" data-theme="default"><span class="line"><span style="color:var(--shiki-color-text)">incoming_users_df</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">  </span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">createOrReplaceTempView</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&quot;incomgin_users&quot;</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">staging</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-color-text)">users_df</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">  </span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">createOrReplaceTempView</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&quot;staging_users&quot;</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">users_deduplicate_df </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> spark</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">sql</span><span style="color:var(--shiki-token-punctuation)">(</span></span>
<span class="line"><span style="color:var(--shiki-token-punctuation)">  </span><span style="color:var(--shiki-token-string-expression)">&quot;SELECT * FROM incoming_users u1</span></span>
<span class="line"><span style="color:var(--shiki-token-punctuation)">  LEFT JOIN staging_users u2</span></span>
<span class="line"><span style="color:var(--shiki-token-punctuation)">  ON u1.user_id </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-token-punctuation)"> u2.user_id</span></span>
<span class="line"><span style="color:var(--shiki-token-punctuation)">  WHERE u2.user_id IS NULL</span><span style="color:var(--shiki-token-string-expression)">&quot;</span></span>
<span class="line"><span style="color:var(--shiki-token-punctuation)">)</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
<li class="nx-my-2">Le problème c&#x27;est que la déduplication à chaque fois avec l&#x27;ensemble des données coûte cher. Donc il faut vérifier que notre use-case le nécessite d&#x27;un point de vue business.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut aussi dédupliquer avec seulement les fichiers dans le dossier de l&#x27;année actuelle, du mois actuel etc. depuis la <em>staging area</em>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>Data quality checks</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Une vérification minimale de la qualité de la donnée est en général nécessaire pour la plupart des cas d&#x27;usages. Par exemple :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La longueur de certaines colonnes.</li>
<li class="nx-my-2">La valeur numérique acceptable de certaines colonnes.</li>
<li class="nx-my-2">Le fait d&#x27;avoir certaines colonnes “obligatoires”.</li>
<li class="nx-my-2">Le fait d&#x27;avoir certaines colonnes respecter un pattern, par exemple l&#x27;email.</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> a la fonction <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">filter()</code> qui permet d&#x27;obtenir les colonnes qui respectent une mauvaise condition.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On a aussi <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">subtract()</code> qui permet d&#x27;enlever ces rows du batch, pour passer les rows valides à la <em>production area</em>, et les rows invalides à la <em>failed area</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Attention à la <strong>consistance des données</strong>, en fonction du contexte business, il peut être plus judicieux de laisser passer la donnée, et de simplement informer les data engineers du problème.</li>
<li class="nx-my-2">De manière générale, il faut réfléchir à <strong>la criticité de chaque problème de qualité</strong> pour décider quoi faire en cas de donnée malformée : filtrer la donnée, laisser passer et prévenir quelqu&#x27;un, ou annuler l&#x27;ingestion du batch entier.</li>
</ul>
</li>
<li class="nx-my-2">Exemple :<!-- -->
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="python" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="python" data-theme="default"><span class="line"><span style="color:var(--shiki-color-text)">users_df </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> spark</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-color-text)">read</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">format</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&quot;csv&quot;</span><span style="color:var(--shiki-token-punctuation)">).</span><span style="color:var(--shiki-token-function)">load</span><span style="color:var(--shiki-token-punctuation)">(in_path)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">bad_user_rows </span><span style="color:var(--shiki-token-keyword)">=</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">  users_df</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">filter</span><span style="color:var(--shiki-token-punctuation)">(</span></span>
<span class="line"><span style="color:var(--shiki-token-punctuation)">    </span><span style="color:var(--shiki-token-string-expression)">&quot;length(email) &gt; 100 OR username IS NULL&quot;</span></span>
<span class="line"><span style="color:var(--shiki-token-punctuation)">  )</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">users_df </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> users_df</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">subtract</span><span style="color:var(--shiki-token-punctuation)">(bad_user_rows)</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">On peut créer des <strong>jobs configurables</strong> : l&#x27;orchestration layer lance un job, en lui donnant d&#x27;abord la configuration contenant les sources à traiter, le schéma à valider en fonction des sources, la folder structure où insérer les nouveaux fichiers etc.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ça permet d&#x27;économiser du code, au moins pour les jobs de transformation “common”.</li>
<li class="nx-my-2">Le bon endroit pour la configuration c&#x27;est le <em>metadata layer</em>.</li>
<li class="nx-my-2">Pour déclencher nos jobs, il faut qu&#x27;il y ait une forme de monitoring de la <em>landing area</em>, soit avec du code qu&#x27;on écrit nous-mêmes, soit avec la fonctionnalité de monitoring d&#x27;un outil d&#x27;orchestration cloud.</li>
</ul>
</li>
</ul>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">6 - Real-time data processing and analytics<a href="#6---real-time-data-processing-and-analytics" id="6---real-time-data-processing-and-analytics" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La notion de <strong>real-time</strong> (ou <strong>streaming</strong>) dans le contexte d&#x27;une pipeline data peut recouvrir deux choses différentes :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>1 - real-time ingestion</strong> : on ingère la donnée une par une avec un mécanisme de message streaming, et on l&#x27;amène jusqu&#x27;au <em>data warehouse</em>. Mais la consommation de la donnée ne se fait pas en temps réel.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L&#x27;aspect “real-time” ne concerne que l&#x27;<em>ingestion layer</em>.</li>
<li class="nx-my-2"><strong>Le processing se fait à la demande, et peut prendre des secondes voire des minutes</strong>, mais il se fait sur une donnée fraîche.</li>
<li class="nx-my-2">Il peut se faire selon un schedule, ou à la demande des utilisateurs humains qui attendront un peu avant d&#x27;avoir un résultat.</li>
<li class="nx-my-2">Exemple : un data analyste veut pouvoir exécuter une requête pour afficher un dashboard sur des données fraîches quand il en a besoin. Le dashboard n&#x27;est pas mis à jour en continu mais juste à l&#x27;exécution de cette requête.</li>
</ul>
</li>
<li class="nx-my-2"><strong>2 - real-time processing</strong> : on récupère la donnée une par une, et on la redirige vers un autre système qui va réagir à chaque donnée qui arrive pour se mettre à jour.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le <em>real-time processing</em> nécessite la <em>real-time ingestion</em>. L&#x27;aspect “real-time” concerne donc l&#x27;<em>ingestion layer</em> et le <em>processing layer</em>.</li>
<li class="nx-my-2">On est dans un cas d&#x27;usage où on a besoin que <strong>le processing se fasse très vite et en continu</strong>, en général à destination d&#x27;un autre système.</li>
<li class="nx-my-2">Exemple : la donnée qui arrive dans la pipeline est ensuite mise à disposition d&#x27;un système de jeu vidéo pour adapter le comportement du jeu en fonction de ce que fait le joueur en temps réel. Par exemple, ajuster la probabilité de faire apparaître un monstre.</li>
<li class="nx-my-2">La donnée est traitée par un <strong>real-time job</strong> qui tourne en permanence et ajuste les calculs en fonction des nouvelles données.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Elle est ensuite mise à disposition d&#x27;un <em>key/value store</em> ou éventuellement d&#x27;une DB relationnelle, pour un accès rapide. Le <em>data warehouse</em> est trop lent et est fait pour des requêtes à la demande sur de grandes quantités de données.</li>
<li class="nx-my-2">Elle peut aussi être postée dans le <em>fast storage</em>, c&#x27;est-à-dire comme event de streaming pour déclencher un autre processing.</li>
<li class="nx-my-2">C&#x27;est parce que ce job tourne en continu avec des choses chargées en RAM qu&#x27;il donne un résultat rapide, contrairement à une requête SQL dans un <em>data warehouse</em> par exemple, qui ne se déclenche qu&#x27;au moment où on la lance.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Il est très important de <strong>clarifier le besoin</strong> : dans le cas où on n&#x27;a besoin que de <em>real-time ingestion</em>, la complexité de mise en œuvre est beaucoup moins grande.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les auteurs conseillent d&#x27;utiliser la <em>real-time ingestion</em> plutôt que la <em>batch ingestion</em>, sauf quand la source ne supporte pas le real time.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La <em>real-time ingestion</em> implique moins de nécessité d&#x27;orchestration et de monitoring.</li>
<li class="nx-my-2">Pour éviter l&#x27;incohérence pour les utilisateurs, il vaut mieux éviter de mixer des données real-time avec des données qui viennent en batch.</li>
<li class="nx-my-2">On n&#x27;a en général pas la possibilité d&#x27;utiliser le même système pour traiter les données qui arrivent en real-time et les données qui arrivent par batch.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Cloud Dataflow</em> le permet avec l&#x27;utilisation de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Beam</em>, mais la plupart du temps on aura besoin de deux outils.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Selon les auteurs, la plupart du temps quand les utilisateurs demandent du “real-time”, ils veulent en fait juste de la <em>real-time ingestion</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Quand des utilisateurs demandent à pouvoir afficher leur dashboard en “real-time” alors qu&#x27;il tourne une fois par jour, bien souvent avoir de la <em>real-time ingestion</em> et faire tourner le processing du rapport toutes les heures ou toutes les 15 minutes leur suffira.</li>
<li class="nx-my-2">Parmi les cas d&#x27;usage qui pourraient nécessiter du real-time processing : les systèmes d&#x27;action in-game, les systèmes de recommandation, les systèmes de détection de fraude.</li>
</ul>
</li>
<li class="nx-my-2">Transiter une pipeline de la <em>batch ingestion</em> à la real-time ingestion se fait sans trop de difficulté.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Transiter du <em>batch processing</em> au <em>real-time processing</em> est bien plus complexe vu qu&#x27;il va falloir en général changer d&#x27;outils, et donc il faut penser ça en amont.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Le <strong>fast storage</strong> est composé d&#x27;un système d&#x27;<strong>event streaming</strong> du type <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les messages (qui font entre quelques KB et 1 MB) sont traités un par un, et stockés dans des <em>topics</em>. Ils sont identifiables par leur offset.</li>
<li class="nx-my-2">Les <em>producers</em> écrivent dans les topics, et les <em>consumers</em> lisent depuis les topics. <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em> a des mécanismes qui leur permettent de publier et consommer de manière fiable malgré les fautes.</li>
<li class="nx-my-2">Pour permettre de scaler, le contenu des topics est séparé en <em>partitions</em>, qui se trouvent sur des machines différentes, avec des copies pour plus de fiabilité.</li>
<li class="nx-my-2">Là où lire et écrire dans <em style="color:#3d85c6;font-weight:bold;font-style:normal">S3</em> mettrait quelques centaines de ms, le faire dans Kafka en prend 10 fois moins, mais surtout <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em> tient la charge avec une très grande quantité de petits messages.</li>
</ul>
</li>
<li class="nx-my-2">De même que pour le <em>slow storage</em> et le <em>batch processing</em>, le <em>fast storage</em> est <strong>organisé en areas</strong> qui servent à des stages de processing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les étapes sont :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>1 - Landing area</strong> : l&#x27;<em>ingestion layer</em> écrit la donnée dans cet endroit.</li>
<li class="nx-my-2"><strong>2 - Staging area</strong> : la donnée subit des checks basiques de qualité, et on vérifie qu&#x27;elle est conforme au schéma attendu.</li>
<li class="nx-my-2"><strong>3 - Archive area</strong> : la donnée est copiée depuis la <em>landing area</em> vers l&#x27;<em>archive area</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s&#x27;agit d&#x27;espace de stockage cloud classique.</li>
<li class="nx-my-2">On pourra refaire le processing de la donnée simplement en la copiant depuis l&#x27;<em>archive area</em> vers la <em>landing area</em>.</li>
</ul>
</li>
<li class="nx-my-2"><strong>4 - Production area</strong> : la donnée subit la transformation business nécessaire pour un use-case particulier avant d&#x27;aller là.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>4.1 - Pass-through job</strong> : il s&#x27;agit d&#x27;un job qui copie la donnée de la <em>staging area</em> vers la <em>production area</em> sans transformation, et ensuite la copie dans le <em>data warehouse</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ce use-case “basique” est utile pour débugguer les autres use-cases.</li>
</ul>
</li>
<li class="nx-my-2"><strong>4.2 - Staging to production</strong> : des jobs lisent la donnée à partir de la <em>staging area</em> dans un but de reporting/analytics, et créent un dataset dans la <em>production area</em>, pour charger la donnée ensuite dans le <em>data warehouse</em> ou dans une DB relationnelle ou NoSQL.</li>
</ul>
</li>
<li class="nx-my-2"><strong>5 - Failed area</strong> : chaque étape peut faire face à des erreurs, qu&#x27;elles soient liées à la donnée ou à des échecs temporaires de la pipeline.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les messages qui n&#x27;ont pas réussi une étape vont dans cette area où on pourra les examiner et voir ce qu&#x27;il faut corriger.</li>
<li class="nx-my-2">Une fois la correction faite, il suffit de les copier dans l&#x27;area de l&#x27;étape où ils ont échoués.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Côté <strong>organisation en topics</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les providers limitent en général le nombre de topics à quelques milliers, et c&#x27;est l&#x27;abstraction principale qu&#x27;on a. Avec des centaines de tables par DB qu&#x27;on utilise comme source, les topics sont vite très nombreux.</li>
<li class="nx-my-2">Selon les auteurs, l&#x27;organisation la plus pertinente pour le cas général serait d&#x27;utiliser <strong>un topic par area</strong>, et de faire la distinction entre sources avec un champ à l&#x27;intérieur des messages.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Mais dans le cas où on a des sources qui donnent des messages structurés très différemment, ou qui ne permettent pas d&#x27;utiliser des jobs de processings communs, on peut faire des topics différents par source.</li>
<li class="nx-my-2">Une autre raison de séparer en topics par source peut être la limitation en termes de quotas par topic, de la part du provider.</li>
<li class="nx-my-2">Une autre raison pour publier dans des topics différents peut être la structure interne des équipes, et les questions de sécurité, pour restreindre certaines données à certaines équipes.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Pour rendre les jobs configurables, on peut faire en sorte qu&#x27;ils lisent le contenu du message et appellent une librairie qui va faire quelque chose de particulier en fonction de la valeur lue.</li>
</ul>
</li>
<li class="nx-my-2">Parmi les transformations qu&#x27;on a couramment dans les systèmes real-time, il y a la <strong>déduplication des messages</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les duplications sont courantes dans les systèmes real-time, elles ont deux origines :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - Des duplications issues de la source, sur lesquelles on n&#x27;a pas de contrôle.</li>
<li class="nx-my-2">2 - Des duplications qui sont dues au fonctionnement des systèmes real-time, et à leur nature distribuée.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut par exemple avoir un producer qui envoie un message, mais ne reçoit pas l&#x27;acknowledgement à cause d&#x27;un problème réseau. Un autre broker sera élu master de la partition et on se retrouvera avec une duplication.</li>
<li class="nx-my-2">Côté consumer, il suffit que l&#x27;un d&#x27;entre eux envoie un message et crash avant de commiter. Il va alors renvoyer le même message quand il reviendra à la vie.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">La difficulté pour dédupliquer avec les systèmes real-time c&#x27;est qu&#x27;on a une donnée qui arrive en permanence, et qui est distribuée sur plusieurs machines.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Une solution peut être d&#x27;utiliser une <strong>time window</strong> : on choisit un début et une fin de timestamp, et on récupère tous les messages correspondants pour faire une déduplication parmi eux.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut avoir par exemple une <em>sliding window</em> qui se déplace dans le temps, ou <em>tumbling window</em> qui va diviser le temps en tranches disjointes.</li>
<li class="nx-my-2">Le problème c&#x27;est qu&#x27;on est limités sur la tranche de temps qu&#x27;une machine peut traiter, et la déduplication ne se fait que pour les messages de cette tranche, et pas avec les autres tranches.</li>
</ul>
</li>
<li class="nx-my-2">Une autre solution est d&#x27;avoir un <strong>key/value cache</strong> dans lequel on met l&#x27;ID de chaque message traité, et qu&#x27;on réinterroge à chaque fois pour éviter de le retraiter encore.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La taille va rarement être un problème : stocker 1 milliard de UUID fait ~15 Go.</li>
<li class="nx-my-2">Par contre il faut que le store soit <em>highly available</em> et performant, donc une solution cloud est bien adaptée.</li>
<li class="nx-my-2">Exemples de key/value stores : <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Cosmos DB</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Cloud Bigtable</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS DynamoDB</em>.</li>
</ul>
</li>
<li class="nx-my-2">Une 3ème solution peut être de laisser les messages dupliqués jusqu&#x27;au <em>data warehouse</em>, et dédupliquer ensuite par <strong>un job en mode batch</strong>, soit dans le <em>data lake</em>, soit dans le <em>data warehouse</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ca permet d&#x27;avoir une real-time ingestion particulièrement rapide, mais il faut que la duplication soit OK dans un premier temps.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Une autre transformation courante est la <strong>conversion de format</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les messages dans le système real-time sont consommés un par un, donc il est capital d&#x27;avoir des schémas bien définis entre producers et consumers. Le <em>metadata layer</em> pourra nous aider à le stocker.</li>
<li class="nx-my-2">Concernant le format :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">JSON ne fournit pas de mécanisme de gestion de schéma, et est plus volumineux. Il peut être compressé, mais ce serait surtout efficace avec plusieurs messages où des noms de champ se répètent par exemple.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em> permet de <strong>minimiser la taille du message</strong>, et permet une gestion du schéma avec la possibilité de le stocker dans un store.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Parquet</em> <strong>n&#x27;apporte aucun avantage</strong> dans un système real-time puisque son but est de permettre de lire de grandes quantités de données pour faire du processing dessus, et qu&#x27;on est ici sur du message par message.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant les <strong>quality checks</strong>, on peut avoir un job qui vérifie la qualité de chaque message avant de le placer dans l&#x27;area du stage suivant ou dans la <em>failed area</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Dans le cas où on a de nombreuses sources gérées par plusieurs équipes, la difficulté va surtout être dans la définition de ce qu&#x27;est une donnée avec une qualité suffisante.</li>
<li class="nx-my-2">Nos <em>quality checks</em> peuvent impliquer de vérifier une caractéristique impliquant plusieurs messages, par exemple “pas plus de 10% des commandes avec le statut cancelled”.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faudra alors utiliser les techniques de <em>windowing</em> comme avec la déduplication.</li>
<li class="nx-my-2">Si la durée sur laquelle on veut faire les checks est trop grande par rapport à ce que supportent nos outils, il faudra faire passer le flow par le batch processing.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Dans le cas où on veut <strong>combiner une source de données real-time et une source batch</strong>, on peut :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - Avoir le job real-time qui lit le message batch à combiner avec les données du message real-time, et qui le stocke dans sa RAM.</li>
<li class="nx-my-2">2 - Puis ce job combine les deux pour les mettre dans la real-time production area.</li>
<li class="nx-my-2">3 - Et il continue avec les messages suivants en utilisant le message batch qui est dans sa RAM, jusqu&#x27;à ce qu&#x27;il y en ait un nouveau.</li>
<li class="nx-my-2">La limitation pourrait être la taille du message batch : s&#x27;il ne rentre pas dans la ram des VMs qui font le real-time processing, on peut fallback sur du batch processing.</li>
</ul>
</li>
<li class="nx-my-2">Les <strong>3 cloud vendors principaux</strong> fournissent chacun deux outils pour le real-time processing : un outil de real-time storage type <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em>, et un outil qui fait le real-time processing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>AWS</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Kinesis Data Streams</em> est équivalent à <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il fournit des clients dans 5 langages, dont Node.js.</li>
<li class="nx-my-2">Il a l&#x27;équivalent des topics sous le nom de <em>Data Streams</em>.</li>
<li class="nx-my-2">Il a l&#x27;équivalent des partitions sous le nom de <em>shard</em>, et limite la throughput à 1 MB/s par shard.</li>
<li class="nx-my-2">Il supporte le “resharding” à la hausse ou à la baisse.</li>
<li class="nx-my-2">Il limite la taille des records à 1 MB.</li>
<li class="nx-my-2">La rétention par défaut est d&#x27;un jour, et va jusqu&#x27;à une semaine.</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Kinesis Data Analytics</em> est l&#x27;outil de processing real-time.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il fournit une API SQL pour créer les jobs, mais c&#x27;est limité à des records qui contiendront du CSV ou du JSON.</li>
<li class="nx-my-2">Il fournit aussi une API Java, qui utilise <em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Flink</em> et permet plus de flexibilité sur le format des records.</li>
<li class="nx-my-2">Il ne fournit pas de mécanisme de déduplication.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>GCP</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Cloud Pub/Sub</em> est un peu différent de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em> et il abstrait plus de choses.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il fournit des clients dans 7 langages, dont Node.js.</li>
<li class="nx-my-2">Les <em>topics</em> permettent de regrouper les records, mais il n&#x27;y a <strong>pas de notion de partition</strong>, ou en tout cas elle est abstraite derrière l&#x27;API.</li>
<li class="nx-my-2">Les consumers peuvent faire une <em>subscription</em> à un topic pour consommer les records.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ils peuvent aussi utiliser une <em>subscription</em> pour recevoir de la donnée combinée de plusieurs <em>topics</em>.</li>
<li class="nx-my-2">On se sert aussi des subscriptions pour scaler le throughput : on a le droit à 1 MB/s par subscription.</li>
</ul>
</li>
<li class="nx-my-2">Les records sont limités à 10 MB.</li>
<li class="nx-my-2">La rétention des données maximale est d&#x27;une semaine.</li>
<li class="nx-my-2">Il ne fournit pas d&#x27;offsets pour les records, ce qui limite la possibilité de rejouer certains messages particuliers.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut faire des <em>snapshots</em> pour pouvoir les rejouer, mais ils sont limités à 5000 par projet.</li>
<li class="nx-my-2">On a aussi la possibilité de rejouer par timestamp, mais c&#x27;est peu précis.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Cloud Dataflow</em> est l&#x27;outil de processing real-time.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il fournit une API SQL pour créer les jobs, mais c&#x27;est limité à des records qui contiendront du JSON.</li>
<li class="nx-my-2">Il fournit aussi une API Java et Python, qui utilise <em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Beam</em> et permet plus de flexibilité sur le format des records.</li>
<li class="nx-my-2">Il permet de dédupliquer les messages issus de problèmes techniques, et propose aussi une déduplication des messages par ID, sur une fenêtre de 10 minutes.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>Azure</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Event Hubs</em> est équivalent à <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il fournit des clients en .NET et Python, mais des versions open source sont disponibles pour d&#x27;autres langages.</li>
<li class="nx-my-2"><strong>Il supporte 3 protocoles pour s&#x27;y intégrer</strong> en tant que producer ou consumer : HTTPS, AMQP et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em>. Ça permet de migrer vers Azure sans avoir à tout réécrire.</li>
<li class="nx-my-2">Il a l&#x27;équivalent des topics dans le cas de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em>, ou des hubs dans le cas d&#x27;AMQP.</li>
<li class="nx-my-2">Il a l&#x27;équivalent des partitions, qu&#x27;il faut définir à l&#x27;avance comme pour <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em>, et à l&#x27;inverse de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kinesis Data Streams</em> pour lequel on peut “resharder”.</li>
<li class="nx-my-2">Le throughput est limité à 1 MB/s ou 1000 messages/s par partition.</li>
<li class="nx-my-2">Les records ne peuvent pas dépasser 1 MB.</li>
<li class="nx-my-2">La période de rétention maximale est d&#x27;une semaine.</li>
<li class="nx-my-2">Contrairement à <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kinesis Data Streams</em> qui stocke les offsets des consumers dans <em style="color:#3d85c6;font-weight:bold;font-style:normal">DynamoDB</em>, ou à <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em> qui le stocke dans un topic interne, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Event Hubs</em> laisse cette responsabilité aux consumers.</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Stream Analytics</em> est l&#x27;outil de processing real-time.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il ne propose qu&#x27;une API SQL, avec des fonctionnalités avancées de type windowing, recherche dans des dictionnaires etc.</li>
<li class="nx-my-2">Si on veut plus de flexibilité, on peut utiliser <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> à travers <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Databricks</em>, mais il s&#x27;agira de micro-batching et non pas de vrai streaming.</li>
<li class="nx-my-2">Il ne fournit pas de fonctionnalités de déduplication.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">7 - Metadata layer architecture<a href="#7---metadata-layer-architecture" id="7---metadata-layer-architecture" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il existe deux types de metadata dans le cadre de la data.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - La <strong>business metadata</strong> permet de <strong>donner du contexte</strong> à la donnée.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ca peut être par exemple : la source, le propriétaire de la donnée, la date de sa création, la taille de la donnée, le but de la donnée, son niveau de qualité etc.</li>
<li class="nx-my-2">Ça aide notamment à trouver la donnée qu&#x27;on cherche.</li>
<li class="nx-my-2">On appelle souvent l&#x27;outillage autour de la business metadata le <strong>data catalog</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les cloud vendors ont chacun leur outil : <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Cloud Data Catalog</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Data Catalog</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Glue Data Catalog</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">2 - La <strong>data platform metadata</strong> (ou <em>pipeline metadata</em>) permet de rassembler des informations sur les pipelines de données.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ça peut être des informations sur les sources, sur le succès ou l&#x27;échec de runs de pipelines, les erreurs qui ont eu lieu etc.</li>
<li class="nx-my-2">Ça permet notamment le <strong>monitoring et la configuration des pipelines</strong>.</li>
<li class="nx-my-2">Cette metadata est plus alignée avec la responsabilité des data engineers, et c&#x27;est sur elle que se concentre ce livre.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Une seule pipeline simple peut être gérée avec du code, mais dès que le système de pipelines se complexifie, il faut <strong>gérer cette complexité</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On a le choix de :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - <strong>Dupliquer le code des pipelines</strong> pour les rendre simples, mais alors il faudra refaire des modifications à plusieurs endroits à chaque fois qu&#x27;on voudra changer quelque chose qui concerne plusieurs pipelines.</li>
<li class="nx-my-2">2 - <strong>Mettre du code en commun</strong> pour éviter de réécrire trop de choses, mais alors la codebase se complexifie, et l&#x27;investigation des problèmes aussi.</li>
</ul>
</li>
<li class="nx-my-2">Les auteurs du livre conseillent de mettre le code en commun, et de <strong>rendre les pipelines configurables</strong> pour éviter l&#x27;explosion de complexité.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On pourra par exemple mettre en commun l&#x27;ingestion de sources de type RDBMS, et celles de type file. Ou encore mettre en commun des jobs de <em>data quality check</em>.</li>
<li class="nx-my-2">Si la configuration se trouve dans un endroit séparé, il devient facile de la changer sans avoir à toucher au code.</li>
<li class="nx-my-2">Parmi les éléments de configuration, il peut y avoir par exemple : l&#x27;endroit d&#x27;où on récupère la donnée, l&#x27;endroit où on l&#x27;envoie, les checks de qualité et transformations qu&#x27;il faut faire sur chaque donnée etc.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">La <em>data platform metadata</em> a 3 fonctions :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - <strong>Stocker les configurations des pipelines</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple, si un path d&#x27;input sur un serveur FTP change, il suffira d&#x27;aller changer la configuration de la pipeline dans le <em>metadata layer</em>, sans toucher au code.</li>
<li class="nx-my-2">Pour connaître les inputs et outputs d&#x27;une pipeline, il suffira aussi de regarder sa configuration.</li>
</ul>
</li>
<li class="nx-my-2">2 - <strong>Monitorer l&#x27;exécution et le statut des pipelines</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple, en cas d&#x27;erreur sur un pipeline, il suffira d&#x27;aller regarder dans le metadata layer pour avoir un statut détaillé de la pipeline, avec des statistiques d&#x27;échec, de nombre de duplicatas etc.</li>
</ul>
</li>
<li class="nx-my-2">3 - <strong>Servir de schema repository</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Cette partie sera plus développée dans le chapitre 8.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Il n&#x27;existe pas vraiment de standard concernant le <strong>modèle d&#x27;un metadata layer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les auteurs du livre en proposent un centré autour de 4 domaines, contenant les aspects qu&#x27;ils pensent être suffisamment universels.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - La <strong>Pipeline Metadata</strong> contient les informations d&#x27;input, output et transformations de chaque pipeline.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L&#x27;objet <strong>Namespace</strong> se trouve au plus haut niveau, et permet de séparer des groupes de pipelines.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s&#x27;agit par exemple de pouvoir appliquer des droits d&#x27;accès différents à des ensembles de pipelines.</li>
<li class="nx-my-2">On pourra l&#x27;utiliser pour nommer les folders, ou les topics de notre système de slow et fast storage.</li>
<li class="nx-my-2">Sa structure est :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em>ID</em></li>
<li class="nx-my-2"><em>Name</em></li>
<li class="nx-my-2"><em>Description</em></li>
<li class="nx-my-2"><em>Created At</em></li>
<li class="nx-my-2"><em>Updated At</em></li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">L&#x27;objet <strong>Pipeline</strong> décrit un ensemble de jobs qui prend un ou plusieurs inputs, et écrit dans une ou plusieurs destinations, avec d&#x27;éventuelles transformations.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les pipelines seront souvent liées : par exemple une pipeline d&#x27;ingestion qui écrit dans le <em>data lake</em>, puis une autre qui lit cette donnée, la combine avec une autre, et écrit à nouveau dans le <em>data lake</em>.</li>
<li class="nx-my-2">Sa structure est :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em>ID</em></li>
<li class="nx-my-2"><em>Name</em></li>
<li class="nx-my-2"><em>Description</em></li>
<li class="nx-my-2"><em>Type</em> : indique par exemple si c&#x27;est une pipeline d&#x27;ingestion ou de transformation.</li>
<li class="nx-my-2"><em>Velocity</em> : batch ou real-time.</li>
<li class="nx-my-2"><em>Sources and Destinations</em> : liste les identifiants d&#x27;objets <em>Source</em> desquels la pipeline lit, et <em>Destination</em> vers lesquels la pipeline écrit.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">En général une pipeline d&#x27;ingestion aura une source et une destination, et une pipeline de transformation aura plusieurs sources et une destination.</li>
</ul>
</li>
<li class="nx-my-2"><em>Data Quality Checks IDs</em> : une liste d&#x27;identifiants de checks de qualité à appliquer à l&#x27;ensemble des sources et destinations de la pipeline.</li>
<li class="nx-my-2"><em>Created At</em></li>
<li class="nx-my-2"><em>Updated At</em></li>
<li class="nx-my-2"><em>Connectivity Details</em> : pour les pipelines d&#x27;ingestion, il s&#x27;agit d&#x27;avoir des informations sur les sources. Par exemple des URLs, adresses IP etc.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Attention à ne pas stocker de username / mots de passe dans ce layer. Il vaut mieux les mettre dans des outils sécurisés comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Key Vault</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Secrets Manager</em> ou <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Cloud Secrets Manager</em>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">L&#x27;objet <strong>Source</strong> décrit un endroit dont on veut aller chercher de la donnée en entrée d&#x27;une pipeline.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Sa structure est :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em>ID</em></li>
<li class="nx-my-2"><em>Name</em></li>
<li class="nx-my-2"><em>Schema ID</em> : un lien vers le <em>schema registry</em> qui contient le schéma de cette source.</li>
<li class="nx-my-2"><em>Data Quality Checks IDs</em> : les checks de qualité à appliquer à chaque fois que cette source est utilisée.</li>
<li class="nx-my-2"><em>Type</em> : le type de source, par exemple “file”, “real-time topic”, “table”.</li>
<li class="nx-my-2"><em>Created At</em></li>
<li class="nx-my-2"><em>Updated At</em></li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">L&#x27;objet <strong>Destination</strong> est similaire à l&#x27;objet Source, mais les types peuvent être différents. Par exemple, on peut vouloir aussi mettre dans un <em>key/value store</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Sa structure est :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em>ID</em></li>
<li class="nx-my-2"><em>Name</em></li>
<li class="nx-my-2"><em>Schema ID</em></li>
<li class="nx-my-2"><em>Data Quality Checks IDs</em></li>
<li class="nx-my-2"><em>Type</em></li>
<li class="nx-my-2"><em>Created At</em></li>
<li class="nx-my-2"><em>Updated At</em></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">2 - Les <strong>Data Quality Checks</strong> permettent d&#x27;identifier les données qui posent problème.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ils s&#x27;appliquent à des pipelines et sources ou destinations sans êtres spécifiques à un namespace.</li>
<li class="nx-my-2">Il existe deux types de <em>data quality checks</em> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les <strong>proactive</strong> checks sont faits pour contrôler la donnée une par une, et s&#x27;assurer que la donnée de mauvaise qualité ne rentre pas.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On va souvent vérifier le format de la donnée, ou le fait que certaines valeurs soient cohérentes. Par exemple 24h dans un jour, pas de dates négatives etc.</li>
<li class="nx-my-2">Ces checks ne peuvent pas être trop lourds pour ne pas bloquer la pipeline trop longtemps.</li>
</ul>
</li>
<li class="nx-my-2">Les <strong>retrospective</strong> checks sont schédulés régulièrement, et opèrent sur de plus grandes quantités de données, pour s&#x27;assurer qu&#x27;on garde une certaine consistance sur l&#x27;ensemble.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ca peut par exemple être de faire une jointure sur deux jeux de données de départements et d&#x27;employés, pour s&#x27;assurer qu&#x27;aucun département n&#x27;est sans employé.</li>
<li class="nx-my-2">Ils produisent des rapports réguliers pour donner lieu à d&#x27;éventuelles actions pour améliorer la qualité de la donnée.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">L&#x27;élément principal du <em>data quality check</em> est <strong>la règle</strong> à faire respecter. Il existe de nombreuses options sur la manière de l&#x27;implémenter.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ça peut être une requête SQL, ou encore un Domain Specific Language (DSL).</li>
</ul>
</li>
<li class="nx-my-2">Leur structure est :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em>ID</em></li>
<li class="nx-my-2"><em>Name</em></li>
<li class="nx-my-2"><em>Severity</em> : la gravité du problème si la règle n&#x27;est pas respectée.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em>info</em> indique qu&#x27;on laisse passer la donnée, qu&#x27;on log le problème dans l&#x27;activity metadata, mais qu&#x27;on ne crée pas d&#x27;alerte.</li>
<li class="nx-my-2"><em>warning</em> indique qu&#x27;on laisse passer la donnée, et qu&#x27;on crée une alerte pour avertir un data engineer.</li>
<li class="nx-my-2"><em>critical</em> indique qu&#x27;on ne laisse pas passer la donnée et qu&#x27;on la met en quarantaine, avec aussi une alerte.</li>
</ul>
</li>
<li class="nx-my-2"><em>Rule</em> : en fonction de la manière dont on gère nos règles, cet attribut contiendra quelque chose de différent.</li>
<li class="nx-my-2"><em>Created At</em></li>
<li class="nx-my-2"><em>Updated At</em></li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">3 - Les <strong>Pipeline Activities</strong> contiennent des informations de succès, échecs, statistiques etc. sur l&#x27;exécution régulière des pipelines.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On enregistre les informations de chaque pipeline qui tourne, et on ne supprime jamais ces données, pour pouvoir ensuite investiguer, ou faire des analyses dessus.</li>
<li class="nx-my-2">On pourra par exemple répondre à des questions comme :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Quelle est la durée moyenne d&#x27;une pipeline ?</li>
<li class="nx-my-2">Combien de rows lit en moyenne une pipeline ?</li>
<li class="nx-my-2">Combien de données on collecte en moyenne depuis une source donnée ?</li>
</ul>
</li>
<li class="nx-my-2">Parmi les éléments de structure que les auteurs ont trouvé utiles dans la plupart des contextes :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em>Activity ID</em></li>
<li class="nx-my-2"><em>Pipeline ID</em></li>
<li class="nx-my-2"><em>Start time</em>, <em>Stop time</em> : début et fin de l&#x27;exécution de la pipeline.</li>
<li class="nx-my-2"><em>Status</em> : succès / échec.</li>
<li class="nx-my-2"><em>Error Message</em> : en cas d&#x27;échec, mettre l&#x27;erreur dans ce champ fait gagner beaucoup de temps de recherche dans les logs.</li>
<li class="nx-my-2"><em>Source and Destination Ids</em> : la liste précise des sources et destinations qui ont été utilisées par la pipeline.</li>
<li class="nx-my-2"><em>Rows Read</em> : nombre de rows qui ont été lues, dans le cas de fichiers ça permet notamment de s&#x27;assurer qu&#x27;on a lu le fichier entier.</li>
<li class="nx-my-2"><em>Rows Written</em></li>
<li class="nx-my-2"><em>Bytes Read</em></li>
<li class="nx-my-2"><em>Bytes Written</em> : on peut l&#x27;utiliser pour du monitoring, par exemple pour s&#x27;assurer que la valeur ne vaut pas 0 si <em>Bytes Read</em> ne vaut pas 0.</li>
<li class="nx-my-2"><em>Extra</em> : des infos additionnelles comme le path où le fichier a été écrit sur le storage, le nom du topic et le window dans le cas de real-time.</li>
</ul>
</li>
<li class="nx-my-2">Dans le cas de real-time processing, c&#x27;est une bonne idée d&#x27;aligner le <em>time window</em> avec la fréquence d&#x27;écriture des messages dans le slow storage.</li>
</ul>
</li>
<li class="nx-my-2">4 - <strong>Schema Registry</strong> contient l&#x27;ensemble des versions des schémas des données entrantes. Il est détaillé au chapitre suivant.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Selon l&#x27;expérience des auteurs, il n&#x27;y a pas d&#x27;outil open source ou commercial qui permette de mettre en œuvre le metadata layer de manière satisfaisante. Ils conseillent donc de <strong>le coder soi-même</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - Une première solution simple est d&#x27;implémenter le <em>metadata layer</em> avec des <strong>fichiers</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s&#x27;agit de la solution la plus simple, quand on a peu de sources et de pipelines.</li>
<li class="nx-my-2">La <em>pipeline metadata</em> peut être implémentée avec des fichiers de configuration de type JSON ou YAML par exemple.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s&#x27;agit d&#x27;avoir par exemple un fichier pour les namespaces, un pour les pipelines etc.</li>
<li class="nx-my-2">Les IDs doivent être assignés à la main.</li>
<li class="nx-my-2">Il s&#x27;agira de les mettre dans le gestionnaire de version avec le reste du code, et de les déployer à chaque fois avec la pipeline de CI/CD.</li>
</ul>
</li>
<li class="nx-my-2">Les <em>pipeline activities metadata</em> sont l&#x27;équivalent de fichiers logs où la donnée afflue régulièrement.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Pour pouvoir chercher dedans, il faut un outil spécialisé qui permette de le faire, il s&#x27;agit des <strong>Cloud Log Aggregation Services</strong> : <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Monitor</em> avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Log Analytics</em> sur Azure, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Cloud Logging</em> sur GCP, et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Elasticsearch</em> sur AWS.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">2 - Un cran de complexité au-dessus, on a l&#x27;utilisation d&#x27;une <strong>base de données</strong> pour stocker les fichiers de configuration (la <em>pipeline metadata</em>).<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les fichiers de configuration sont toujours dans le gestionnaire de version, et servent de source de vérité pour la configuration du <em>metadata layer</em>. C&#x27;est nécessaire pour avoir un historique des changements.</li>
<li class="nx-my-2">A chaque fois qu&#x27;un changement est fait dans ces fichiers, une migration sera faite sur la <em>metadata database</em>.</li>
<li class="nx-my-2">L&#x27;avantage d&#x27;avoir cette DB, c&#x27;est qu&#x27;on va pouvoir faire des requêtes pour obtenir des informations spécifiques qui existent à travers les fichiers de config. Par exemple : “Je veux voir toutes les sources qui utilisent ce <em>data quality check</em>”.</li>
<li class="nx-my-2">La DB peut être une DB relationnelle ou une DB de document qui permettra plus de flexibilité sur l&#x27;évolution du schéma.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Des exemples typiques peuvent être <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Cloud Datastore</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Cosmos DB</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS DynamoDB</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">3 - Quand on a plusieurs équipes en charge des pipelines, il faut une solution qui puisse abstraire les détails d&#x27;implémentation exposés par la DB : on peut utiliser une <strong>metadata API</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L&#x27;idée c&#x27;est que le changement dans la structure de la DB n&#x27;impactera pas de nombreux outils maintenus par plusieurs équipes différentes. On pourra par exemple faire plusieurs versions de l&#x27;API.</li>
<li class="nx-my-2">La metadata API est en général faite selon les principes REST.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Pour plus d&#x27;infos sur comment designer une API REST, il y a <em style="color:#a64d79;font-weight:bold;font-style:italic">The Design of Web APIs</em> d&#x27;Arnaud Lauret.</li>
</ul>
</li>
<li class="nx-my-2">Il faudra que l&#x27;ensemble des outils qui utilisaient la DB, y compris les pipelines, utilisent maintenant l&#x27;API pour accéder aux configurations.</li>
</ul>
</li>
<li class="nx-my-2">Les auteurs conseillent de <strong>commencer par implémenter la solution la plus simple qui satisfait les besoins actuels</strong> de la <em>data platform</em>, avec la possibilité de passer à la version un cran plus complexe dès que le besoin sera là.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Chaque solution se base sur la précédente en lui ajoutant quelque chose, donc ça devrait être relativement facile de migrer.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Parmi les <strong>outils qu&#x27;on peut trouver chez les cloud vendors</strong>, qui se rapprochent le plus de ce qu&#x27;on recherche avec notre <em>metadata layer</em>, il y a :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Glue Data Catalog</em> stocke des informations à propos des sources et destinations, et des statistiques sur les runs des pipelines, ce qui fait de cet outil le plus proche de ce qu&#x27;on recherche.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le désavantage majeur c&#x27;est sa flexibilité : il faut implémenter les pipelines avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Glue ETL</em>, ce qui veut dire n&#x27;avoir que des <em>batch jobs</em>, et qui soient compatibles avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Glue</em> (donc pas de source REST par exemple).</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Data Catalog</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Cloud Data Catalog</em> sont plus orientées <em>business metadata</em>, et fournissent surtout de la <strong>data discovery</strong> : permettre aux utilisateurs de la donnée de faire une recherche dans une UI pour trouver la table qui les intéresse.</li>
</ul>
</li>
<li class="nx-my-2">Parmi les <strong>outils open source</strong>, qui se rapprochent le plus de ce qu&#x27;on recherche avec notre <em>metadata layer</em>, il y a :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Atlas</em> permet de faire de la <em>data discovery</em>, mais aussi de gérer la configuration de pipelines de manière <strong>flexible</strong> : on peut utiliser les <em>Types</em> qu&#x27;il propose pour créer la configuration des namespaces, des pipelines, sources, destinations etc. avec des liens entre les objets.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son inconvénient principal est qu&#x27;il a été créé pour l&#x27;écosystème de <em style="color:#3d85c6;font-weight:bold;font-style:normal">Hadoop</em>, et possède de nombreuses fonctionnalités qui lui sont dédiées.</li>
<li class="nx-my-2">Un autre inconvénient est que c&#x27;est un outil open source qui nécessite de faire tourner d&#x27;autres outils open sources difficiles à administrer : <em style="color:#3d85c6;font-weight:bold;font-style:normal">HBase</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Solr</em>.</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">DataHub</em> est similaire à Atlas, dans la mesure où il est suffisamment flexible pour permettre d&#x27;implémenter le modèle décrit dans ce chapitre, et permet aussi la data discovery.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il a aussi l&#x27;inconvénient de nécessiter de faire tourner des outils open source difficiles à administrer : <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">MySQL</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Elasticsearch</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Neo4j</em>.</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Marquez</em> permet principalement de mettre à disposition des informations de <strong>data lineage</strong>, c&#x27;est-à-dire des informations sur l&#x27;origine des données.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il n&#x27;est pas assez flexible pour implémenter le modèle présenté dans ce chapitre.</li>
<li class="nx-my-2">Il a l&#x27;avantage de ne nécessiter que <em style="color:#3d85c6;font-weight:bold;font-style:normal">PostgreSQL</em> comme dépendance à faire tourner, et on peut le faire comme service managé.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">8 - Schema management<a href="#8---schema-management" id="8---schema-management" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Certaines organisations ont une approche <strong>proactive</strong>, et planifient les conséquences des changements dans les DBs opérationnelles sur les équipes data.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">D&#x27;autres ont une approche <strong>”do nothing and wait for things to break”</strong>, et attendent simplement que la pipeline ETL casse pour que l&#x27;équipe data la répare en prenant en compte le changement de schéma.</li>
</ul>
</li>
<li class="nx-my-2">Dans les <strong>architectures data traditionnelles</strong> basées sur le <em>data warehouse</em>, les données arrivent dans une <em>landing table</em> qui reproduit exactement leur schéma, et donc quand elles changent, l&#x27;ingestion casse.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il existe une approche alternative <strong>schema-on-read</strong> où il s&#x27;agit d&#x27;ingérer la donnée telle quelle dans un système de fichiers distribués, et dans ce cas on repousse le problème au <em>processing layer</em>.</li>
</ul>
</li>
<li class="nx-my-2">Coupler le <em>schema-on-read</em> avec une approche ”<em>do nothing and wait for things to break</em>” est plutôt une mauvaise idée selon les auteurs. Comme alternatives, on a :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - <strong>Le schema as a contract</strong> où il s&#x27;agit pour l&#x27;équipe de développeurs d&#x27;enregistrer le schéma de leur source de donnée dans le <em>schema repository</em>, et d&#x27;en être <strong>responsables</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ils doivent alors ne faire que des changements <em>backward-compatibles</em> dans leur DB. Par exemple ajouter des colonnes mais pas en renommer.</li>
<li class="nx-my-2">Pour que ça marche, il faut deux choses :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Un grand niveau de maturité dans les process de développement, notamment d&#x27;un point de vue automatisation de du check de rétrocompatibilité dans la pipeline de CI.</li>
<li class="nx-my-2">Un owner pour chaque source de donnée externe à l&#x27;organisation.</li>
</ul>
</li>
<li class="nx-my-2">De l&#x27;expérience des auteurs, les organisations n&#x27;ont en général pas la maturité technique suffisante, et le besoin de schéma versionné venant après coup, il est difficile de convaincre les équipes opérationnelles de mettre en place le <em>schema as a contract</em>.</li>
<li class="nx-my-2">NDLR : il s&#x27;agit de l&#x27;approche mise en avant par le Data Mesh.</li>
</ul>
</li>
<li class="nx-my-2">2 - <strong>La gestion du schéma dans la data platform</strong>. Dans ce cas, la responsabilité se trouve du côté de l&#x27;équipe qui gère la data platform.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les auteurs trouvent que cette solution marche bien dans pas mal de contextes. Elle a l&#x27;avantage de permettre de <strong>centraliser</strong> au même endroit les schémas des données qui viennent des équipes internes et ceux qui viennent de l&#x27;extérieur.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Cette centralisation permet ensuite d&#x27;avoir un catalogue de données dans lequel on peut fouiller.</li>
<li class="nx-my-2">Ca permet d&#x27;avoir un historique des schémas pour pouvoir utiliser n&#x27;importe quelle donnée archivée, ou faire du debugging.</li>
<li class="nx-my-2">Ca peut aussi permettre de détecter et ajuster les changements de schémas avant que la pipeline n&#x27;échoue.</li>
</ul>
</li>
<li class="nx-my-2">Une autre solution peut être de laisser aux équipes internes la responsabilité du schéma de leurs données, et de centraliser les schémas des sources externes chez l&#x27;équipe responsable de la data platform.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Dans le cas où la gestion des schémas se fait dans la data platform, elle doit être ajoutée en tant que <strong>1ère étape du common data processing</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le module de <em>schema-management</em> va d&#x27;abord vérifier si un schéma existe déjà pour cette source.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">S&#x27;il n&#x27;existe pas, le module va inférer un schéma depuis les données, puis enregistrer ce schéma dans le <em>schéma registry</em> en tant que V1.</li>
<li class="nx-my-2">S&#x27;il existe, le module va récupérer la dernière version depuis le <em>schema registry</em>, puis inférer le schéma depuis les données, créer un nouveau schéma compatible avec les deux et l&#x27;enregistrer en tant que version actuelle.</li>
</ul>
</li>
<li class="nx-my-2"><strong>L&#x27;inférence de schéma</strong> dont on est en train de parler se base sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Spark</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> est capable d&#x27;inférer le schéma de fichiers CSV, JSON, y compris s&#x27;il y a plusieurs records dedans.</li>
<li class="nx-my-2">Il utilise un sample de records pour faire l&#x27;inférence, par défaut 1000, et ce nombre est configurable.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">S&#x27;il est trop faible on risque d&#x27;avoir une inférence faussée qui ne permet pas de parser l&#x27;ensemble des données. Et s&#x27;il est trop grand on risque d&#x27;avoir des problèmes de performance.</li>
<li class="nx-my-2">Pour une table d&#x27;une DB relationnelle par exemple, le nombre pourra être bas parce que la schéma est garanti par la DB.</li>
</ul>
</li>
<li class="nx-my-2">Dans le cas où la donnée est différente entre deux records, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> essayera de trouver un type qui englobe les deux. Par exemple, un nombre et un string vont donner un string.</li>
<li class="nx-my-2">Dans le cas où un type commun n&#x27;est pas possible, les données minoritaires seront placées dans le champ <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">_corrupt_record</code>.</li>
<li class="nx-my-2">Le schéma inféré par <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> va d&#x27;abord être converti en schéma <em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em> avant d&#x27;être mis dans le <em>schema registry</em>.</li>
<li class="nx-my-2">Si on utilise un outil qui ne supporte pas l&#x27;inférence de schéma, comme par exemple <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Cloud Dataflow</em> basé sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Beam</em>, alors il faudra gérer les schémas à la main.</li>
</ul>
</li>
<li class="nx-my-2">Dans le cas d&#x27;une <strong>real-time pipeline</strong>, on ne peut pas utiliser l&#x27;inférence à cause du problème de performance et de la quantité de schémas qui seraient générés.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Dans ce cas, les auteurs conseillent de <strong>laisser les développeurs qui génèrent les données de streaming maintenir le schéma</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Pour pouvoir avoir du <strong>monitoring</strong> sur les changements de schémas, le module de <em>schema-management</em> peut créer un log dans la partie <em>Pipeline Activities</em> du <em>metadata layer</em> à chaque fois qu&#x27;il trouve des données avec un schéma qui a changé.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Même si l&#x27;ingestion et les <em>common data processing</em> steps peuvent se “réparer” automatiquement, la suite du processing peut ne pas donner le résultat voulu. Par exemple un rapport qui n&#x27;a plus les valeurs d&#x27;une colonne qui a été enlevée par la source.</li>
<li class="nx-my-2">Il vaut mieux être alerté du changement de schéma, et prévenir les équipes qui utilisent les données de cette source, avant qu&#x27;ils ne s&#x27;aperçoivent du problème par eux-mêmes.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Côté <strong>implémentation</strong> du <em>schema registry</em> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Apache Avro</em> est l&#x27;option conseillée par les auteurs pour servir de format de base pour l&#x27;ensemble des données de la <em>data platform</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son schéma peut être écrit et maintenu à la main.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em> peut aussi transformer son schéma inféré en schéma <em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em> automatiquement.</li>
<li class="nx-my-2">Ces schémas peuvent être représentés par du simple JSON, et donc n&#x27;importe quelle DB qui supporte ça peut les héberger.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em> a un très bon système de gestion des versions des schémas.</li>
</ul>
</li>
<li class="nx-my-2">Les <strong>solutions cloud-natives</strong> de type <em>data catalog</em> permettent d&#x27;implémenter un <em>schema registry</em>, mais ont des limitations.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La plupart sont surtout orientés data discovery, et manquent de fonctionnalités concernant la gestion des versions des schémas et le support d&#x27;<em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em>.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Confluent Schema Registry</em> offre les fonctionnalités de gestion de version des schémas et un bon support d&#x27;<em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em>, mais il nécessite d&#x27;utiliser <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em>, ou un outil compatible avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kafka</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Donc si on utilise par exemple <em style="color:#3d85c6;font-weight:bold;font-style:normal">Kinesis</em>, ou bien si on ne fait pas de real-time, on ne pourra pas utiliser leur <em>schema registry</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">La <strong>solution maison</strong> proposée par les auteurs consiste à avoir soit une DB, soit une API avec une DB derrière.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le solution pure texte stockée dans le gestionnaire de version, similaire au reste de la configuration du metadata layer, ne peut pas marcher pour le <em>schema registry</em> parce qu&#x27;il faut pouvoir le mettre à jour automatiquement.</li>
<li class="nx-my-2">Comme DB, on peut utiliser les mêmes <em style="color:#3d85c6;font-weight:bold;font-style:normal">Cosmos DB</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Datastore</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">DynamoDB</em>.</li>
<li class="nx-my-2">La structure des objets de schéma sera :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em>ID</em></li>
<li class="nx-my-2"><em>Version</em> : l&#x27;<em>ID</em> et la <em>Version</em> forment ensemble une clé unique. L&#x27;<em>ID</em> en elle-même n&#x27;est donc pas unique pour éviter d&#x27;avoir à mettre à jour en permanence les configurations des sources et destinations.</li>
<li class="nx-my-2"><em>Schema</em> : le champ qui stocke le schéma <em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em> au format texte.</li>
<li class="nx-my-2"><em>Created At</em></li>
<li class="nx-my-2"><em>Updated At</em></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant la stratégie de <strong>gestion de version des schémas</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il existe deux types de compatibilité entre les schémas :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>1 - Backward-compatible</strong> : la dernière version du schéma doit permettre de lire l&#x27;ensemble des données existantes, y compris produites par un ancien schéma.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em> impose des règles précises pour garder la <em>backward-compatibility</em>. Par exemple ajouter une colonne le permet, dans ce cas la lecture d&#x27;une donnée ancienne par un schéma récent donnera lieu à l&#x27;usage de la valeur par défaut pour la colonne manquante.</li>
</ul>
</li>
<li class="nx-my-2"><strong>2 - Forward-compatible</strong> : une version plus ancienne du schéma doit permettre de lire les données produites par une version plus récente.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Si on reprend l&#x27;exemple de l&#x27;ajout de colonne, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em> permet une forward-compatibility : l&#x27;ancien schéma ignorera la nouvelle colonne au moment de la lecture de la nouvelle donnée.</li>
</ul>
</li>
<li class="nx-my-2">Le renommage de colonne est l&#x27;équivalent d&#x27;une création de colonne, et d&#x27;une suppression de colonne. Donc si on a des valeurs par défaut dans le schéma, elle sera à la fois <em>backward-compatible</em> et <em>forward-compatible</em>.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em> supporte aussi automatiquement certains changements de types, par exemple un entier 32 bits vers 64 bits. On peut aussi soi-même implémenter d&#x27;autres règles de conversion, mais les auteurs le déconseillent pour garder la complexité des pipelines faible.</li>
<li class="nx-my-2">Les règles d&#x27;évolution de schéma d&#x27;<em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em> sont disponibles <a href="https://avro.apache.org/docs/1.7.7/spec.html#Schema+Resolution" target="_blank" rel="noreferrer" class="nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]">dans leur doc<span class="nx-sr-only nx-select-none"> (opens in a new tab)</span></a>.</li>
</ul>
</li>
<li class="nx-my-2">Les <em>common data transformation pipelines</em> ne vont en général pas avoir besoin de la présence de colonnes spécifiques, et donc vont être résilientes aux changements de schémas.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les <em>business processing pipelines</em> en revanche vont y être beaucoup plus sensibles.</li>
</ul>
</li>
<li class="nx-my-2">Les auteurs conseillent d&#x27;<strong>utiliser les anciens schémas</strong> dans les pipelines, et de passer aux nouveaux quand les changements de code ont été faits. Ca veut dire s&#x27;efforcer à faire des changements de schémas <em>forward-compatibles</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Quelle que soit la stratégie, même si la pipeline ne casse pas grâce aux règles de <em>backward / forward compatibility</em>, il est possible qu&#x27;on se retrouve avec des <strong>erreurs logiques</strong> dans nos transformations.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple, une colonne indiquant le nombre de ventes est renommée, et peut continuer à être lue de manière forward compatible avec la valeur par défaut <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">NULL</code>. Mais le dashboard se mettra à montrer une absence de ventes.</li>
<li class="nx-my-2">Il n&#x27;y a pas de solution simple à ce problème. Il faut avoir un système de monitoring et d&#x27;alerting efficaces, et prévenir les clients en amont que leurs dashboards risquent d&#x27;avoir des incohérences le temps de mettre à jour le code.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Alors que les fichiers peuvent avoir chacun leur version de schéma associée, la donnée qui se trouve dans une table du <strong>data warehouse</strong> ne peut pas avoir plusieurs schémas en même temps.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On ne peut pas simplement utiliser le <em>schema registry</em> pour mettre à jour la table du <em>data warehouse</em>, il va falloir le faire avec <strong>du code dans le module de schema-management</strong>, qui fait partie des <em>common data transformations</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ça veut dire que les changements de schéma se feront quand même de manière automatique, avec des règles pré-établies où on va générer le bon SQL pour restructurer la table, en fonction de chaque changement de schéma <em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em>.</li>
</ul>
</li>
<li class="nx-my-2">On ne peut pas non plus appliquer les mêmes règles qu&#x27;avec les transformations de schémas entre fichiers : dans le cas de suppression d&#x27;une colonne (ou de renommage, qui implique une suppression de fait), on va <strong>garder l&#x27;ancienne colonne</strong> quand même pour garder la donnée historique.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Parfois, quand les données ne sont pas trop grosses, il pourra être préférable de supprimer la colonne et de la recréer avec les données historiques et les nouvelles données dedans.</li>
</ul>
</li>
<li class="nx-my-2">Côté <strong>data warehouses des cloud vendors</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Redshift</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Synapse</em> ont une approche similaire :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ils sont ancrés dans le monde du relationnel, et nécessitent la définition du schéma avant de charger de la donnée.</li>
<li class="nx-my-2">Ils supportent <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">ALTER TABLE</code> pour faire des changements sur les tables.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Redshift</em> supporte <em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em> mais sans inférence à partir du schéma, alors que <em style="color:#3d85c6;font-weight:bold;font-style:normal">Synapse</em> supporte seulement <em style="color:#3d85c6;font-weight:bold;font-style:normal">CSV</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">ORC</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Parquet</em>.</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Google BigQuery</em> a une approche moins relationnelle, et permet d&#x27;inférer le schéma à partir de la donnée qu&#x27;on lui donne.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il va aussi ajouter des colonnes au schéma automatiquement en inférant le type, si on lui présente de la donnée qui a des colonnes en plus. Il le supporte pour <em style="color:#3d85c6;font-weight:bold;font-style:normal">Avro</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">JSON</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Parquet</em>.</li>
<li class="nx-my-2">En revanche, il ne permet pas de modifier les tables après coup, sauf en ajoutant ou supprimant des colonnes, ce qui peut prendre du temps et coûter cher.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">9 - Data access and security<a href="#9---data-access-and-security" id="9---data-access-and-security" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les données d&#x27;analytics sont utilisées par de plus en plus de personnes au sein des entreprises, et par des moyens variés.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - Il y a les <strong>utilisateurs humains</strong> qui utilisent en général des outils BI ou veulent exécuter des requêtes SQL, et parfois des data scientists qui veulent accéder à la <em>raw data</em>.</li>
<li class="nx-my-2">2 - Et il y a les <strong>applications</strong> qui utilisent la donnée par exemple pour des applications ML de recommandation ou de prédiction. Le <em>data warehouse</em> ne suffit pas pour ces cas d&#x27;usage.</li>
</ul>
</li>
<li class="nx-my-2">Le <strong>data warehouse</strong> reste quand même l&#x27;outil le plus commun pour accéder à la donnée d&#x27;analytics, du fait de la compatibilité avec les outils BI et du support du SQL.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">AWS Redshift</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s&#x27;agit d&#x27;un <em>data warehouse</em> <strong>distributé</strong>, c&#x27;est-à-dire qu&#x27;il répartit la donnée sur plusieurs machines.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Un nœud <em>leader</em> reçoit les requêtes et répartit le travail à faire et les données sur les autres nœuds.</li>
<li class="nx-my-2">Les autres nœuds eux-mêmes sont subdivisés en <em>slices</em>. Ces slices peuvent être déplacés de nœud en nœud, pour équilibrer la capacité par du <em>rebalancing</em>.</li>
<li class="nx-my-2">Quand on crée une table, on peut indiquer sa propriété <em>DISTSTYLE</em> pour choisir la manière dont ses données seront distribuées sur les nœuds. C&#x27;est le réglage de performance le plus impactant.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em>ALL</em> : une copie de la table est créée sur chaque nœud. On ne peut le faire qu&#x27;avec les petites tables qui sont souvent l&#x27;objet de jointures.</li>
<li class="nx-my-2"><em>EVEN</em> : les rows de la table sont répartis de manière équitable sur les nœuds.</li>
<li class="nx-my-2"><em>KEY</em> : permet d&#x27;indiquer une colonne dont les valeurs identiques donneront lieu à ce que la donnée soit stockée sur la même machine.</li>
<li class="nx-my-2"><em>AUTO</em> : vaut <em>ALL</em> au début, et passe à <em>EVEN</em> quand la table grandit.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Il est basé sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">PostgreSQL</em> et présente les caractéristiques des DB relationnelles.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il ne supporte que les types “primitifs”, c&#x27;est-à-dire pas les tableaux ou les objets imbriqués. Il est donc peu adapté à de la donnée JSON, avec laquelle les optimisations d&#x27;encodage ou de distribution dans les nœuds par clé ne pourront pas servir.</li>
</ul>
</li>
<li class="nx-my-2">On peut optimiser la taille des données en choisissant le type d&#x27;encodage pour les colonnes : par exemple dans le cas où une colonne peut avoir seulement quelques valeurs possibles, l&#x27;encodage <em>byte-dictionary</em> permet de limiter la taille de ces données.</li>
<li class="nx-my-2">Il possède une fonctionnalité appelée <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spectrum</em>, qui permet de créer une table dans <em style="color:#3d85c6;font-weight:bold;font-style:normal">Redshift</em>, dont les données sont sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">S3</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ca permet d&#x27;éviter d&#x27;utiliser des ressources CPU et de l&#x27;espace sur le <em>data warehouse</em>, pour des données qu&#x27;on veut juste explorer par exemple.</li>
<li class="nx-my-2">Les performances seront du coup moins bonnes que les données qui sont sur les nœuds <em style="color:#3d85c6;font-weight:bold;font-style:normal">Redshift</em>.</li>
<li class="nx-my-2">Les auteurs recommandent de créer une DB dédiée sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">Redshift</em> pour regrouper ces tables qui pointent vers ailleurs.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Synapse</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">C&#x27;est une DB distribuée comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">Redshift</em>, avec un <em>control node</em> principal qui reçoit les requêtes, et qui fait appel aux autres nœuds.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il y a une <strong>séparation storage / compute</strong>. Les données sont séparées en 60 distributions, et sont associées à des <em>compute nodes</em>.</li>
<li class="nx-my-2">Il n&#x27;est pas complètement élastique, puisque pour redimensionner le cluster, il faut tout arrêter, et ça peut prendre du temps.</li>
<li class="nx-my-2">Les tables peuvent être configurées pour la répartition de leurs données, de la même manière que <em style="color:#3d85c6;font-weight:bold;font-style:normal">Redshift</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em>REPLICATE</em> : l&#x27;équivalent de <em>ALL</em>, c&#x27;est-à-dire copier sur chaque nœud.</li>
<li class="nx-my-2"><em>ROUND ROBIN</em> : l&#x27;équivalent de <em>EVEN</em>, c&#x27;est-à-dire répartir entre les nœuds.</li>
<li class="nx-my-2"><em>HASH</em> : l&#x27;équivalent de <em>KEY</em>, c&#x27;est-à-dire spécifier une colonne dont les valeurs permettront de répartir les données.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Il présente des caractéristiques relationnelles.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il supporte seulement les types primitifs, et fournit des fonctions de parsing pour JSON, mais au prix de nombreuses optimisations perdues.</li>
</ul>
</li>
<li class="nx-my-2">Il a une fonctionnalité similaire à <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spectrum</em>, configurable par la notion de <strong>pools</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em>SQL pool</em> représente l&#x27;utilisation normale du <em>data warehouse</em>.</li>
<li class="nx-my-2"><em>SQL on-demand pool</em> permet de faire des requêtes sur des données sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azur Blob Storage</em> au format <em style="color:#3d85c6;font-weight:bold;font-style:normal">Parquet</em>, CSV ou JSON.</li>
<li class="nx-my-2"><em>Spark pool</em> permet de faire des requêtes avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>, sur des données qui sont dans <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azur Blob Storage</em>. Ils permettent l&#x27;auto-scaling, mais nécessitent que 3 nœuds tournent en permanence.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Google BigQuery</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">BigQuery</em> est un <strong>peu plus “managé”</strong> que les deux autres, dans la mesure où il n&#x27;y a pas de besoin de planifier la capacité dont on aura besoin à l&#x27;avance.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La puissance de calcul est “provisionnée” <strong>à chaque requête</strong>, grâce à des groupes de dizaines de milliers de nœuds qui tournent en permanence dans l&#x27;infra de Google.</li>
<li class="nx-my-2">Comme il est plus managé, on peut aussi moins facilement contrôler la manière dont les données d&#x27;une table sont réparties au sein des nœuds.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On a quand même la notion de <em>partitioning</em> qui permet de répartir les données selon les valeurs d&#x27;une colonne.</li>
<li class="nx-my-2">Et de <em>clustering</em> qui permet d&#x27;organiser physiquement les données de manière à rendre les requêtes qu&#x27;on fait le plus souvent plus efficaces.</li>
</ul>
</li>
<li class="nx-my-2">Le pricing se fait aussi sur la quantité de données traitée, ce qui peut être avantageux quand on a de petits besoins, mais rend les coûts difficilement prédictibles.</li>
</ul>
</li>
<li class="nx-my-2">Les nœuds de calcul sont sur des machines différentes des nœuds de stockage : on n&#x27;a <strong>pas de <em>data locality</em></strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">C&#x27;est moins rapide que si la donnée était locale, mais ça évite d&#x27;avoir à recopier la donnée à chaque rebalancing. La donnée est accédée via le réseau local de Google qui est suffisamment performant pour que ça passe.</li>
</ul>
</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">BigQuery</em> vient initialement plutôt d&#x27;un système permettant de traiter des fichiers de log, et non pas un système relationnel comme les deux autres.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il a un <strong>support natif des structures imbriquées</strong>, et peut traiter le JSON comme une structure et pas juste du texte, avec la possibilité d&#x27;appliquer des traitements sur les attributs.</li>
<li class="nx-my-2">Il est du coup moins facilement compatible avec les outils BI, il faudra passer par une API REST.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Les grandes organisations peuvent tirer parti de l&#x27;utilisation de <strong>plusieurs cloud providers</strong>, mais pour les petites le <strong>coût opérationnel</strong> n&#x27;en vaut pas la peine. Le choix du <em>data warehouse</em> dépendra donc en général du choix du cloud provider pour le reste de l&#x27;infra.</li>
</ul>
</li>
<li class="nx-my-2">Les <strong>applications</strong> utilisent de plus en plus la data dans des systèmes customer-facing, par exemple dans des systèmes de recommandation.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Donner à l&#x27;application un <strong>accès au data warehouse serait une mauvaise idée</strong> pour plusieurs raisons :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les <em>data warehouses</em> ne sont pas conçues pour offrir des <strong>latences</strong> se comptant en millisecondes, mais en secondes voire minutes sur de grandes quantités de données.</li>
<li class="nx-my-2">Ils ne sont pas conçus pour supporter un trop <strong>grand nombre de transactions</strong> en même temps (par exemple des dizaines ou centaines de milliers) comme pourrait le nécessiter une application.</li>
<li class="nx-my-2">Si l&#x27;application est compromise, l&#x27;ensemble du contenu du <em>data warehouse</em> pourrait fuiter, alors que si l&#x27;application a seulement accès à une DB qui a ce dont elle a besoin, on aura une meilleure <strong>sécurité</strong>.</li>
</ul>
</li>
<li class="nx-my-2"><strong>1 - Cloud relational databases</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Chaque cloud provider a ses services de DBs managées, qui tiennent sans problèmes jusqu&#x27;à 1 TB. Au-delà de ça, ou si on a besoin de situer les machines géographiquement, il faut une DB distribuée.</li>
<li class="nx-my-2">AWS propose <em style="color:#3d85c6;font-weight:bold;font-style:normal">Relational Database Service</em> (RDS) pour <em style="color:#3d85c6;font-weight:bold;font-style:normal">PostgreSQL</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">MySQL</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">MariaDB</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Oracle</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">SQL Server</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il propose <em style="color:#3d85c6;font-weight:bold;font-style:normal">Aurora</em> comme DB distribuée, compatible avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">MySQL</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">PostgreSQL</em>.</li>
</ul>
</li>
<li class="nx-my-2">GCP propose <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Cloud SQL</em>, qui supporte <em style="color:#3d85c6;font-weight:bold;font-style:normal">MySQL</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">PostgreSQL</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">SQL Server</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il propose <em style="color:#3d85c6;font-weight:bold;font-style:normal">Google Cloud Spanner</em> pour la version distribuée.</li>
</ul>
</li>
<li class="nx-my-2">Azure propose <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure SQL Database</em>, qui supporte <em style="color:#3d85c6;font-weight:bold;font-style:normal">MySQL</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">PostgreSQL</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">SQL Server</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il propose <em style="color:#3d85c6;font-weight:bold;font-style:normal">HyperScale</em> pour la version distribuée, disponible seulement pour <em style="color:#3d85c6;font-weight:bold;font-style:normal">SQL Server</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>2 - Cloud key / value data stores</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les services key/value offrent une faible latence pour insérer et retrouver des valeurs par leur clé.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ils sont souvent utilisés par les nouveaux projets pour pouvoir itérer vite sans avoir de migration à faire.</li>
</ul>
</li>
<li class="nx-my-2">Les cloud providers proposent soit une version <em>pay per use</em> plus avantageuse en cas de faible utilisation, et une version <em>pay per provisioned capacity</em> plus avantageuse en cas de grosse utilisation.</li>
<li class="nx-my-2">AWS propose <em style="color:#3d85c6;font-weight:bold;font-style:normal">DynamoDB</em>, qui reste performant quel que soit le scale, et offre les deux types de facturation.</li>
<li class="nx-my-2">GCP propose <em style="color:#3d85c6;font-weight:bold;font-style:normal">Datastore</em> qui est similaire à <em style="color:#3d85c6;font-weight:bold;font-style:normal">DynamoDB</em> et qui propose du <em>pay per use</em>, et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Cloud Bigtable</em> qui ne permet pas de mettre de contrainte de types sur les données, et supporte le <em>price per provisioned capacity</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Cloud Bigtable</em> est d&#x27;ailleurs compatible avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">HBase</em>.</li>
</ul>
</li>
<li class="nx-my-2">Azure propose <em style="color:#3d85c6;font-weight:bold;font-style:normal">CosmosDB</em>, qui a la particularité de supporter les API clientes de <em style="color:#3d85c6;font-weight:bold;font-style:normal">MongoDB</em>, <em style="color:#3d85c6;font-weight:bold;font-style:normal">Cassandra</em>, SQL et de graph API, ce qui rend le portage depuis ces technos facile.</li>
</ul>
</li>
<li class="nx-my-2"><strong>3 - Full-text search services</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Dans le cas où la fonctionnalité de notre application est de permettre une recherche dans la donnée, il existe <em style="color:#3d85c6;font-weight:bold;font-style:normal">Solr</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Elasticsearch</em>, tous deux basés sur <em style="color:#3d85c6;font-weight:bold;font-style:normal">Lucene</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple, si on veut chercher quelque chose de similaire à ce qui est tapé par l&#x27;utilisateur.</li>
</ul>
</li>
<li class="nx-my-2">AWS propose <em style="color:#3d85c6;font-weight:bold;font-style:normal">CloudSearch</em>, Azure propose <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Search</em>, et GCP ne propose rien de managé au moment de l&#x27;écriture du livre.</li>
</ul>
</li>
<li class="nx-my-2"><strong>4 - In-memory cache</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les caches permettent des temps d&#x27;accès inférieurs à la milliseconde grâce au stockage en RAM. Ils doivent être liés à une DB persistante pour pouvoir être reconstruits.</li>
<li class="nx-my-2">AWS propose <em style="color:#3d85c6;font-weight:bold;font-style:normal">ElasticCache</em>, qui supporte <em style="color:#3d85c6;font-weight:bold;font-style:normal">Memcached</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Redis</em>, GCP propose <em style="color:#3d85c6;font-weight:bold;font-style:normal">Memorystore</em> qui supporte <em style="color:#3d85c6;font-weight:bold;font-style:normal">Memcached</em>, et Azure propose <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Cache</em> qui supporte <em style="color:#3d85c6;font-weight:bold;font-style:normal">Redis</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Les modèles de <strong>machine learning</strong> nécessitent l&#x27;accès à une grande quantité de données variée, une grande puissance de calcul, et l&#x27;accès à des outils spécifiques. La <em>cloud data platform</em> est parfaitement adaptée à ça.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Dans les plateformes traditionnelles, les data scientists passent 80% de leur temps à récupérer la donnée sur leur machine, et la nettoyer et la transformer pour qu&#x27;elle puisse être interprétée par leurs outils.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ils vont ensuite faire des tests exploratoires pour comprendre ce qu&#x27;ils peuvent faire ce cette donnée.</li>
<li class="nx-my-2">Puis ils séparent la donnée en deux : la donnée d&#x27;entraînement et la donnée de validation.</li>
<li class="nx-my-2">Ils vont faire un cycle <em>entraînement / validation</em> où ils vont plusieurs fois améliorer le modèle puis le tester contre la donnée de validation.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Cette validation permet d&#x27;éviter l&#x27;<em>overfitting</em> où le modèle ne serait bon que sur les données avec lesquelles il s&#x27;est entraîné.</li>
<li class="nx-my-2">Faire l&#x27;entraînement sur leur machine locale leur prend beaucoup de temps.</li>
</ul>
</li>
<li class="nx-my-2">Une fois que le modèle est fonctionnel, il faut le rendre production-ready pour le déployer, en ajoutant du logging, de la gestion d&#x27;erreurs etc. ce qui est souvent difficile.</li>
</ul>
</li>
<li class="nx-my-2">La <em>cloud data platform</em> aide au développement de modèles ML.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Une bonne partie de la mise en forme et de la validation des données est faite dans l&#x27;<em>ingestion layer</em> et dans le <em>processing layer</em> avec les <em>common data transformation steps</em>.</li>
<li class="nx-my-2">Les data scientists peuvent copier la donnée comme ils veulent dans le <em>storage</em> de la <em>cloud data platform</em>, et faire de l&#x27;exploration ou du processing sans télécharger les données en local.</li>
<li class="nx-my-2">Ils peuvent collaborer sur un même jeu de données puisqu&#x27;il est dans le cloud, et peuvent avoir accès à de la donnée de production en grande quantité.</li>
<li class="nx-my-2">Chacun des cloud vendors fournit un service de ML permettant de gérer un projet ML de bout en bout, et de mieux collaborer entre data scientists : <em style="color:#3d85c6;font-weight:bold;font-style:normal">SageMaker</em> chez AWS, <em style="color:#3d85c6;font-weight:bold;font-style:normal">AI Platform</em> chez GCP, et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure ML</em> chez Azure.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">La <strong>business intelligence</strong> et le <strong>reporting</strong> sont en général le premier usage de la donnée de type analytics.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ces outils nécessitent souvent que la donnée soit <strong>relationnelle</strong>, c&#x27;est-à-dire que chaque donnée soit dans sa colonne avec la table “à plat” reliée à d&#x27;autres tables par des clés étrangères, plutôt que d&#x27;avoir des données imbriquées comme dans du JSON.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">BigQuery</em> commence à être supporté par des outils comme <em style="color:#3d85c6;font-weight:bold;font-style:normal">Tableau</em>, mais tous ne le supportent pas correctement.</li>
</ul>
</li>
<li class="nx-my-2">Bien que de nombreux outils BI supportent <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark SQL</em>, et pourraient se <strong>brancher directement sur le <em>data lake</em></strong>, <strong>les auteurs le déconseillent</strong> parce que ça rendrait l&#x27;interface de ces outils peu interactive et lente. Se brancher sur le <em>data warehouse</em> est bien plus adapté pour cette raison.</li>
<li class="nx-my-2"><em style="color:#3d85c6;font-weight:bold;font-style:normal">Excel</em> peut se brancher sur le <em>data warehouse</em> grâce à son API JDBC/ODBC, mais c&#x27;est un outil qui tourne sur une machine locale, donc il sera limité sur la quantité de données, et télécharger les données sur sa machine locale pose des problèmes de performance.</li>
<li class="nx-my-2">On voit souvent des <strong>outils externes</strong>, par exemple chez d&#x27;autres cloud providers, accéder à la donnée de la <em>cloud data platform</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut faire attention aux <strong>coûts de sortie des données</strong> (<em>data egress costs</em>), que chaque cloud provider applique.</li>
<li class="nx-my-2">Chaque cloud provider a sa solution BI : <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Power BI</em> qui est très connu, AWS <em style="color:#3d85c6;font-weight:bold;font-style:normal">QuickSight</em>, et <em style="color:#3d85c6;font-weight:bold;font-style:normal">DataStudio</em> et <em style="color:#3d85c6;font-weight:bold;font-style:normal">Looker BI</em> pour GCP.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">La <strong>sécurité</strong> est essentielle pour une plateforme data.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il vaut mieux éviter les accès ad hoc dès qu&#x27;il y a un besoin, mais plutôt utiliser les concepts de <strong>Users</strong>, <strong>Groups</strong> et <strong>Roles</strong> fournis par les cloud providers.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les groupes facilitent grandement la gestion des permissions, il vaut mieux les configurer à ce niveau là dans la mesure du possible.</li>
<li class="nx-my-2">Une bonne pratique est de ne fournir que les permissions nécessaires à chaque type d&#x27;utilisateur (<em>principle of least privilege</em>).</li>
</ul>
</li>
<li class="nx-my-2">Il existe des outils cloud-native pour l&#x27;authentification, à la place des mots de passe, par exemple <em style="color:#3d85c6;font-weight:bold;font-style:normal">Azure Active Directory</em>. Les auteurs conseillent de les utiliser quand c&#x27;est possible.</li>
<li class="nx-my-2">Certaines configurations permettent de rendre des services accessibles publiquement. Pour limiter le risque, on peut faire diverses choses comme des audits, ou l&#x27;utilisation du principe <em>infrastructure-as-code</em>.</li>
<li class="nx-my-2">Dans le cas où on a des données sensibles, il ne faut pas hésiter à chiffrer des colonnes particulières.</li>
<li class="nx-my-2">Une autre solution peut être de limiter l&#x27;accès réseau à la donnée, dans le cas où les utilisateurs seraient sur un réseau particulier.</li>
</ul>
</li>
</ul>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">10 - Fueling business value with data platforms<a href="#10---fueling-business-value-with-data-platforms" id="10---fueling-business-value-with-data-platforms" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La <em>data platform</em> doit être organisée autour d&#x27;une <strong>data strategy</strong>, c&#x27;est-à-dire être au service des objectifs business.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Parmi les grands objectifs business, on trouve :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Augmenter les revenus.</li>
<li class="nx-my-2">Augmenter l&#x27;efficacité opérationnelle.</li>
<li class="nx-my-2">Améliorer l&#x27;expérience utilisateur.</li>
<li class="nx-my-2">Permettre l&#x27;innovation.</li>
<li class="nx-my-2">Améliorer la conformité.</li>
</ul>
</li>
<li class="nx-my-2">Exemples :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Dans le cas d&#x27;une entreprise de jeux vidéo qui veut maximiser les achats ou la publicité in-game, la stratégie peut être d&#x27;optimiser la plateforme data pour du real-time processing des événements du jeu.</li>
<li class="nx-my-2">Dans le cas d&#x27;une entreprise minière qui veut réduire ses coûts opérationnels, la stratégie peut être d&#x27;optimiser la plateforme pour ingérer la donnée des capteurs des engins miniers, et prédire quand faire la maintenance.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">La <strong>maturité data</strong> d&#x27;une organisation passe par 4 étapes.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>1 - See</strong> : le business veut voir des rapports et des dashboards pour mieux comprendre ce qui se passe par rapport à ce qui s&#x27;est passé dans le passé.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Traditionnellement les rapports sont créés par des personnes spécialistes de ces outils, à la demande du business.</li>
<li class="nx-my-2">Dans les plateformes modernes, on applique le principe <em>Bring Your Own Analytics (BYOA)</em>, où <strong>les personnes du business utilisent leurs propres outils</strong> qu&#x27;ils branchent sur la <em>data platform</em>, pour créer leurs rapports.</li>
<li class="nx-my-2">Ces outils sont branchés sur le <em>data warehouse</em>.</li>
</ul>
</li>
<li class="nx-my-2"><strong>2 - Predict</strong> : une fois qu&#x27;on a ce qui s&#x27;est passé et se passe, on veut prédire ce qui va se passer, par exemple avec du ML.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut que la plateforme puisse proposer une grande quantité de données.</li>
<li class="nx-my-2">Les données brutes vont être plutôt sur le <em>data lake</em>, et les données raffinées sur le <em>data warehouse</em>.</li>
</ul>
</li>
<li class="nx-my-2"><strong>3 - Do</strong> : on va donner le résultat des deux premières étapes à des systèmes pour déclencher des actions.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ça peut être du ML avec par exemple des systèmes de recommandation, ou même simplement de la donnée qui est déplacée vers le système opérationnel pour servir les clients.</li>
<li class="nx-my-2">Le fait de déplacer des données du monde analytics au monde opérationnel s&#x27;appelle l&#x27;<strong>orchestration</strong>.</li>
<li class="nx-my-2">Ça implique que le système qui utilise cette donnée soit disponible et réponde aux exigences d&#x27;un système de production.</li>
</ul>
</li>
<li class="nx-my-2"><strong>4 - Create</strong> : la donnée initialement collectée comme analytics devient la source pour un nouveau produit.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple, une banque qui a collecté des données pour améliorer l&#x27;expérience utilisateur en aidant les agents à anticiper les réactions des clients, s&#x27;est rendue compte qu&#x27;elle pouvait l&#x27;utiliser aussi pour améliorer l&#x27;app mobile.</li>
<li class="nx-my-2">Autre exemple, une entreprise de sécurité s&#x27;est servie des dashboards construits pour visualiser les intrusions, pour montrer aux clients en quoi elle leur apportait de la valeur avec tous les risques qu&#x27;elle a évités.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Certains challenges non techniques peuvent faire <strong>échouer la cloud data platform</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Délivrer de valeur business rapidement</strong> : le business a besoin d&#x27;itérations qui résolvent de vrais besoins au bout de quelques mois maximum.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les auteurs conseillent de partir d&#x27;un use-case pas trop complexe lié à la data, et de l&#x27;implémenter en faisant avancer la plateforme. Et on passe comme ça de use-cases en use-cases.</li>
<li class="nx-my-2">L&#x27;alternative moins intéressante c&#x27;est d&#x27;ingérer toutes les sources possibles, pour finir par trouver des cas d&#x27;usage avec les sources qu&#x27;on supporte déjà.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Faire adopter la plateforme par les utilisateurs</strong> : les utilisateurs ont peut-être déjà leur manière de travailler avec les analytics, en particulier la production de rapport traditionnelle plutôt que la data self-service.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il y a les <em>early adopters</em> qui supportent la nouvelle plateforme, les <em>blockers</em> qui montrent leur scepticisme publiquement, les <em>chickens</em> qui ont peur de tout ce qui est nouveau, et les <em>avoiders</em> qui ne veulent pas toucher à ce qui est nouveau.</li>
<li class="nx-my-2">Quelques conseils pour avoir une meilleure adoption :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">S&#x27;assurer que les premiers utilisateurs soient à la fois des <em>early adopters</em> et des employés influents.</li>
<li class="nx-my-2">Après les <em>early adopters</em>, on peut aider un <em>blocker</em> pour tenter de le retourner. Si ça marche c&#x27;est excellent pour le projet.</li>
<li class="nx-my-2">Les <em>chickens</em> ont besoin de beaucoup de formation.</li>
<li class="nx-my-2">Les <em>avoiders</em> mettront plus de temps, mais c&#x27;est OK.</li>
<li class="nx-my-2">Ce serait bien d&#x27;avoir un sponsor C-level qui soutient le projet, et crée de la visibilité pour lui.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Exemple : Disney avait lancé un concours interne où les utilisateurs data pouvaient montrer leurs résultats avec la plateforme et être récompensés.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>Obtenir et garder la confiance des utilisateurs</strong> : il faut que la qualité de la donnée soit suffisamment bonne pour que les utilisateurs aient confiance en elle.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Prendre en compte l&#x27;utilisateur de la donnée et ses besoins rendre dans le cadre de la <strong>data governance</strong>.</li>
<li class="nx-my-2">Parmi les métriques de qualité à surveiller, il peut y avoir le pourcentage de données correctes, les champs obligatoires remplis, la précision, la consistance, l&#x27;intégrité de la donnée etc.</li>
<li class="nx-my-2">Quand la qualité qu&#x27;on s&#x27;est fixée n&#x27;est plus respectée, il faut :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - prévenir les consommateurs de la donnée.</li>
<li class="nx-my-2">2 - Mettre l&#x27;équipe sur le coup pour régler le problème au plus vite.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>Éviter la formation de d&#x27;un silo autour de la data platform</strong> : la responsabilité de la donnée, des règles de qualité et la mesure de la qualité, les SLA etc. doivent être drivées par le business.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La donnée part des sources potentiellement extérieures, et irrigue l&#x27;organisation à travers divers systèmes. On ne peut pas considérer que la responsabilité de l&#x27;équipe technique s&#x27;arrête au moment où la donnée sort de la plateforme.</li>
<li class="nx-my-2">Il faut constituer des équipes pluridisciplinaires capables de prendre en charge la responsabilité du système de bout en bout : le fonctionnement de la plateforme et l&#x27;utilisation de la donnée.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Prendre en compte les coûts</strong> : pour que la plateforme soit un succès, il faut adopter le point de vue de l&#x27;entreprise.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut s&#x27;intéresser aux manières d&#x27;optimiser les coûts des services cloud (<em>FinOps</em>), et comprendre les trade-offs qui y sont liés.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Et à l&#x27;inverse s&#x27;intéresser à ce que la plateforme permet de rapporter d&#x27;un point de vue business.</li>
</ul>
</li>
<li class="nx-my-2">Exemple : une grande entreprise de télécommunications recueille des données IoT.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La bonne pratique est de faire le processing dans le <em>data lake</em> avec <em style="color:#3d85c6;font-weight:bold;font-style:normal">Spark</em>, mais il se trouve que le business avait un deal avec GCP pour une utilisation illimitée de <em style="color:#3d85c6;font-weight:bold;font-style:normal">BigQuery</em> à prix fixe.</li>
<li class="nx-my-2">Dans ce cas, la bonne chose à faire sera sans doute de faire des concessions sur le design, et faire le processing dans le <em>data warehouse</em>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul><div class="nx-mt-16"></div><div class="nx-mb-8 nx-flex nx-items-center nx-border-t nx-pt-8 dark:nx-border-neutral-800 contrast-more:nx-border-neutral-400 dark:contrast-more:nx-border-neutral-400 print:nx-hidden"><a title="Continuous Discovery Habits" class="nx-flex nx-max-w-[50%] nx-items-center nx-gap-1 nx-py-4 nx-text-base nx-font-medium nx-text-gray-600 nx-transition-colors [word-break:break-word] hover:nx-text-primary-600 dark:nx-text-gray-300 md:nx-text-lg ltr:nx-pr-4 rtl:nx-pl-4" href="/reading-notes/books/continuous-discovery-habits/"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="nx-inline nx-h-5 nx-shrink-0 ltr:nx-rotate-180"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg>Continuous Discovery Habits</a><a title="Designing Data-Intensive Applications" class="nx-flex nx-max-w-[50%] nx-items-center nx-gap-1 nx-py-4 nx-text-base nx-font-medium nx-text-gray-600 nx-transition-colors [word-break:break-word] hover:nx-text-primary-600 dark:nx-text-gray-300 md:nx-text-lg ltr:nx-ml-auto ltr:nx-pl-4 ltr:nx-text-right rtl:nx-mr-auto rtl:nx-pr-4 rtl:nx-text-left" href="/reading-notes/books/designing-data-intensive-applications/">Designing Data-Intensive Applications<svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="nx-inline nx-h-5 nx-shrink-0 rtl:nx-rotate-180"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg></a></div></main></article></div><footer class="nx-bg-gray-100 nx-pb-[env(safe-area-inset-bottom)] dark:nx-bg-neutral-900 print:nx-bg-transparent"><div class="nx-mx-auto nx-flex nx-max-w-[90rem] nx-gap-2 nx-py-2 nx-px-4 nx-hidden"><button title="Change theme" class="nx-h-7 nx-rounded-md nx-px-2 nx-text-left nx-text-xs nx-font-medium nx-text-gray-600 nx-transition-colors dark:nx-text-gray-400 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50" id="headlessui-listbox-button-:Rkt6:" type="button" aria-haspopup="listbox" aria-expanded="false" data-headlessui-state=""><div class="nx-flex nx-items-center nx-gap-2 nx-capitalize"><svg fill="none" viewBox="3 3 18 18" width="12" height="12" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" fill="currentColor" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"></path></svg><span class="">Light</span></div></button></div><hr class="dark:nx-border-neutral-800"/><div class="nx-mx-auto nx-flex nx-max-w-[90rem] nx-justify-center nx-py-12 nx-text-gray-600 dark:nx-text-gray-400 md:nx-justify-start nx-pl-[max(env(safe-area-inset-left),1.5rem)] nx-pr-[max(env(safe-area-inset-right),1.5rem)]">Made by Roman Mkrtchian</div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/books/designing-cloud-data-platforms","query":{},"buildId":"DrK92t89GlVCRkv-RQVRz","assetPrefix":"/reading-notes","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>