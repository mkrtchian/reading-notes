(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[82],{5980:function(e,n,s){(window.__NEXT_P=window.__NEXT_P||[]).push(["/books/effective-kafka",function(){return s(277)}])},277:function(e,n,s){"use strict";s.r(n),s.d(n,{__toc:function(){return a}});var r=s(5893),i=s(2673),l=s(2643),t=s(8397);let a=[{depth:2,value:"1 - Event Streaming Fundamentals",id:"1---event-streaming-fundamentals"},{depth:2,value:"2 - Introducing Apache Kafka",id:"2---introducing-apache-kafka"},{depth:2,value:"3 - Architecture and Core Concepts",id:"3---architecture-and-core-concepts"},{depth:2,value:"4 - Installation",id:"4---installation"},{depth:2,value:"5 - Getting Started",id:"5---getting-started"},{depth:2,value:"6 - Design Considerations",id:"6---design-considerations"},{depth:2,value:"7 - Serialization",id:"7---serialization"},{depth:2,value:"8 - Bootstrapping and Advertised Listeners",id:"8---bootstrapping-and-advertised-listeners"},{depth:2,value:"9 - Broker Configuration",id:"9---broker-configuration"},{depth:2,value:"10 - Client Configuration",id:"10---client-configuration"},{depth:2,value:"11 - Robust Configuration",id:"11---robust-configuration"},{depth:2,value:"12 - Batching and Compression",id:"12---batching-and-compression"},{depth:2,value:"13 - Replication and Acknowledgements",id:"13---replication-and-acknowledgements"},{depth:2,value:"14 - Data Retention",id:"14---data-retention"},{depth:2,value:"15 - Group Membership and Partition Assignment",id:"15---group-membership-and-partition-assignment"},{depth:2,value:"16 - Security",id:"16---security"},{depth:2,value:"17 - Quotas",id:"17---quotas"},{depth:2,value:"18 - Transactions",id:"18---transactions"}];function o(e){let n=Object.assign({h1:"h1",h2:"h2",ul:"ul",li:"li",strong:"strong",em:"em",code:"code",a:"a",pre:"pre",span:"span",p:"p"},(0,l.a)(),e.components);return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h1,{children:"Effective Kafka"}),"\n",(0,r.jsx)(n.h2,{id:"1---event-streaming-fundamentals",children:"1 - Event Streaming Fundamentals"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"syst\xe8mes distribu\xe9s"})," sont plus complexes que les syst\xe8mes non distribu\xe9s, ils d\xe9placent une partie de la ",(0,r.jsx)(n.strong,{children:"complexit\xe9 du local vers le global"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La raison pour laquelle on les utilise c'est qu'ils permettent de d\xe9composer le syst\xe8me en plus petits probl\xe8mes qu'on va pouvoir diviser entre plusieurs \xe9quipes."}),"\n",(0,r.jsx)(n.li,{children:"La complexit\xe9 globale peut \xeatre r\xe9duite par certaines techniques, par exemple les messages asynchrones."}),"\n",(0,r.jsx)(n.li,{children:"On y trouve des \xe9checs partiels, intermittents, ou m\xeame byzantins (les nœuds envoient des informations fausses)."}),"\n",(0,r.jsx)(n.li,{children:"Le probl\xe8me le plus important est sans doute celui de la consistance."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'",(0,r.jsx)(n.strong,{children:"event-driven architecture"})," (EDA) consiste \xe0 avoir des ",(0,r.jsx)(n.em,{children:"emitters"})," envoyant des notifications d'event \xe0 des ",(0,r.jsx)(n.em,{children:"consumers"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les emitters n'ont aucune connaissance des consumers. Et de m\xeame les consumers n'ont pas connaissance des emitters."}),"\n",(0,r.jsx)(n.li,{children:"Les notifications d'event sont immutables, que ce soit c\xf4t\xe9 emitter ou consumer."}),"\n",(0,r.jsxs)(n.li,{children:["L'EDA est la mani\xe8re ",(0,r.jsx)(n.strong,{children:"la plus d\xe9coupl\xe9e"})," de faire communiquer des composants entre eux.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le seul couplage sera dans le contenu des messages qui transitent."}),"\n",(0,r.jsxs)(n.li,{children:["Imaginons un syst\xe8me d'e-commerce, avec une plateforme BI et un CRM. Il leur suffira de consommer les events d'achat et d'y r\xe9agir en toute ind\xe9pendance.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Parmi les autres possibilit\xe9s qu'on aurait pour l'exemple e-commerce :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut les mettre dans un monolith (non-modulaire), mais la complexit\xe9 risque d'augmenter \xe0 mesure que le mod\xe8le global est enrichi."}),"\n",(0,r.jsx)(n.li,{children:"On peut utiliser des patterns d'int\xe9gration : des messages synchrones envoy\xe9s par le composant e-commerce ou par les deux autres. Dans ce cas on se rapproche du distributed monolith parce que les composants ne seront pas ind\xe9pendants."}),"\n",(0,r.jsxs)(n.li,{children:["On peut utiliser la ",(0,r.jsx)(n.em,{children:"data decapsulation"}),", o\xf9 les composants BI et CRM viennent lire la DB du composant e-commerce. Dans ce cas on se retrouve dans un mode “get rich quick scheme” qui m\xe8ne toujours \xe0 des pleurs. Le couplage est maximal."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Cet exemple montre que ",(0,r.jsx)(n.strong,{children:"l'EDA scale de mani\xe8re lin\xe9aire"}),", alors qu'avec les approches plus coupl\xe9es, la complexit\xe9 explose quand on scale le nombre de composants."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'EDA est beaucoup ",(0,r.jsx)(n.strong,{children:"plus r\xe9silient"})," que les approches coupl\xe9es : si un composant est en situation d'\xe9chec, il a peu de chances d'impacter d'autres composants.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Si on reprend l'exemple d'e-commerce :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dans le cas o\xf9 le composant d'e-commerce est en situation d'\xe9chec, les autres composants vont continuer \xe0 pouvoir fonctionner, mais simplement ils ne recevront plus de nouveaux events."}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas o\xf9 par exemple le CRM est en situation d'\xe9chec, les events continueront d'arriver, et il pourra toujours rattraper son retard d\xe8s qu'il est r\xe9tabli."}),"\n",(0,r.jsx)(n.li,{children:"On peut aussi pr\xe9voir une mesure pour que si le message broker est en situation d'\xe9chec, l'\xe9metteur puisse publier les events localement, pour les mettre dans le message broker plus tard."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Dans un syst\xe8me coupl\xe9, un composant qui est en \xe9chec peut entra\xeener des ",(0,r.jsx)(n.em,{children:"correlated failures"})," chez les autres qui en d\xe9pendent.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut aussi avoir des ",(0,r.jsx)(n.em,{children:"congestive collapses"})," dans le cas o\xf9 certains composants sont temporairement surcharg\xe9s, et que les requ\xeates synchrones m\xe8nent \xe0 avoir des timeouts, puis \xe0 envoyer plus de requ\xeates."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'EDA a aussi des avantages en termes de ",(0,r.jsx)(n.strong,{children:"consistance"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il favorise l'ownership d'un \xe9l\xe9ment stateful par un composant unique, les autres composants recevant les notifications d'event ne pouvant pas modifier cet \xe9tat."}),"\n",(0,r.jsxs)(n.li,{children:["En dehors du composant owner, les events sont rejouables ",(0,r.jsx)(n.strong,{children:"dans le bon ordre"}),", garantissant une ",(0,r.jsx)(n.em,{children:"sequential consistency"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'EDA n'est cependant pas adapt\xe9e dans certains cas.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Elle n'est ",(0,r.jsx)(n.strong,{children:"pas adapt\xe9e aux interactions synchrones"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Par contre, dans les cas o\xf9 on peut l'utiliser, elle permet des am\xe9liorations significatives des aspects non fonctionnels."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'",(0,r.jsx)(n.strong,{children:"event streaming"})," est un moyen d'obtenir un stream ",(0,r.jsx)(n.strong,{children:"durable"})," et ",(0,r.jsx)(n.strong,{children:"ordonn\xe9"})," d'events ",(0,r.jsx)(n.strong,{children:"immutables"}),", d\xe9livr\xe9s aux consumers qui ont souscrit.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'event streaming n'est pas n\xe9cessaire pour impl\xe9menter l'EDA, qui peut d'ailleurs \xeatre impl\xe9ment\xe9 dans un monolith (cf. outils comme React qui sont bas\xe9s sur des events)."}),"\n",(0,r.jsxs)(n.li,{children:["En revanche l'",(0,r.jsx)(n.strong,{children:"event streaming est pertinent"})," comme choix face aux solutions concurrentes (comme les message queues) ",(0,r.jsx)(n.strong,{children:"dans le cadre d'EDA distribu\xe9es"}),", parce qu'il a \xe9t\xe9 con\xe7u pour \xe7a.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'event streaming supporte nativement l'immutabilit\xe9 des events."}),"\n",(0,r.jsx)(n.li,{children:"Il supporte la garantie d'ordre des events."}),"\n",(0,r.jsx)(n.li,{children:"Il supporte le fait d'avoir de multiples consumers."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2---introducing-apache-kafka",children:"2 - Introducing Apache Kafka"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Kafka est une plateforme d'event streaming, mais elle comprend aussi un \xe9cosyst\xe8me entier qui permet l'impl\xe9mentation d'EDAs."}),"\n",(0,r.jsxs)(n.li,{children:["L'event streaming est r\xe9cent compar\xe9 aux formes traditionnelles de messaging (MQ-style).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il n'y a pas de standard, mais Kafka est le leader du domaine, et son fonctionnement sert de mod\xe8le pour les solutions concurrentes comme ",(0,r.jsx)(t.U,{children:"Azure Event Hubs"})," et ",(0,r.jsx)(t.U,{children:"Apache Pulsar"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Historiquement, Kafka a \xe9t\xe9 open-sourc\xe9 en 2011 par LinkedIn, et confi\xe9 \xe0 la fondation Apache.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il avait \xe9t\xe9 con\xe7u notamment pour g\xe9rer les events d'activit\xe9 des utilisateurs."}),"\n",(0,r.jsx)(n.li,{children:"En 2019, LinkedIn op\xe9rait 100 clusters Kafka, pour un total de 100 000 topics et 7 millions de partitions."}),"\n",(0,r.jsxs)(n.li,{children:["Aujourd'hui Kafka est utilis\xe9 par des g\xe9ants de la tech, pour des usages comme le real-time analytics, la data ingestion, le log aggregation et le messaging pour l'EDA.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Uber par exemple l'utilise pour g\xe9rer au total plus de 1000 milliards d'events par jour."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Parmi les usages qui permettent l'EDA, Kafka supporte :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Publish-subscribe"})," : un emitter publie des events, et plusieurs consumers les consomment sans que ces noeuds se connaissent.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est notamment utilis\xe9 pour des microservices avec un faible couplage."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Log aggregation"})," : un ensemble de sources publient des events sous forme de log (soit applicatifs, soit d'infrastructure), qu'on va ensuite agr\xe9ger au sein du m\xeame topic, pour le consommer dans une DB optimis\xe9e pour la lecture, comme ",(0,r.jsx)(t.U,{children:"Elasticsearch"})," ou ",(0,r.jsx)(t.U,{children:"HBase"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Log shipping"})," : il s'agit de streamer des logs depuis une DB master vers un topic o\xf9 plusieurs DB followers vont consommer et se mettre \xe0 jour.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ce pattern permet notamment d'impl\xe9menter l'event sourcing."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"SEDA pipelines"})," : le Stage Event-Driven Architecture est l'impl\xe9mentation d'une pipeline d'events, o\xf9 on fait une op\xe9ration \xe0 chaque \xe9tape, avant d'\xe9mettre un event modifi\xe9 pour l'\xe9tape suivante.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est typiquement utilis\xe9 avec les data warehouses, data lakes, le reporting et autres outils de BI."}),"\n",(0,r.jsx)(n.li,{children:"On peut voir le log aggregation comme une forme de SEDA."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"CEP"})," : le Complex Event Processing consiste en un composant qui consomme des events de multiples sources, et en extrait l'information pertinente.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il a souvent besoin d'un stockage pour se rappeler les patterns d\xe9j\xe0 vus et y r\xe9agir."}),"\n",(0,r.jsx)(n.li,{children:"\xc7a peut \xeatre par exemple pour le trading algorithmique, l'analyse des menaces de s\xe9curit\xe9, l'analyse de fraude en temps r\xe9el etc."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Event-sourced CQRS"})," : Kafka se place entre la DB master et les DBs de projection, en permettant de les alimenter chacune au travers du concept de ",(0,r.jsx)(n.em,{children:"consumer groups"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La diff\xe9rence avec le log shipping c'est que le log shipping op\xe8re plut\xf4t \xe0 l'int\xe9rieur d'un subdomain, alors que le CQRS peut aussi op\xe9rer \xe0 travers les subdomains."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"3---architecture-and-core-concepts",children:"3 - Architecture and Core Concepts"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Kafka est compos\xe9 de plusieurs types de noeuds :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Broker nodes"})," : ce sont les composants principaux de Kafka, ils s'occupent des op\xe9rations I/O et de la persistance.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ces nœuds sont des processus Java."}),"\n",(0,r.jsxs)(n.li,{children:["Chaque partition est sous la responsabilit\xe9 d'un nœud master qui peut \xe9crire dedans, les followers en ont une copie et peuvent \xeatre lus.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Un m\xeame nœud peut \xeatre master pour certaines partitions, et follower pour d'autres."}),"\n",(0,r.jsx)(n.li,{children:"L'ownership peut passer \xe0 un autre nœud en cas de besoin (op\xe9ration sp\xe9ciale qui le n\xe9cessite ou \xe9chec du nœud qui \xe9tait master de la partition)."}),"\n",(0,r.jsxs)(n.li,{children:["Concernant l'attribution de l'ownership, \xe7a se fait d'abord en \xe9lisant un des nœuds comme ",(0,r.jsx)(n.em,{children:"cluster controller"}),", puis celui-ci assigne l'ownership des partitions au gr\xe9 des besoins."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Augmenter le nombre de nœuds brokers constitue un moyen de scaler Kafka.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut am\xe9liorer la ",(0,r.jsx)(n.em,{children:"durability"})," en ayant plusieurs copies de chaque partition (jusqu'\xe0 autant que le nombre de nœuds)."]}),"\n",(0,r.jsxs)(n.li,{children:["On peut am\xe9liorer l'",(0,r.jsx)(n.em,{children:"availability"})," pour les donn\xe9es en lecture."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Zookeeper nodes"})," : Zookeeper est un projet open source distinct de Kafka.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ses nœuds sont charg\xe9s d'\xe9lire le broker qui sera le ",(0,r.jsx)(n.em,{children:"cluster controller"}),", de garantir qu'il n'y en ait qu'un, et d'en r\xe9\xe9lire un s'il n'est plus op\xe9rationnel."]}),"\n",(0,r.jsx)(n.li,{children:"Ils fournissent aussi diverses m\xe9tadonn\xe9es \xe0 propos du cluster, par exemple l'\xe9tat des diff\xe9rents nœuds, des informations de quotas, les access control list etc."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Producers"})," : les applications clientes qui \xe9crivent dans les topics.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Un producer communique avec Kafka via TCP, avec une connexion par broker node."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Consumers"})," : les applications clientes qui lisent des topics."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le fonctionnement de Kafka se base sur des notions d'ordering venant de la th\xe9orie des ensembles (",(0,r.jsx)(n.em,{children:"set theory"}),").","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"total ordering"})," consiste \xe0 avoir un ensemble d'\xe9l\xe9ments dont une ",(0,r.jsx)(n.strong,{children:"seule configuration est possible"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut l'illustrer avec un set de nombres entiers ",(0,r.jsx)(n.code,{children:"{ 2, 4, 6 }"}),". Si on enl\xe8ve l'\xe9l\xe9ment 4, puis qu'on le remet, il ne pourra qu'\xeatre \xe0 la 2\xe8me place, avant le 6 et apr\xe8s le 2."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"partial ordering"})," consiste \xe0 avoir un ensemble d'\xe9l\xe9ments ordonn\xe9s selon un crit\xe8re sp\xe9cifique, mais dont ",(0,r.jsx)(n.strong,{children:"plusieurs configurations sont possibles"})," pour satisfaire le crit\xe8re.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Par exemple, si on a des entiers qu'on veut ordonner de mani\xe8re \xe0 ce que le diviseur d'un nombre soit toujours apr\xe8s ce nombre, et qu'on a ",(0,r.jsx)(n.code,{children:"[ 2, 3, 4, 6, 9, 8 ]"}),", on peut tout autant les organiser en ",(0,r.jsx)(n.code,{children:"[ 3, 2, 6, 9, 4, 8 ]"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La notion de ",(0,r.jsx)(n.strong,{children:"causal order"})," indique qu'on respecte le fait que certains \xe9l\xe9ments ont une relation ",(0,r.jsx)(n.em,{children:"happened-before"})," entre eux qui est respect\xe9e, quel que soit leur ordre d'arriv\xe9e \xe0 destination.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cette notion vient de l'\xe9tude des syst\xe8mes distribu\xe9s (et non de la th\xe9orie des ensembles)."}),"\n",(0,r.jsx)(n.li,{children:"Elle est une forme de partial ordering."}),"\n",(0,r.jsx)(n.li,{children:"Elle est la cons\xe9quence du fait qu'il n'y ait pas d'horloge commune \xe0 l'ensemble des nœuds d'un syst\xe8me distribu\xe9, et que les events peuvent arriver dans le mauvais ordre."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"records"})," sont l'unit\xe9 principale de Kafka. Ils correspondent aux events.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ils sont compos\xe9s :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["D'attributs assez classiques : la ",(0,r.jsx)(n.em,{children:"value"})," qui peut \xeatre sous forme binaire, des ",(0,r.jsx)(n.em,{children:"headers"})," pour donner des m\xe9tadonn\xe9es, la ",(0,r.jsx)(n.em,{children:"partition"})," associ\xe9e au record, l'",(0,r.jsx)(n.em,{children:"offset"})," par rapport aux autres records de la partition, un ",(0,r.jsx)(n.em,{children:"timestamp"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La combinaison ",(0,r.jsx)(n.em,{children:"partition"})," + ",(0,r.jsx)(n.em,{children:"offset"})," permet d'identifier un record de mani\xe8re unique."]}),"\n",(0,r.jsxs)(n.li,{children:["L'",(0,r.jsx)(n.em,{children:"offset"})," est une valeur enti\xe8re qui ne peut qu'augmenter, m\xeame s'il peut y avoir des gaps entre deux offsets qui se suivent (cf. compaction chapitre 14)."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["D'un champ binaire un peu plus inhabituel qui est la ",(0,r.jsx)(n.em,{children:"key"}),", et qui est utilis\xe9e par Kafka pour associer les records avec une m\xeame partition."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Kafka est largement utilis\xe9 pour traiter des events \xe0 l'int\xe9rieur d'un bounded context, tout comme les events entre bounded contexts."}),"\n",(0,r.jsxs)(n.li,{children:["Il est aussi de plus en plus utilis\xe9 en remplacement des brokers traditionnels (",(0,r.jsx)(t.U,{children:"RabbitMQ"}),", ",(0,r.jsx)(t.U,{children:"ActiveMQ"}),", ",(0,r.jsx)(t.U,{children:"AWS SQS/SNS"}),", ",(0,r.jsx)(t.U,{children:"Google Cloud Pub/Sub"})," etc.). Dans ce cas, les records ne correspondent pas forc\xe9ment \xe0 des events, et on n'est pas forc\xe9ment dans de l'EDA."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"partitions"})," sont l'unit\xe9 de stream principale qui contient les records.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les records d'une m\xeame partition sont ",(0,r.jsx)(n.em,{children:"totally ordered"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Les records publi\xe9s dans une partition par un m\xeame producer seront donc aussi ",(0,r.jsx)(n.em,{children:"causally ordered"})," (la pr\xe9c\xe9dence respect\xe9e).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"En revanche, si plusieurs producers publient dans la m\xeame partition sans eux-m\xeames se synchroniser entre eux, les records de chaque producer seront causally ordered pour un m\xeame producer, mais ne le seront pas entre les producers (\xe7a d\xe9pendra de qui l'a emport\xe9 pour publier plus vite)."}),"\n",(0,r.jsx)(n.li,{children:"Publier dans plusieurs partitions ne r\xe8gle pas ce probl\xe8me : les records de chaque producer ne seront pas causally ordered. Si on veut un tel ordre, il faut un seul producer."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"topics"})," sont des unit\xe9s logiques qui regroupent des partitions.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Vu qu'il s'agit d'une union de partitions qui sont chacune ",(0,r.jsx)(n.em,{children:"totally ordered"}),", les topics peuvent \xeatre consid\xe9r\xe9s comme ",(0,r.jsx)(n.em,{children:"partially ordered"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut donc \xe9crire dans les records de plusieurs partitions en parall\xe8le, et n'assurer que l'ordre des records dans chaque partition."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut indiquer \xe0 la main la partition vers laquelle on veut publier un record, mais g\xe9n\xe9ralement on indique la key, qui sera hash\xe9e pour correspondre avec une partition donn\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Dans le cas o\xf9 on ",(0,r.jsx)(n.strong,{children:"r\xe9duit le nombre de partitions"}),", les messages peuvent \xeatre ",(0,r.jsx)(n.strong,{children:"d\xe9truits"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Dans le cas o\xf9 on ",(0,r.jsx)(n.strong,{children:"augmente le nombre de partitions"}),", on peut ",(0,r.jsx)(n.strong,{children:"perdre l'ordre"})," qu'on voulait conserver avec nos keys, puisque la fonction de hash redirigera vers une autre partition."]}),"\n",(0,r.jsxs)(n.li,{children:["M\xeame si on a un nombre de partitions sup\xe9rieur au nombre de keys, il est possible que deux keys m\xe8nent vers la m\xeame partition.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La seule chose qui est garantie, c'est qu'avec la m\xeame key, et si le nombre de partitions ne change pas, l'ordre sera respect\xe9."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Un consumer peut souscrire \xe0 un topic en tant que membre d'un ",(0,r.jsx)(n.strong,{children:"consumer group"}),", et b\xe9n\xe9ficier d'un m\xe9canisme de ",(0,r.jsx)(n.strong,{children:"load balancing"})," avec d'autres consumers.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le 1er consumer qui souscrit se voit assigner toutes les partitions. Quand un 2\xe8me consumer souscrit au topic, il se voit assigner environ la moiti\xe9 des partitions qui \xe9taient assign\xe9es au 1er. et ainsi de suite."}),"\n",(0,r.jsxs)(n.li,{children:["Les consumers ne peuvent que lire les events sans impact sur eux.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Une des cons\xe9quences c'est qu'on peut en ajouter beaucoup sans stresser le cluster. Et c'est une des diff\xe9rences par rapport aux brokers classiques."}),"\n",(0,r.jsx)(n.li,{children:"Ils maintiennent les offsets de l\xe0 o\xf9 ils en sont pour chacune des partitions qu'ils sont en train de lire."}),"\n",(0,r.jsx)(n.li,{children:"Les consumers de diff\xe9rents consumer groups n'ont pas d'impact les uns sur les autres."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Kafka s'assure qu'il n'y a ",(0,r.jsx)(n.strong,{children:"qu'un consumer d'un m\xeame consumer group"})," qui peut lire dans une ",(0,r.jsx)(n.strong,{children:"m\xeame partition"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si un consumer ne lit plus de messages jusqu'\xe0 d\xe9passer un timeout, Kafka assignera ses partitions \xe0 un autre consumer, consid\xe9r\xe9 comme sain, du m\xeame groupe."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour que Kafka puisse r\xe9assigner une partition \xe0 un autre consumer en gardant le bon offset, ou redonner le bon offset \xe0 un consumer qui se reconnecte apr\xe8s s'\xeatre d\xe9connect\xe9, il faut que ",(0,r.jsx)(n.strong,{children:"les consumers communiquent leurs offsets \xe0 Kafka"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On appelle ce processus ",(0,r.jsx)(n.em,{children:"committing offsets"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["On peut avoir un contr\xf4le sur le ",(0,r.jsx)(n.strong,{children:"moment o\xf9 on va faire ce commit"}),", et donc agir sur la ",(0,r.jsx)(n.strong,{children:"garantie de delivery"})," des messages, c'est-\xe0-dire le fait qu'ils soient int\xe9gralement trait\xe9s.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut passer d'une strat\xe9gie ",(0,r.jsx)(n.em,{children:"at-most-once"})," \xe0 une strat\xe9gie ",(0,r.jsx)(n.em,{children:"at-least-once"})," en faisant le commit apr\xe8s l'ex\xe9cution de la callback au lieu du moment o\xf9 le message est pris par le consumer."]}),"\n",(0,r.jsxs)(n.li,{children:["Par d\xe9faut, Kafka va faire un commit toutes les 5 secondes, sauf si un record est toujours en train d‘\xeatre ex\xe9cut\xe9, auquel cas il attendra la prochaine occasion 5 secondes plus tard.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut r\xe9gler cette dur\xe9e de 5 secondes \xe0 une autre valeur avec la configuration ",(0,r.jsx)(n.code,{children:"auto.commit.interval.ms"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"\xc7a implique que si le record est ex\xe9cut\xe9, et que dans les quelques secondes apr\xe8s le cluster bascule la partition sur un autre consumer, on risque de ne pas avoir commit\xe9 et de r\xe9ex\xe9cuter la callback du record dans le nouveau consumer."}),"\n",(0,r.jsxs)(n.li,{children:["Si on veut avoir le contr\xf4le sur le moment exact o\xf9 on veut faire le commit, on peut d\xe9sactiver le commit automatique (configuration ",(0,r.jsx)(n.code,{children:"enable.auto.commit"})," \xe0 ",(0,r.jsx)(n.code,{children:"false"}),"), et le faire \xe0 la main dans le consumer."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le commit peut se faire via un canal in-memory asynchrone pour ne pas bloquer le consumer, avec la possibilit\xe9 de fournir une callback qui sera ex\xe9cut\xe9e par Kafka quand le commit aura \xe9t\xe9 pris en compte","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ou alors le consumer peut aussi utiliser un appel synchrone pour le commit."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Un cas classique est de traiter les records avec une strat\xe9gie ",(0,r.jsx)(n.em,{children:"at-least-once"})," par batch, qu'on appelle ",(0,r.jsx)(n.em,{children:"poll-process loop"})," :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le consumer garde un buffer de records qu'il prefetch en arri\xe8re-plan."}),"\n",(0,r.jsx)(n.li,{children:"Il traite les records un par un (ou parfois en parall\xe8le avec un pool de threads si c'est OK d'un point de vue business)."}),"\n",(0,r.jsx)(n.li,{children:"Quand on arrive au dernier record, il fait le commit de l'offset."}),"\n",(0,r.jsx)(n.li,{children:"Puis il prend le batch suivant et recommence."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["M\xeame si c'est moins courant, il est possible de souscrire un consumer ",(0,r.jsx)(n.strong,{children:"sans qu'il soit membre d'un consumer group"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Dans ce cas, il ne b\xe9n\xe9ficiera pas des divers m\xe9canismes associ\xe9s aux consumer groups : load balancing, rebalancing en cas d'\xe9chec, d\xe9tection de l'\xe9chec par inactivit\xe9, persistance de l'offset.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il devra indiquer les couples topic/partition auxquels il souscrit, et devra persister ses propres offsets lui-m\xeame dans un store."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il peut y avoir deux cas d'usages :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le besoin d'avoir vraiment le contr\xf4le sur la mani\xe8re de consommer les messages, en stockant soi-m\xeame son offset etc.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Mais ce cas d'usage est tr\xe8s rare, et difficile \xe0 impl\xe9menter correctement."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Un consumer \xe9ph\xe9m\xe8re qui est l\xe0 juste pour monitorer ou d\xe9bugger un topic, sans avoir besoin de persister d'offsets.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est ce que fait par exemple l'outil Kafdrop qui permet de visualiser les messages pr\xe9sents dans les partitions via une interface web : \xe0 chaque fois il attache un consumer sans groupe."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"4---installation",children:"4 - Installation"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il y a 4 m\xe9thodes pour installer Kafka (et Zookeeper) :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["En utilisant les images Docker.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si on choisit une autre m\xe9thode que Docker, on aura juste besoin d'avoir d'avoir un JDK d'install\xe9."}),"\n",(0,r.jsx)(n.li,{children:"La m\xe9thode Kafka dans Docker est la plus imm\xe9diate pour avoir Kafka qui tourne, mais elle est aussi connue pour \xeatre difficile \xe0 configurer si on veut personnaliser."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"En utilisant un package manager (yum, apt, homebrew etc.)"}),"\n",(0,r.jsx)(n.li,{children:"En clonant le d\xe9p\xf4t git et en installant depuis les sources."}),"\n",(0,r.jsxs)(n.li,{children:["En t\xe9l\xe9chargeant des binaires sur le site de Kafka.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il suffit de t\xe9l\xe9charger un tar.gz et de le d\xe9sarchiver, pour obtenir les ex\xe9cutables de Kafka qu'on peut lancer avec notre JDK."}),"\n",(0,r.jsx)(n.li,{children:"Le livre part l\xe0-dessus."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La configuration de Kafka peut se faire en changeant les fichiers de conf dans le dossier ",(0,r.jsx)(n.code,{children:"config/"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut voir les configs prises en compte dans les logs, \xe0 chaque fois qu'on d\xe9marre Kafka."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"5---getting-started",children:"5 - Getting Started"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On a du tooling livr\xe9 avec Kafka sous forme de scripts shell pour le g\xe9rer en CLI.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut par exemple cr\xe9er un topic puis y ajouter des records."}),"\n",(0,r.jsx)(n.li,{children:"On peut changer des offsets pour un consumer group."}),"\n",(0,r.jsx)(n.li,{children:"etc."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'auteur ",(0,r.jsx)(n.strong,{children:"d\xe9conseille de laisser Kafka cr\xe9er automatiquement les topics"})," (",(0,r.jsx)(n.code,{children:"auto.create.topics.enable"})," \xe0 ",(0,r.jsx)(n.code,{children:"true"}),") pour plusieurs raisons :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les valeurs par d\xe9faut de Kafka remontent \xe0 sa cr\xe9ation, et n'ont pas forc\xe9ment \xe9t\xe9 pens\xe9s pour l'usage qu'il a en g\xe9n\xe9ral aujourd'hui."}),"\n",(0,r.jsx)(n.li,{children:"Quand on cr\xe9e un topic, on devrait d\xe9cider du nombre de partitions en fonction des crit\xe8res de parall\xe9lisation. Donc un nombre par d\xe9faut ne va en g\xe9n\xe9ral pas \xeatre satisfaisant."}),"\n",(0,r.jsx)(n.li,{children:"La cr\xe9ation de topic \xe0 la lecture est encore plus probl\xe9matique, puisqu'on va avoir des lecteurs qui croient lire quelque chose et qui ne lisent rien."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.em,{children:"lag"})," est la diff\xe9rence entre l'offset qui a \xe9t\xe9 commit\xe9 par un consumer sur une partition donn\xe9e et le ",(0,r.jsx)(n.em,{children:"high water mark"})," de la partition (c'est-\xe0-dire le dernier record dispo \xe0 la consommation)."]}),"\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"suppression d'un topic est asynchrone"}),", c'est-\xe0-dire qu'elle sera effectivement r\xe9alis\xe9e quelque part dans le futur par Kafka, apr\xe8s qu'on l'ait demand\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour nos ",(0,r.jsx)(n.strong,{children:"tests d'int\xe9gration"}),", il va donc falloir trouver des solutions :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"1 - Supprimer le consumer group, les offsets enregistr\xe9s, ou mettre les offsets au high water mark (tous les trois ont le m\xeame effet)."}),"\n",(0,r.jsxs)(n.li,{children:["2 - Tronquer les partitions en avan\xe7ant le ",(0,r.jsx)(n.em,{children:"low water mark"})," (le record le plus ancien disponible \xe0 la consommation)."]}),"\n",(0,r.jsxs)(n.li,{children:["3 - Utiliser des noms de topics uniques, et les supprimer au fil de l'eau (si on ne les r\xe9utilise pas, le fait qu'ils soient supprim\xe9s de mani\xe8re asynchrone ne pose probl\xe8me).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cette derni\xe8re option est celle recommand\xe9e par l'auteur."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Supprimer les offsets pour un consumer group et sur un topic donn\xe9, fait que la prochaine fois que ces consumers voudront consommer le topic, ils seront par d\xe9faut assign\xe9s au dernier record.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ou au premier en fonction de l'option ",(0,r.jsx)(n.code,{children:"auto.offset.reset"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Si on supprimer un consumer group, c'est comme si on supprimait ses offsets pour l'ensemble des topics o\xf9 il avait consomm\xe9 des records."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'essentiel des classes du client Java se r\xe9sument \xe0 :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["1 - L'interface ",(0,r.jsx)(n.code,{children:"Producer"}),", l'impl\xe9mentation ",(0,r.jsx)(n.code,{children:"KafkaProducer"}),", et la repr\xe9sentation du record ",(0,r.jsx)(n.code,{children:"ProducerRecord"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["2 - La m\xeame chose c\xf4t\xe9 consumer : ",(0,r.jsx)(n.code,{children:"Consumer"}),", ",(0,r.jsx)(n.code,{children:"KafkaConsumer"}),", ",(0,r.jsx)(n.code,{children:"ConsumerRecord"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Et c'est \xe0 peu pr\xe8s la m\xeame chose pour les autres clients qui s'en inspirent."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'option ",(0,r.jsx)(n.code,{children:"enable.idempotence"})," \xe0 la cr\xe9ation du producer permet de garder des s\xe9quences pour les couples producer/partition, pour s'assurer qu'un record n'est pas publi\xe9 deux fois ou dans le mauvais ordre, dans le cas o\xf9 il y aurait un timeout pendant une publication.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'auteur conseille de l'activer."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Il faut bien penser \xe0 fermer la connexion, sinon on risque de monopoliser des ressources c\xf4t\xe9 client et serveur."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"6---design-considerations",children:"6 - Design Considerations"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["A propos de la s\xe9paration des ",(0,r.jsx)(n.strong,{children:"responsabilit\xe9s"})," entre producers et consumers.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Dans le cas d'un ",(0,r.jsx)(n.strong,{children:"event-oriented broadcast"}),", c'est le producer qui a la responsabilit\xe9 de la configuration du topic et du format des donn\xe9es publi\xe9es.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est utile pour que les producers ne connaissent pas du tout les consumers, et qu'on reste sur du couplage faible."}),"\n",(0,r.jsxs)(n.li,{children:["Le fait qu'on puisse avoir plusieurs consumers aux int\xe9r\xeats diff\xe9rents montre qu'il est plus pertinent que le producer ait la responsabilit\xe9 des messages.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour autant, on peut se demander comment faire en sorte que les consumers soient tous satisfaits par le mod\xe8le propos\xe9 par le producer."}),"\n",(0,r.jsxs)(n.li,{children:["On peut mettre en place du ",(0,r.jsx)(n.strong,{children:"topic conditioning"}),", c'est-\xe0-dire compartimenter les probl\xe8mes li\xe9s \xe0 chaque consumer avec une architecture SEDA, contenant pour chaque consumer (ou groupe de consumers aux int\xe9r\xeats communs), un module de conditionnement publiant \xe0 son tour dans un topic pour le consumer vis\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cette solution permet de s\xe9parer les responsabilit\xe9s, et laisser le producer avec son mod\xe8le, et chaque consumer avec le sien."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour du ",(0,r.jsx)(n.strong,{children:"peer-to-peer messaging"}),", c'est au contraire le consumer qui a la responsabilit\xe9 de la configuration du topic et du format de donn\xe9es.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le consumer envoie des commandes au producer, pour que celui-ci lui pr\xe9pare des donn\xe9es qu'il mettra dans Kafka."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Dans tous les cas, les flows doivent \xeatre design\xe9s avec soin, en prenant en compte les besoins des producers et des consumers."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Concernant la question du ",(0,r.jsx)(n.strong,{children:"parall\xe9lisme"})," dans le cas o\xf9 on veut laisser plusieurs consumers consommer depuis plusieurs partitions, il y a des facteurs \xe0 prendre en compte pour obtenir quelque chose de performant.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["L'organisation des partitions d'un topic est ",(0,r.jsx)(n.strong,{children:"consumer-driven"}),", du fait du design de Kafka. Le consumer se pose la question de la ",(0,r.jsx)(n.strong,{children:"bonne cl\xe9 de partitionnement"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"En pratique, le consumer doit trouver une entit\xe9 suffisamment stable pour que son identifiant puisse servir de cl\xe9 de partitionnement."}),"\n",(0,r.jsx)(n.li,{children:"Par exemple, si on a des tournois de football, avec des events repr\xe9sentant ce qui se passe dans le jeu, on peut prendre le match comme entit\xe9 stable, et avoir tous les events d'un m\xeame match ordonn\xe9s dans une m\xeame partition."}),"\n",(0,r.jsxs)(n.li,{children:["Si on garde l'exemple mais qu'un consumer est int\xe9ress\xe9 par le d\xe9roulement du tournoi, alors il nous faudra garder l'ordre des matchs, et donc choisir comme entit\xe9 stable le tournoi.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Mais on aura alors moins de possibilit\xe9s de parall\xe9lisation puisqu'on ne pourra plus parall\xe9liser les matchs."}),"\n",(0,r.jsx)(n.li,{children:"L'autre possibilit\xe9 c'est de laisser le consumer qui a besoin de l'ordre des tournois le reconstituer lui-m\xeame, avec des infos qu'il a dans les events."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Se pose ensuite la question du ",(0,r.jsx)(n.strong,{children:"nombre de partitions du topic"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour rappel on ne peut pas enlever de partitions sans d\xe9truire de messages, et en rajouter fait que la fonction de hash n'envoie plus dans les m\xeames partitions qu'avant le rajout (donc il vaut mieux \xe9viter si on veut garder l'ordre des messages)."}),"\n",(0,r.jsxs)(n.li,{children:["Une solution peut \xeatre d'avoir d\xe8s le d\xe9but un ",(0,r.jsx)(n.strong,{children:"nombre suffisamment \xe9lev\xe9 de partitions par topic"}),", pour ne jamais avoir \xe0 les augmenter.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Attention cependant, trop de partitions peut causer des probl\xe8mes de performance."}),"\n",(0,r.jsxs)(n.li,{children:["Confluent recommande un nombre de partitions maximal par broker de ",(0,r.jsx)(n.code,{children:"100 x b x r"})," partitions (avec ",(0,r.jsx)(n.code,{children:"b"})," le nombre de brokers du cluster, et ",(0,r.jsx)(n.code,{children:"r"})," le facteur de r\xe9plication)."]}),"\n",(0,r.jsx)(n.li,{children:"Si on atteint le nombre maximal de partitions qu'on avait pr\xe9vu, une technique peut \xeatre de cr\xe9er un nouveau topic avec plus de partitions, et de copier l'ensemble des messages de l'ancien topic vers le nouveau. \xc7a n\xe9cessite un peu d'effort."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"nombre de consumers"})," dans un consumer group doit \xeatre au moins aussi grand que le nombre de partitions si on veut profiter du maximum de parall\xe9lisme.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Par contre, allouer un tel nombre peut aussi mener \xe0 du g\xe2chis de ressources, vu que le broker ne fonctionne pas forc\xe9ment en flux tendu."}),"\n",(0,r.jsx)(n.li,{children:"On peut alors plut\xf4t allouer un nombre variable de consumers au groupe, bas\xe9 sur l'activit\xe9 du cluster."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Enfin on peut envisager d'avoir du ",(0,r.jsx)(n.strong,{children:"parall\xe9lisme \xe0 l'int\xe9rieur des consumers"}),", en g\xe9rant plusieurs threads, pour traiter plusieurs records en m\xeame temps."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos de la question de la ",(0,r.jsx)(n.strong,{children:"delivery des messages"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On parle ici de “delivery” au sens o\xf9 les messages sont trait\xe9s jusqu'au bout par les consumers, pas juste du fait qu'ils soient disponibles \xe0 la lecture (\xe7a, ils le restent de toute fa\xe7on pour tous les consumers d\xe8s lors que la publication a march\xe9)."}),"\n",(0,r.jsxs)(n.li,{children:["On peut avoir une delivery ",(0,r.jsx)(n.strong,{children:"at-most-once"}),", en faisant le commit d\xe8s le d\xe9but de la lecture.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est utile dans les cas o\xf9 la perte occasionnelle de donn\xe9e n'est pas grave, et ne laisse pas le syst\xe8me consommateur dans un \xe9tat inconsistant de mani\xe8re permanente."}),"\n",(0,r.jsx)(n.li,{children:"Ca peut \xeatre aussi parce que faire l'action deux fois pose probl\xe8me, alors le que le fait de la rater de temps en temps non."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut avoir une delivery ",(0,r.jsx)(n.strong,{children:"at-least-once"}),", en ne faisant le commit qu'apr\xe8s ex\xe9cution compl\xe8te de la callback du consumer.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est utile dans le cas o\xf9 la perte de donn\xe9e n'est pas acceptable, et o\xf9 on est pr\xeat \xe0 recommencer certains messages pour l'\xe9viter."}),"\n",(0,r.jsx)(n.li,{children:"Par contre on doit \xeatre pr\xeat \xe0 avoir la callback potentiellement ex\xe9cut\xe9e plusieurs fois."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Et enfin, si on veut une delivery ",(0,r.jsx)(n.strong,{children:"exactly-once"}),", on ne peut malheureusement pas compter sur le message broker \xe0 lui seul : on doit s'assurer d'avoir un flow ",(0,r.jsx)(n.strong,{children:"idempotent"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On pourrait le vouloir pour avoir \xe0 la fois la consistance parce que la perte de donn\xe9e ou le fait de ne pas faire une action n'est pas acceptable, mais en m\xeame temps o\xf9 le fait de le faire deux fois n'est pas acceptable non plus."}),"\n",(0,r.jsxs)(n.li,{children:["Pour r\xe9ussir \xe7a, on a besoin d'avoir une ",(0,r.jsx)(n.strong,{children:"idempotence de bout en bout"}),", c'est \xe0 dire que :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La callback du consumer ne doit faire que des changements idempotents. Par exemple un update en DB qui ne change pas l'\xe9tat de la DB quand il est jou\xe9 plusieurs fois."}),"\n",(0,r.jsx)(n.li,{children:"Le consumer doit v\xe9rifier si les side-effects qu'il fait ont d\xe9j\xe0 \xe9t\xe9 faits pour ne pas les refaire une 2\xe8me fois. Par exemple, Kafka offre un m\xe9canisme de transaction qui permet de ne publier qu'une fois dans un topic sortant pour un message d'un topic entrant."}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas o\xf9 on ne peut pas savoir si le side-effect a d\xe9j\xe0 \xe9t\xe9 fait ou pas, il faut que le side-effect lui-m\xeame soit rendu idempotent de bout en bout."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"7---serialization",children:"7 - Serialization"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le client Java a des serializers de base et une interface \xe0 impl\xe9menter pour cr\xe9er des serializers Kafka custom.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour l'auteur, m\xeame si cette approche est idiomatique, il vaut mieux avoir Kafka et tout ce qui y est li\xe9 isol\xe9 dans une couche de messaging pour que la logique business n'y soit pas li\xe9e et soit testable.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["L'auteur pr\xe9f\xe8re ",(0,r.jsx)(n.strong,{children:"laisser la s\xe9rialisation c\xf4t\xe9 logique business"}),", et donc conseille de ne pas utiliser les serializers custom de Kafka dans ce cas."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Et de la m\xeame mani\xe8re, les choses sp\xe9cifiques \xe0 Kafka comme le fait de mettre l'ID des customers comme cl\xe9, doivent \xeatre dans la couche de messaging pour pouvoir \xeatre mis en commun entre les use cases."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Quand on est en mode ",(0,r.jsx)(n.strong,{children:"commit manuel"}),", on peut appeler la fonction qui fait le commit de mani\xe8re asynchrone ",(0,r.jsx)(n.strong,{children:"sans l'attendre"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\xc7a aura pour effet d'avoir plus d'offsets pas encore commit\xe9s mais un throughput plus \xe9lev\xe9."}),"\n",(0,r.jsxs)(n.li,{children:["On respecte quand m\xeame le ",(0,r.jsx)(n.em,{children:"at-least-one delivery"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Dans le cas o\xf9 on utilise le m\xe9canisme de ",(0,r.jsx)(n.em,{children:"poll-process loop"})," (o\xf9 on consomme les messages par batch), le client Java va avoir deux threads : un pour aller chercher plus de records et un autre pour faire le processing des records qui sont d\xe9j\xe0 l\xe0.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il s'agit l\xe0 d'un m\xe9canisme de ",(0,r.jsx)(n.strong,{children:"pipelining"}),", o\xf9 la 1\xe8re \xe9tape va chercher de la donn\xe9e pour la mettre dans le buffer suivant jusqu'\xe0 ce que le buffer soit plein, auquel cas elle attend avant de continuer."]}),"\n",(0,r.jsxs)(n.li,{children:["L'auteur propose une version encore plus parall\xe9lis\xe9e, en ajoutant une 3\xe8me \xe9tape dans la pipeline pour s\xe9parer la d\xe9s\xe9rialisation du reste du traitement du message.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'avantage c'est que \xe7a peut augmenter le throughput, mais l'inconv\xe9nient c'est une utilisation plus intensive du CPU."}),"\n",(0,r.jsx)(n.li,{children:"Il faut cr\xe9er un thread \xe0 la main, et g\xe9rer la communication inter-thread \xe0 travers un buffer, avec tous les edge cases li\xe9s au parall\xe9lisme."}),"\n",(0,r.jsxs)(n.li,{children:["Selon l'auteur, cette technique a du sens parce que :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'utilisation de Kafka est souvent associ\xe9e \xe0 des cas d'usages qui ont besoin de performance."}),"\n",(0,r.jsx)(n.li,{children:"Elle ajoute de la complexit\xe9, mais qu'on n'a \xe0 faire qu'une fois et qu'on peut isoler dans un adapter qu'on r\xe9utilise."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"C\xf4t\xe9 publisher \xe7a aurait moins de sens vu que la s\xe9rialisation est moins co\xfbteuse que la d\xe9s\xe9rialisation."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il peut \xeatre pertinent de ",(0,r.jsx)(n.strong,{children:"filtrer des messages au niveau de la couche adapter"})," du consumer Kafka.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Par exemple, si le topic contient plus de messages que ce que le use-case qui le consomme peut ou veut d\xe9s\xe9rialiser.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\xc7a peut \xeatre parce que le producer publie les messages plusieurs fois, en indiquant la version du sch\xe9ma dans le header, et qu'on ne veut en lire qu'une version sans avoir \xe0 parser les autres."}),"\n",(0,r.jsx)(n.li,{children:"\xc7a peut aussi \xeatre un topic qui contient plusieurs types de messages, dont on ne veut traiter qu'un type."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"8---bootstrapping-and-advertised-listeners",children:"8 - Bootstrapping and Advertised Listeners"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Chaque partition a un leader broker, et ",(0,r.jsx)(n.code,{children:"n"})," follower brokers qui contiennent sa donn\xe9e (avec ",(0,r.jsx)(n.code,{children:"n + 1"})," \xe9tant le ",(0,r.jsx)(n.strong,{children:"replication factor"}),")."]}),"\n",(0,r.jsxs)(n.li,{children:["Pour pouvoir \xe9crire un record, un client publisher doit l'envoyer au broker leader de la partition qui l'int\xe9resse.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le leader transf\xe9rera aux followers, mais on ne peut pas compter sur un des followers pour transf\xe9rer d'abord au leader."}),"\n",(0,r.jsxs)(n.li,{children:["\xc7a veut donc dire que ",(0,r.jsx)(n.strong,{children:"le client devra avoir une connexion directe"})," avec quasi tous (ou m\xeame tous) les brokers, vu que tous les brokers peuvent \xeatre des leaders de partitions et qu'il risque de vouloir en lire plusieurs."]}),"\n",(0,r.jsxs)(n.li,{children:["Les brokers sont au courant de la topologie du cluster parce qu'ils ont l'info partag\xe9e via ZooKeeper.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le client peut donc ",(0,r.jsx)(n.strong,{children:"demander la liste des adresses IP des brokers \xe0 n'importe lequel d'entre eux"}),". Et donc, pour peu qu'il ait au moins une adresse de broker valide, il peut r\xe9obtenir toutes les autres."]}),"\n",(0,r.jsxs)(n.li,{children:["Le client est initialement fourni avec une ",(0,r.jsx)(n.em,{children:"bootstrap list"})," des brokers, et ensuite se d\xe9brouille pour la mettre \xe0 jour en leur demandant."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Cette technique de base de demander la liste des adresses \xe0 au moins un broker dont on a l'adresse valide n'est pas super fiable : si le client n'a plus aucune adresse valide parce qu'elles ont toutes chang\xe9, il est coinc\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ce que fait la communaut\xe9 pour r\xe9pondre \xe0 cette probl\xe9matique c'est d'utiliser des ",(0,r.jsx)(n.strong,{children:"alias DNS, pointant vers les bonnes adresses IP des brokers"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"La sp\xe9cification DNS permet m\xeame d'indiquer un seul nom qui sera associ\xe9 \xe0 une liste d'adresses IP pointant vers chacun des brokers."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il y a un probl\xe8me classique de configuration auquel beaucoup de monde se heurte, et qui emp\xeache la connexion du client aux brokers : le client demande la liste des adresses, et le broker lui r\xe9pond des adresses en ",(0,r.jsx)(n.code,{children:"localhost"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La solution est de configurer les ",(0,r.jsx)(n.strong,{children:"advertised listeners"})," dans le fichier ",(0,r.jsx)(n.code,{children:"config/server.properties"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Les propri\xe9t\xe9s sont initialement comment\xe9es dans le fichier, et donc c'est les valeurs par d\xe9faut qui s'appliquent (on peut les retrouver dans la ",(0,r.jsx)(n.a,{href:"https://kafka.apache.org/documentation/#brokerconfigs",children:"documentation de Kafka"}),")."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"advertised.listeners"})," permet d'indiquer les URI qui seront envoy\xe9es aux clients qui demandent la liste des adresses des brokers. C'est \xe7a qu'il faut configurer avec le bon hostname pour r\xe9soudre le probl\xe8me de config."]}),"\n",(0,r.jsxs)(n.li,{children:["Dans le cas o\xf9 on a des clients situ\xe9s dans des environnements r\xe9seau diff\xe9rents, on a besoin de leur advertiser des adresses diff\xe9rentes pour les m\xeames brokers.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est le cas par exemple si on a un VPC (virtual private cloud) avec le cluster Kafka et des clients, et d'autres clients situ\xe9s \xe0 l'ext\xe9rieur et ne pouvant pas acc\xe9der aux adresses IP internes au VPC."}),"\n",(0,r.jsxs)(n.li,{children:["Dans ce cas, on va pouvoir configurer plusieurs URI (ou plut\xf4t sockets) sur lesquels \xe9coute chaque broker (dans ",(0,r.jsx)(n.code,{children:"listeners"}),"), et plusieurs URI qui sont advertised (dans ",(0,r.jsx)(n.code,{children:"advertised.listeners"}),").","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il faut faire attention \xe0 indiquer des ports diff\xe9rents pour chacune des URI si on ne veut pas de probl\xe8mes."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les probl\xe9matiques de bootstrapping se posent largement dans les environnements conteneuris\xe9s. La simple utilisation de ",(0,r.jsx)(n.strong,{children:"docker-compose"})," nous am\xe8ne \xe0 avoir l'\xe9quivalent d'un VPC interne aux containers lanc\xe9s par docker-compose, et un mapping de port vers la machine h\xf4te.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Exemple de config Kafka dans un ",(0,r.jsx)(n.em,{children:"docker-compose"})," :","\n",(0,r.jsx)(n.pre,{"data-language":"yml","data-theme":"default",children:(0,r.jsxs)(n.code,{"data-language":"yml","data-theme":"default",children:[(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"kafka"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"image"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:"bitnami/kafka:2"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"ports"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    - "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:"9092:9092"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"environment"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"KAFKA_CFG_ZOOKEEPER_CONNECT"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:"zookeeper:2181"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"ALLOW_PLAINTEXT_LISTENER"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:'"yes"'})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"KAFKA_LISTENERS"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:">-"})]}),"\n",(0,r.jsx)(n.span,{className:"line",children:(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"      INTERNAL://:29092,EXTERNAL://:9092"})}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"KAFKA_ADVERTISED_LISTENERS"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:">-"})]}),"\n",(0,r.jsx)(n.span,{className:"line",children:(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"      INTERNAL://kafka:29092,EXTERNAL://localhost:9092"})}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"KAFKA_LISTENER_SECURITY_PROTOCOL_MAP"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:">-"})]}),"\n",(0,r.jsx)(n.span,{className:"line",children:(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"      INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT"})}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"KAFKA_INTER_BROKER_LISTENER_NAME"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:'"INTERNAL"'})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"depends_on"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    - "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:"zookeeper"})]})]})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On d\xe9finit ici deux protocoles propres \xe0 Kafka (et associ\xe9s au type ",(0,r.jsx)(n.code,{children:"PLAINTEXT"}),", donc non s\xe9curis\xe9s) : un qu'on appelle ",(0,r.jsx)(n.code,{children:"INTERNAL"})," pour l'URI depuis le r\xe9seau interne des containers ",(0,r.jsx)(n.em,{children:"docker-compose"}),", et un autre qu'on appelle ",(0,r.jsx)(n.code,{children:"EXTERNAL"})," pour le r\xe9seau de l'h\xf4te."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"KAFKA_LISTENERS"})," est l'\xe9quivalent de ",(0,r.jsx)(n.code,{children:"listeners"})," dans ",(0,r.jsx)(n.code,{children:"config/server.properties"}),", c'est-\xe0-dire les sockets sur lesquels le broker \xe9coute.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On choisit deux ports diff\xe9rents qui permettent de diff\xe9rencier les connexions internes et externes, et on indique qu'on \xe9coute sur toutes les interfaces possibles (en n'indiquant aucun hostname ni adresse IP)."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"KAFKA_ADVERTISED_LISTENERS"})," est l'\xe9quivalent de ",(0,r.jsx)(n.code,{children:"advertised.listeners"}),", c'est-\xe0-dire les adresses URI communiqu\xe9es aux clients pour joindre le broker.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On indique bien le hostname ",(0,r.jsx)(n.code,{children:"localhost"})," aux clients du r\xe9seau externe, et le hostname ",(0,r.jsx)(n.code,{children:"kafka"})," aux clients du r\xe9seau interne (le nom des containers sert aussi de hostname dans ",(0,r.jsx)(n.em,{children:"docker-compose"}),")."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"KAFKA_INTER_BROKER_LISTENER_NAME"})," permet d'indiquer quel protocole doit \xeatre utilis\xe9 pour la communication avec les autres brokers du cluster."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"depends_on"})," permet d'indiquer l'ordre dans lequel on start les containers dans ",(0,r.jsx)(n.em,{children:"docker-compose"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"9---broker-configuration",children:"9 - Broker Configuration"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La configuration peut se faire sur 4 entit\xe9s de Kafka : les ",(0,r.jsx)(n.strong,{children:"brokers"}),", les ",(0,r.jsx)(n.strong,{children:"topics"}),", les ",(0,r.jsx)(n.strong,{children:"clients"})," et les ",(0,r.jsx)(n.strong,{children:"users"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Il existe une ",(0,r.jsx)(n.strong,{children:"configuration statique"})," et une ",(0,r.jsx)(n.strong,{children:"configuration dynamique"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Historiquement la configuration dynamique a \xe9t\xe9 introduite pour faciliter l'administration de gros clusters, et pour ne plus avoir besoin de restart.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La communaut\xe9 a d\xe9cid\xe9 qu'enlever la configuration statique \xe9tait trop radical, donc elle a \xe9t\xe9 gard\xe9e en fallback."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La configuration statique se fait en changeant le fichier ",(0,r.jsx)(n.code,{children:"config/server.properties"})," et en red\xe9marrant le broker."]}),"\n",(0,r.jsxs)(n.li,{children:["La configuration dynamique se fait via l'admin API de Kafka, au niveau du broker ou du cluster entier.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Elle est stock\xe9e dans Zookeeper, mais ne n\xe9cessite pas la communication directe avec Zookeeper pour faire des modifications de config."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["C\xf4t\xe9 ",(0,r.jsx)(n.strong,{children:"pr\xe9c\xe9dence"}),", c'est d'abord la config dynamique par entit\xe9 qui prend le pas, puis la config dynamique au niveau du cluster, et enfin la config statique.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si rien n'est d\xe9fini, les valeurs par d\xe9faut s'appliquent."}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas de propri\xe9t\xe9s d\xe9pr\xe9ci\xe9es et remplac\xe9es par d'autres, les propri\xe9t\xe9s d\xe9pr\xe9ci\xe9es sont prises en compte si elles sont utilis\xe9es, et sinon c'est la valeur par d\xe9faut des nouvelles propri\xe9t\xe9s qui est prise en compte."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Quelques infos sur les ",(0,r.jsx)(n.strong,{children:"changements de config des brokers"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Sur la configuration ",(0,r.jsx)(n.strong,{children:"statique"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Toutes les propri\xe9t\xe9s de ",(0,r.jsx)(n.code,{children:"config/server.properties"})," sont optionnelles, sauf ",(0,r.jsx)(n.code,{children:"zookeeper.connect"})," qui contient la liste des adresses des nœuds ZooKeeper."]}),"\n",(0,r.jsxs)(n.li,{children:["Il est consid\xe9r\xe9 comme une ",(0,r.jsx)(n.strong,{children:"bonne pratique"})," de sp\xe9cifier la propri\xe9t\xe9 ",(0,r.jsx)(n.code,{children:"broker.id"})," qui repr\xe9sente l'identifiant du broker. Si on ne le fait pas, ZooKeeper assignera un ID automatiquement \xe0 chaque broker (par d\xe9faut en commen\xe7ant par ",(0,r.jsx)(n.code,{children:"1001"}),").","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour changer cette propri\xe9t\xe9, il faut :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"D'abord arr\xeater le broker."}),"\n",(0,r.jsxs)(n.li,{children:["Faire le changement dans ",(0,r.jsx)(n.code,{children:"server.properties"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Faire le changement dans le fichier ",(0,r.jsx)(n.code,{children:"meta.properties"})," (qui se trouve dans le dossier de log du broker), ou m\xeame supprimer le fichier ",(0,r.jsx)(n.code,{children:"meta.properties"})," qui sera r\xe9g\xe9n\xe9r\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le dossier de log contient des fichiers essentiels avec l'info des partitions et des records (rien \xe0 voir avec du logging, on parle des donn\xe9es de Kafka)."}),"\n",(0,r.jsxs)(n.li,{children:["Son path est configur\xe9e avec l'option ",(0,r.jsx)(n.code,{children:"log.dirs"}),", par d\xe9faut c'est ",(0,r.jsx)(n.code,{children:"/tmp/kafka-logs"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Red\xe9marrer le broker."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Sur la configuration ",(0,r.jsx)(n.strong,{children:"dynamique"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut changer la config via l'outil CLI fourni par Kafka sous forme de script bash : ",(0,r.jsx)(n.code,{children:"kafka-configs.sh"}),", ou via une librairie cliente tierce qui va se connecter \xe0 Kafka.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Par exemple pour afficher la liste des configurations dynamiques pour le broker 1001 sur un Kafka qui tourne localement :","\n",(0,r.jsx)(n.pre,{"data-language":"bash","data-theme":"default",children:(0,r.jsxs)(n.code,{"data-language":"bash","data-theme":"default",children:[(0,r.jsx)(n.span,{className:"line",children:(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"./kafka-configs.sh"})}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"--bootstrap-server"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"localhost:9092"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"--entity-type"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"brokers"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"--entity-name"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"1001"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"--describe"})]})]})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il faut faire attention avec les configurations dynamiques, on peut facilement mettre un cluster par terre si on fait une mauvaise manip.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Quand on modifie ",(0,r.jsx)(n.strong,{children:"une config pour tout le cluster"}),", c'est une bonne pratique de la modifier ",(0,r.jsx)(n.strong,{children:"d'abord pour un broker"}),", au cas o\xf9 elle aurait un impact non souhait\xe9 qui serait du coup plus limit\xe9."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos de la ",(0,r.jsx)(n.strong,{children:"configuration des topics"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ils peuvent \xeatre configur\xe9s statiquement via ",(0,r.jsx)(n.code,{children:"config/server.properties"}),", ou dynamiquement au niveau du cluster (une configuration de topic par broker n'aurait pas de sens).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut aussi modifier dynamiquement certaines propri\xe9t\xe9s par topic."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"10---client-configuration",children:"10 - Client Configuration"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["La configuration du client est beaucoup plus sensible, en partie parce qu'elle tombe ",(0,r.jsx)(n.strong,{children:"sous la responsabilit\xe9 des d\xe9veloppeurs applicatifs"}),"."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["En g\xe9n\xe9ral la configuration des brokers se fait par des personnes sp\xe9cialistes de l'infra, g\xe9rant d'autres \xe9l\xe9ments d'infrastructure, et connaissant la mani\xe8re de g\xe9rer les risques.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On voit aussi de plus un shift vers les versions de serveurs Kafka pr\xe9-configur\xe9es. \xc7a ne peut pas \xeatre le cas des clients."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"La plupart des probl\xe8mes"})," avec Kafka viennent d'une ",(0,r.jsx)(n.strong,{children:"mauvaise utilisation c\xf4t\xe9 client"}),", parce que les d\xe9veloppeurs ne le connaissent pas assez bien."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Exemple : il est notoire que Kafka offre des garanties importantes pour ce qui est de la durabilit\xe9 des records. Mais en r\xe9alit\xe9 \xe7a d\xe9pend des param\xe8tres.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il y a d\xe9j\xe0 la question du stockage, elle-m\xeame influenc\xe9e par le nombre de brokers."}),"\n",(0,r.jsxs)(n.li,{children:["Et ensuite il y a des configurations c\xf4t\xe9 client :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le replication factor et quelques autres pour ce qui est de s'assurer que la donn\xe9e reste en cas de probl\xe8me avec certaines machines."}),"\n",(0,r.jsx)(n.li,{children:"Le nombre d'acknowledgements que le broker leader de la partition doit demander avant de consid\xe9rer le record comme valid\xe9, et le fait d'attendre soi-m\xeame l'acknowledgement du leader avant de consid\xe9rer le message comme publi\xe9."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Les d\xe9veloppeurs imaginent aussi que le comportement par d\xe9faut de Kafka optimise la garantie d'ordre et de delivery des records. Mais ces valeurs sont issues de l'utilisation initiale de Linkedin qui avait surtout besoin de performance dans son cas d'usage."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"La 1\xe8re r\xe8gle de l'optimisation avec Kafka est : ne le faites pas"}),"."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La plupart du temps, les configurations qui offrent des garanties vis-\xe0-vis des records n'ont pas un si grand impact que \xe7a. On peut attendre d'en avoir vraiment besoin."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Pour ce qui est des ",(0,r.jsx)(n.strong,{children:"configurations communes"})," \xe0 tous les types de clients (producer, consumer, admin)."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"bootstrap.servers"})," permet de contacter les brokers, mais ensuite le plus important c'est que les brokers envoient les bonnes adresses (cf. le chapitre pr\xe9c\xe9dent)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"client.dns.lookup"})," donne la possibilit\xe9 d'utiliser des alias DNS li\xe9s \xe0 plusieurs adresses."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"client.id"})," permet de d\xe9finir l'identifiant du client, comme on l'a fait pour le serveur dans le chapitre d'avant. \xc7a permet la tra\xe7abilit\xe9, et la gestion de quotas."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"retries"})," indique le nombre de fois qu'on va recommencer une op\xe9ration qui se termine par une erreur transiente, c'est-\xe0-dire qui peut potentiellement ne pas se reproduire en r\xe9essayant.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"retry.backoff.ms"})," indique la dur\xe9e d'attente avant de r\xe9essayer."]}),"\n",(0,r.jsx)(n.li,{children:"Par d\xe9faut on bourrine, en recommen\xe7ant un nombre infini de fois toutes les 100 ms."}),"\n",(0,r.jsx)(n.li,{children:"L'autre possibilit\xe9 c'est en gros de limiter les retries, en ayant conscience que du coup on se retrouvera \xe0 un moment o\xf9 un autre \xe0 avoir des op\xe9rations qui sont en erreur pour des raisons temporaires. Mais on n'aura pas bloqu\xe9 pendant longtemps."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Quand on veut utiliser Kafka dans des ",(0,r.jsx)(n.strong,{children:"tests d'int\xe9gration"}),", il faut prendre en compte que le fait de le lancer dans un environnement virtualis\xe9 type Docker va ralentir consid\xe9rablement son d\xe9marrage.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le fait que Kafka \xe9coute sur le port ne suffit pas pour qu'il soit pr\xeat \xe0 accepter des requ\xeates. Il peut donc falloir attendre un certain temps au d\xe9but des tests pour qu'il d\xe9marre."}),"\n",(0,r.jsx)(n.li,{children:"Et c'est encore pire avec Docker sur MacOS."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Pour ce qui est de la ",(0,r.jsx)(n.strong,{children:"configuration du producer"}),"."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"acks"})," permet d'indiquer le nombre d'acknowledgements qu'on veut attendre de la part du broker leader avant de consid\xe9rer que le message est publi\xe9."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"0"})," indique qu'on ne veut pas attendre du tout."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"1"})," indique qu'on veut attendre que le leader lui-m\xeame ait \xe9crit le record dans son log \xe0 lui.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["C'est la valeur par d\xe9faut si ",(0,r.jsx)(n.code,{children:"enable.idempotence"})," est ",(0,r.jsx)(n.code,{children:"false"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-1"})," permet d'indiquer qu'on veut attendre que le leader mais aussi tous les followers aient \xe9crit le record dans leurs log.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["C'est la valeur par d\xe9faut si ",(0,r.jsx)(n.code,{children:"enable.idempotence"})," est ",(0,r.jsx)(n.code,{children:"true"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"max.in.flight.per.connection"})," indique le nombre de records qu'on veut pouvoir publier (par d\xe9faut 5), avant d'avoir \xe0 attendre le nombre d'acknowledgements qu'on a indiqu\xe9 dans ",(0,r.jsx)(n.code,{children:"acks"}),"."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Augmenter ce nombre permet de se pr\xe9munir contre la lenteur du r\xe9seau, vu qu'attendre la confirmation \xe0 chaque fois qu'on veut publier nous emp\xeache de publier vite."}),"\n",(0,r.jsxs)(n.li,{children:["Par contre, on risque de ne pas publier dans le bon ordre pour les records entre deux acknowledgements.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il suffit qu'un record A ait une erreur transiente qui est retent\xe9e puis r\xe9ussie, mais que le record suivant B ait r\xe9ussi imm\xe9diatement et avant le record A. Ce qui inverse l'ordre de publication de A et B."}),"\n",(0,r.jsxs)(n.li,{children:["Pour ne pas avoir le probl\xe8me il faudrait soit avoir ",(0,r.jsx)(n.code,{children:"max.in.flight.per.connection"})," \xe0 1 (attendre la confirmation \xe0 chaque publication), soit ",(0,r.jsx)(n.code,{children:"retries"})," \xe0 0 (ne jamais r\xe9essayer les erreurs transientes)."]}),"\n",(0,r.jsxs)(n.li,{children:["En r\xe9alit\xe9 il y a une 3\xe8me option qui est d'activer ",(0,r.jsx)(n.code,{children:"enable.idempotence"}),", o\xf9 Kafka va utiliser un m\xe9canisme qui remet le bon ordre pour les records qui arrivent avec le mauvais ordre."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"enable.idempotence"}),"."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Permet de garantir que :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les records soient publi\xe9s ",(0,r.jsx)(n.strong,{children:"au plus une fois"})," (donc d\xe9dupliqu\xe9s)."]}),"\n",(0,r.jsxs)(n.li,{children:["Les records sont publi\xe9s ",(0,r.jsx)(n.strong,{children:"dans l'ordre indiqu\xe9 par le client"})," producer."]}),"\n",(0,r.jsx)(n.li,{children:"Les records sont d'abord persist\xe9s sur l'ensemble des r\xe9plicas avant d'envoyer l'acknowledgement."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il n\xe9cessite que (si ces propri\xe9t\xe9s ne sont pas renseign\xe9es, elles seront mises aux bonnes valeurs par d\xe9faut, mais il ne faut juste pas de conflit) :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"max.in.flight.per.connection"})," soit ",(0,r.jsx)(n.strong,{children:"entre 0 et 5"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"retries"})," soit plus grand que 0."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"acks"})," soit \xe0 -1."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Pour ce qui est du probl\xe8me de duplication, il peut se produire dans le cas o\xf9 le producer subit un timeout alors que le message a \xe9t\xe9 pris en compte par le serveur, mais avant qu'il ne re\xe7oive l'acknowledgement. Il va donc r\xe9essayer d'envoyer le message juste apr\xe8s, ce qui fera un doublon."}),"\n",(0,r.jsxs)(n.li,{children:["Le m\xe9canisme passe par l'attribution \xe0 chaque message par le producer, d'un ID qui s'incr\xe9mente monotoniquement. Et le broker maintient le dernier ID trait\xe9 pour chaque couple [ producer ID, partition o\xf9 on publie le record ].","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si le record qui arrive est identifi\xe9 comme \xe9tant d\xe9j\xe0 arriv\xe9, il est ignor\xe9 comme duplicata."}),"\n",(0,r.jsx)(n.li,{children:"Si le record qui arrive a un ID plus grand qu'un incr\xe9ment de 1 par rapport au dernier message trait\xe9, alors le message est consid\xe9r\xe9 comme \xe9tant dans le mauvais ordre, et le broker r\xe9pond une erreur indiquant au producer qu'il faut le requeuer."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"compression.type"})," permet d'indiquer l'algo de ",(0,r.jsx)(n.strong,{children:"compression"})," qui sera utilis\xe9 par le producer (d\xe9taill\xe9 dans le chapitre 12)."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Parmi les possibilit\xe9s :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.em,{children:"none"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.em,{children:"gzip"})}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"snappy"})," (optimis\xe9 pour le throughput, au d\xe9pend de la compression)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"lz4"})," (optimis\xe9 aussi pour le throughput, surtout la d\xe9compression)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"zstd"})," (nouvel algo, qui est cens\xe9 faire un bon ratio throughput / performance)."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"key.serializer"})," et ",(0,r.jsx)(n.strong,{children:"value.serializer"})," servent \xe0 indiquer la s\xe9rialisation des cl\xe9s et valeurs des records (cf. le chapitre 7)."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"partitioner.class"})," permet d'indiquer une classe Java qui va d\xe9finir une mani\xe8re diff\xe9rente de la mani\xe8re par d\xe9faut d'associer les records et les partitions."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La mani\xe8re par d\xe9faut va, dans l'ordre :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"1 - Si la partition est indiqu\xe9e explicitement dans la publication du record, elle sera utilis\xe9e."}),"\n",(0,r.jsx)(n.li,{children:"2 - Sinon, si on a indiqu\xe9 une cl\xe9, la cl\xe9 sera hash\xe9e pour d\xe9terminer la partition."}),"\n",(0,r.jsx)(n.li,{children:"3 - Sinon, si le batch courant a une partition qui lui est assign\xe9e, on utilise cette partition."}),"\n",(0,r.jsxs)(n.li,{children:["4 - Sinon, on assigne une partition au batch et on l'utilise.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le 3 et 4 ont \xe9t\xe9 introduits dans Kafka plus r\xe9cemment, et permettent, dans le cas o\xf9 on n'a pas de pr\xe9f\xe9rence d'ordre li\xe9e \xe0 une cl\xe9, de ",(0,r.jsx)(n.strong,{children:"n'impliquer qu'un broker pour les records d'un batch."})," \xc7a ",(0,r.jsx)(n.strong,{children:"am\xe9liore les perfs par 2 ou 3"}),", tout en assurant une distribution entre brokers quand on a un grand nombre de batchs."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le client Java a aussi deux autres classes disponibles :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"RoundRobinPartitioner"})," permet d'alterner entre les brokers, sans prendre en compte la cl\xe9."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"UniformStickyPartitioner"})," permet de garder les records d'un m\xeame batch pour une m\xeame partition, sans prendre en compte la cl\xe9."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"On peut aussi donner une classe perso, mais l'auteur conseille d'envisager aussi d'encoder notre ordre custom dans une cl\xe9."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"interceptor.classes"})," permet de d\xe9finir des classes Java qui vont faire quelque chose de particulier \xe0 l'envoi et \xe0 l'acknowledgement."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\xc7a peut \xeatre utile pour le c\xf4t\xe9 “plugin” r\xe9utilisable, parce qu'on est sur de l'AOP (Aspect Oriented Programming)."}),"\n",(0,r.jsx)(n.li,{children:"On peut par exemple l'utiliser pour ajouter une couche qui fait du logging, du tracing, de l'analyse de message pour emp\xeacher la fuite de donn\xe9es etc."}),"\n",(0,r.jsx)(n.li,{children:"Attention par contre : les exceptions dans les interceptors ne sont pas propag\xe9es."}),"\n",(0,r.jsx)(n.li,{children:"Globalement si on y met quelque chose, il vaut mieux que ce soit du code simple et non bloquant."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"max.block.ms"})," permet d'indiquer un timeout au processus de publication (par d\xe9faut 60 secondes)."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"batch.size"})," permet d'attendre d'avoir une certaine taille de messages (par d\xe9faut 16 KB) avant d'envoyer un batch de publication."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"linger.ms"})," fait la m\xeame chose au niveau du temps (par d\xe9faut 0 ms) en ajoutant un temps minimal \xe0 attendre avant d'envoyer un autre batch."]}),"\n",(0,r.jsx)(n.li,{children:"L'int\xe9r\xeat est de faire moins de requ\xeates au serveur et donc d'augmenter le throughput."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"request.timeout"})," permet d'indiquer un timeout vis-\xe0-vis de la r\xe9ponse du broker pour faire l'acknowledgement (par d\xe9faut 30 secondes), avant de r\xe9essayer ou d'indiquer la publication comme \xe9chou\xe9e."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"delivery.timeout"})," permet d'indiquer un temps global pour une requ\xeate de publication, qui englobe l'envoi, les retries, et la r\xe9ponse du serveur."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Par d\xe9faut, c'est 120 secondes."}),"\n",(0,r.jsx)(n.li,{children:"Il doit \xeatre sup\xe9rieur aux autres timeouts r\xe9unis."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"transaction.id"})," et ",(0,r.jsx)(n.strong,{children:"transaction.timeout.ms"})," permettent de g\xe9rer le comportement des transactions (cf. le chapitre 18)."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Pour ce qui est de la ",(0,r.jsx)(n.strong,{children:"configuration du consumer"}),"."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"key.serializer"})," et ",(0,r.jsx)(n.strong,{children:"value.serializer"})," servent \xe0 indiquer la d\xe9s\xe9rialisation des cl\xe9s et valeurs des records (cf. le chapitre 7)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"interceptor.classes"})," permet de faire la m\xeame chose que c\xf4t\xe9 consumer, en traitant les records par batch."]}),"\n",(0,r.jsxs)(n.li,{children:["Une des choses les plus importantes \xe0 r\xe9gler, c'est ",(0,r.jsx)(n.strong,{children:"la taille de ce qu'on va aller chercher en une requ\xeate"}),". \xc7a se configure en plusieurs propri\xe9t\xe9s.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Plus on prendra de donn\xe9es, et plus le throughput sera grand, mais moins on aura un bon d\xe9lai de propagation de bout en bout d'un record."}),"\n",(0,r.jsxs)(n.li,{children:["La propri\xe9t\xe9 ",(0,r.jsx)(n.strong,{children:"timeout"})," donn\xe9e \xe0 ",(0,r.jsx)(n.code,{children:"Consumer.poll()"})," permet de limiter son temps d'ex\xe9cution."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"fetch.min.bytes"})," (par d\xe9faut 1) permet de demander au broker d'attendre d'avoir au moins un minimum de donn\xe9es \xe0 envoyer avant de r\xe9pondre.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["En r\xe9alit\xe9, le broker doit quand m\xeame envoyer une requ\xeate m\xeame s'il n'a pas assez de donn\xe9es, dans le cas o\xf9 il d\xe9passe un timeout fix\xe9 par ",(0,r.jsx)(n.strong,{children:"fetch.max.wait.ms"})," (par d\xe9faut 500 ms)."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"fetch.max.bytes"})," (par d\xe9faut 50 MB) indique au broker \xe0 partir de quelle taille il doit arr\xeater d'ajouter des donn\xe9es.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Vu qu'un record \xe0 lui seul (et donc \xe0 fortiori un batch) peut de toute fa\xe7on d\xe9passer cette taille, la limite n'est qu'indicative."}),"\n",(0,r.jsxs)(n.li,{children:["La m\xeame propri\xe9t\xe9 limite existe pour la taille des partitions : ",(0,r.jsx)(n.strong,{children:"max.partition.fetch.bytes"})," (par d\xe9faut 1 MB).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cette propri\xe9t\xe9 permet de limiter l'impact des partitions “gourmandes”, en laissant de la place aux partitions qui ont moins de donn\xe9es."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Int\xe9ressant \xe0 savoir : les brokers ne font en g\xe9n\xe9ral pas de traitement sur les batchs. ",(0,r.jsx)(n.strong,{children:"Les batchs sont envoy\xe9s par les producers, stock\xe9s tels quels, et envoy\xe9s tels quels aux consumers"}),". C'est un choix de design de Kafka pour garantir une grande performance."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"max.poll.records"})," (par d\xe9faut 500) permet de limiter le nombre de records retourn\xe9s par ",(0,r.jsx)(n.code,{children:"Consumer.poll()"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contrairement aux autres propri\xe9t\xe9s, celle-ci n'impacte pas le broker. C'est le client qui re\xe7oit le m\xeame nombre de records par batch, et il va lui-m\xeame limiter ceux qu'il rend disponible. Il bufferise les autres pour les rendre disponibles \xe0 l'appel suivant."}),"\n",(0,r.jsxs)(n.li,{children:["Elle est l\xe0 pour \xe9viter que le client n'ait \xe0 traiter trop de records, et ne puisse pas appeler \xe0 nouveau ",(0,r.jsx)(n.code,{children:"poll()"})," avant ",(0,r.jsx)(n.code,{children:"max.poll.interval.ms"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"group.id"})," permet d'indiquer le groupe d'un consumer. Si on ne le fournit pas, il deviendra sans groupe, et ne pourra pas b\xe9n\xe9ficier des m\xe9canismes de d'assignation automatique de partition, d\xe9tection des \xe9checs, ni faire de commits au serveur pour sauvegarder son offset."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"group.instance.id"})," consiste \xe0 indiquer un identifiant \xe0 un consumer, unique dans son groupe, rendant le consumer ",(0,r.jsx)(n.em,{children:"static"}),". L'effet est que si le consumer n'est plus l\xe0, sa partition n'est pas r\xe9assign\xe9e, mais reste en attente de son retour.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est pour \xe9viter les rebalancing trop fr\xe9quents dans un contextes de manque d'availability transient."}),"\n",(0,r.jsx)(n.li,{children:"Pour en savoir plus : chapitre 15."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"d\xe9tection d'\xe9checs"})," est contr\xf4l\xe9e par la combinaison de ",(0,r.jsx)(n.code,{children:"heartbeat.interval.ms"}),", ",(0,r.jsx)(n.code,{children:"session.timeout.ms"})," et ",(0,r.jsx)(n.code,{children:"max.poll.interval.ms"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ce sujet fait partie des sujets d\xe9licats, source de nombreux probl\xe8mes."}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"heartbeat.interval.ms"})," (par d\xe9faut 3 secondes) contr\xf4le la fr\xe9quence \xe0 laquelle le consumer envoie des heartbeats."]}),"\n",(0,r.jsxs)(n.li,{children:["Le broker ",(0,r.jsx)(n.em,{children:"coordinator"})," du groupe de son c\xf4t\xe9 v\xe9rifie que le consumer n'envoie pas son prochain heartbeat apr\xe8s le d\xe9lai de ",(0,r.jsx)(n.strong,{children:"session.timeout.ms"})," (par d\xe9faut 10 secondes). Sinon il l'expulse et r\xe9assigne ses partitions dans le groupe."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"max.poll.interval.ms"})," (par d\xe9faut 5 minutes) est le d\xe9lai maximal pour qu'un consumer rappelle ",(0,r.jsx)(n.code,{children:"poll()"}),". S'il ne l'a pas fait, il va lui-m\xeame arr\xeater d'envoyer des heartbeats et demander \xe0 quitter le groupe.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Si le consumer est statique, il arr\xeate les heartbeats mais ne demande pas \xe0 quitter le groupe. Il sera \xe9vinc\xe9 par le broker s'il d\xe9passe la ",(0,r.jsx)(n.code,{children:"session.timeout.interval"})," sans avoir r\xe9\xe9mis de heartbeats."]}),"\n",(0,r.jsx)(n.li,{children:"Le but de ce comportement est d'\xe9viter les situations o\xf9 plusieurs consumers traitent les m\xeames messages."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"auto.reset.offset"})," permet d'indiquer ce qui se passe quand un consumer n'a pas d'offsets pour la partition qu'il consomme.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les options sont : ",(0,r.jsx)(n.code,{children:"earliest"})," pour partir du low water mark, ",(0,r.jsx)(n.code,{children:"latest"})," pour partir du high water mark, et ",(0,r.jsx)(n.code,{children:"none"})," pour renvoyer une exception."]}),"\n",(0,r.jsxs)(n.li,{children:["Les offsets sont stock\xe9s par le ",(0,r.jsx)(n.em,{children:"group coordinator"})," dans un topic nomm\xe9 ",(0,r.jsx)(n.code,{children:"__consumer_offsets"}),". Ce topic a un temps de r\xe9tention comme n'importe quel topic (par d\xe9faut 7 jours)."]}),"\n",(0,r.jsxs)(n.li,{children:["L'offset peut ne pas exister si :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"1 - C'est le d\xe9but de la formation du groupe et que la partition n'a pas encore \xe9t\xe9 lue par lui."}),"\n",(0,r.jsxs)(n.li,{children:["2 - Quand rien n'a \xe9t\xe9 consomm\xe9 sur cette partition par le groupe (et donc aucun offset n'a \xe9t\xe9 commit\xe9 dans ",(0,r.jsx)(n.code,{children:"__consumer_offsets"}),") depuis plus longtemps que le d\xe9lai de r\xe9tention de ",(0,r.jsx)(n.code,{children:"__consumer_offsets"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"3 - Quand on a un offset qui pointe vers un record qui est dans un topic o\xf9 le d\xe9lai de r\xe9tention est plus faible, et a \xe9t\xe9 d\xe9pass\xe9. Donc l'offset pointe vers le vide."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"enable.auto.commit"})," permet d'indiquer si le commit automatique est activ\xe9 pour un consumer. Il s'agit d'envoyer un commit jusqu'au dernier record trait\xe9 par le dernier l'appel \xe0 ",(0,r.jsx)(n.code,{children:"poll()"}),", pour mettre \xe0 jour son offset.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Par d\xe9faut le client commit toutes les 5 secondes (temps r\xe9glable avec ",(0,r.jsx)(n.strong,{children:"auto.commit.interval.ms"}),")."]}),"\n",(0,r.jsxs)(n.li,{children:["Si \xe7a marchait vraiment comme \xe7a (tel que le dit la doc), le client mettrait \xe0 jour son offset au dernier record re\xe7u dans le batch envoy\xe9 par le dernier appel \xe0 ",(0,r.jsx)(n.code,{children:"poll()"}),", alors m\xeame qu'il n'a pas forc\xe9ment termin\xe9 de traiter le batch.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"En r\xe9alit\xe9, l'impl\xe9mentation r\xe8gle le probl\xe8me en envoyant le commit dans le m\xeame thread que celui qui traite les records, et seulement apr\xe8s que le batch ait \xe9t\xe9 trait\xe9."}),"\n",(0,r.jsx)(n.li,{children:"Mais ce comportement n'est pas garanti vu que la doc ne dit pas \xe7a, Kafka pourrait \xe0 tout moment mettre \xe0 jour le comportement pour faire le commit dans un autre thread toutes les 5 secondes."}),"\n",(0,r.jsxs)(n.li,{children:["Pour \xe9viter les probl\xe8mes, l'auteur conseille de ",(0,r.jsx)(n.strong,{children:"faire le commit \xe0 la main"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"isolation.level"})," permet d'indiquer le type de comportement d'une transaction vis-\xe0-vis du consumer.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La valeur ",(0,r.jsx)(n.code,{children:"read_uncommitted"})," va renvoyer tous les records sans prendre en compte les transactions."]}),"\n",(0,r.jsxs)(n.li,{children:["La valeur ",(0,r.jsx)(n.code,{children:"read_committed"})," va renvoyer les records qui ne font pas partie des transactions, et ceux qui font partie de transactions valid\xe9es, mais pas ceux qui font partie de transactions qui ne sont pas encore valid\xe9es.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour garantir l'ordre, tous les records qui doivent se trouver apr\xe8s les records qui sont dans des transactions non valid\xe9es, seront aussi bloqu\xe9s le temps de la transaction."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"11---robust-configuration",children:"11 - Robust Configuration"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Kafka fait le choix d'\xe9mettre un warning dans le cas o\xf9 on donne un mauvais nom de propri\xe9t\xe9 de configuration.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour \xe9viter les typos, on peut utiliser les constantes pour donner les valeurs."}),"\n",(0,r.jsx)(n.li,{children:"NDLR : en TypeScript les clients sont typ\xe9s."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Si la propri\xe9t\xe9 vient d'un fichier de config qui n'est pas du code, il n'y aura pas de check \xe0 la compilation.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dans ce cas, il nous faut v\xe9rifier le contenu au runtime."}),"\n",(0,r.jsxs)(n.li,{children:["L'auteur propose de faire une classe de validation, qui propose des m\xe9thodes de type fluent chaining.","\n",(0,r.jsx)(n.pre,{"data-language":"java","data-theme":"default",children:(0,r.jsxs)(n.code,{"data-language":"java","data-theme":"default",children:[(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"final"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"var"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" config "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"="}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"new"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"TypesafeProducerConfig()"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-punctuation)"},children:"."}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"withBootstrapServers"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"("}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:'"localhost:9092"'}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:")"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-punctuation)"},children:"."}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"withKeySerializerClass"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"("}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"StringSerializer"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-punctuation)"},children:"."}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"class"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:")"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-punctuation)"},children:"."}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"withValueSerializerClass"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"("}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"StringSerializer"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-punctuation)"},children:"."}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"class"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:")"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-punctuation)"},children:"."}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"withCustomEntry"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"("})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"ProducerConfig"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-punctuation)"},children:"."}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-punctuation)"},children:","}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"1"})]}),"\n",(0,r.jsx)(n.span,{className:"line",children:(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  );"})})]})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"12---batching-and-compression",children:"12 - Batching and Compression"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les batchs sont trait\xe9s par Kafka comme un ",(0,r.jsx)(n.strong,{children:"processus de bout en bout"})," : le producer envoie les records par batchs, ils sont stock\xe9s comme tels, puis envoy\xe9s au consumer sous le m\xeame format.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ca permet de recourir \xe0 la ",(0,r.jsx)(n.em,{children:"zero-copy optimization"}),", o\xf9 les donn\xe9es sont copi\xe9es depuis le r\xe9seau vers le disque, puis \xe0 nouveau vers le r\xe9seau, sans que le CPU n'ai eu \xe0 intervenir pour transformer la donn\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dans le cas o\xf9 TLS serait activ\xe9, la zero-copy optimization ne serait plus vraiment possible puisqu'il faudrait au moins d\xe9chiffrer ce qu'envoie le producer et chiffrer ensuite pour envoyer au consumer, ce qui utilise du CPU proportionnellement \xe0 la donn\xe9e."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Ce processus de cr\xe9ation de batchs arrive quand il y a beaucoup de records \xe0 traiter successivement : Kafka va batcher les records qui sont ",(0,r.jsx)(n.strong,{children:"en attente d'\xeatre envoy\xe9s"})," (en limitant la taille des batchs \xe0 ",(0,r.jsx)(n.code,{children:"batch.size"}),"). Quand le client veut publier au compte goutte, il ne fait pas de batchs.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"linger.ms"})," peut permettre d'avoir plus souvent des batchs : pendant ce temps qu'on attend, des records peuvent s'accumuler pour \xeatre batch\xe9s."]}),"\n",(0,r.jsxs)(n.li,{children:["Kafka compte beaucoup sur ",(0,r.jsx)(n.strong,{children:"du fine tuning fait par des admins"})," pour la situation pr\xe9cise dans lequel il est utilis\xe9."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le batching a encore plus d'int\xe9r\xeat quand on utilise la ",(0,r.jsx)(n.strong,{children:"compression"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il n'est pas inhabituel d'obtenir des ratios de compression entre x5 et x7 sur du JSON."}),"\n",(0,r.jsxs)(n.li,{children:["L'essentiel de la performance de compression est obtenue d\xe9j\xe0 avec de ",(0,r.jsx)(n.strong,{children:"petits batchs"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["La compression est r\xe9alis\xe9e par le producer, et la d\xe9compression dans le consumer, donc \xe7a a l'avantage de ne pas mettre de charge sur le serveur.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le serveur offre aussi la possibilit\xe9 de modifier la compression de son c\xf4t\xe9 si on le veut vraiment : avec la propri\xe9t\xe9 ",(0,r.jsx)(n.code,{children:"compression.type"})," c\xf4t\xe9 broker, qui a par d\xe9faut la valeur ",(0,r.jsx)(n.code,{children:"producer"}),", et peut prendre une valeur de type de compression (",(0,r.jsx)(n.code,{children:"gzip"}),", ",(0,r.jsx)(n.code,{children:"snappy"})," etc.)."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'auteur recommande de ",(0,r.jsx)(n.strong,{children:"toujours activer la compression pour les records textuels et binaires"})," (sauf si on sait qu'ils ont une tr\xe8s grande entropie, c'est-\xe0-dire que leur contenu est tr\xe8s variable et difficilement pr\xe9visible, donc difficilement compressible)."]}),"\n",(0,r.jsxs)(n.li,{children:["C\xf4t\xe9 algo, il conseille les heuristiques suivantes :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Si on a des clients legacy (avec une version inf\xe9rieure \xe0 2.1.0) :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"De base LZ4."}),"\n",(0,r.jsx)(n.li,{children:"Si le r\xe9seau est identifi\xe9 comme un bottleneck : Gzip."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Si on a des clients r\xe9cents :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"De base LZ4."}),"\n",(0,r.jsx)(n.li,{children:"Si le r\xe9seau est identifi\xe9 comme un bottleneck : ZStandard."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Bien s\xfbr, si on a un vrai besoin de fine tuner la performance, il faut faire des benchmarks avec chacun des algos dans notre contexte sp\xe9cifique."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"13---replication-and-acknowledgements",children:"13 - Replication and Acknowledgements"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le syst\xe8me de r\xe9plication fonctionne par ",(0,r.jsx)(n.em,{children:"sequential consistency"})," : un leader par partition envoie la donn\xe9e aux followers."]}),"\n",(0,r.jsxs)(n.li,{children:["Plus le replication factor est \xe9lev\xe9, et plus l'acknowledgement des records peut \xeatre ralenti \xe0 cause du fait qu'il faut attendre le follower le plus lent.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour r\xe9pondre \xe0 ce probl\xe8me, chaque leader maintient dans ZooKeeper une liste des ",(0,r.jsx)(n.strong,{children:"In-Sync Replicas"})," (ISR), c'est-\xe0-dire les followers qui ne d\xe9passent pas un retard temporel sp\xe9cifique vis-\xe0-vis des records du leader.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut r\xe9gler un nombre minimal de followers dans l'ISR avec ",(0,r.jsx)(n.code,{children:"min.insync.replicas"})," (par d\xe9faut 1, mais l'auteur conseille au moins 2, pour toujours avoir au moins une autre copie \xe0 jour).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"En dessous de ce nombre se trouvant dans l'ISR, le leader arr\xeate d'accepter la publication de records et attend qu'un nombre suffisant de followers redeviennent \xe9ligibles \xe0 l'ISR."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le temps maximal de lag \xe0 partir duquel un follower est exclu de l'ISR est configur\xe9 avec ",(0,r.jsx)(n.code,{children:"replica.lag.time.max.ms"})," (par d\xe9faut 10 secondes)."]}),"\n",(0,r.jsx)(n.li,{children:"C'est les followers de l'ISR dont on attendra la confirmation pour une durabilit\xe9 maximale, et non pas celle de l'ensemble des followers."}),"\n",(0,r.jsx)(n.li,{children:"Le producer ne peut que dire s'il veut attendre l'acknowledgement de tous les followers (de l'ISR), du leader seulement, ou de personne. Il ne peut pas influer sur qui se trouve ou non dans l'ISR."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Seuls les r\xe9plicas de l'ISR"})," sont \xe9ligibles pour devenir ",(0,r.jsx)(n.strong,{children:"leaders de partition"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Sauf si on a mis la propri\xe9t\xe9 ",(0,r.jsx)(n.code,{children:"unclean.leader.election"})," \xe0 ",(0,r.jsx)(n.code,{children:"true"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Quelle que soit l'approche choisie, elle aura des d\xe9savantages plus ou moins grands :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Avec un faible ",(0,r.jsx)(n.code,{children:"min.insync.replicas"})," on risque de ne plus avoir de r\xe9plicas \xe0 jour pour prendre la main au moment o\xf9 le leader est en \xe9chec."]}),"\n",(0,r.jsxs)(n.li,{children:["Avec un ",(0,r.jsx)(n.code,{children:"min.insync.replicas"})," \xe9lev\xe9 proche ou \xe9gal au replication factor, on risque d'avoir des r\xe9plicas lents qu'on est oblig\xe9s d'attendre."]}),"\n",(0,r.jsxs)(n.li,{children:["Avec un plus grand replication factor (la propri\xe9t\xe9 ",(0,r.jsx)(n.code,{children:"default.replication.factor"}),"), et potentiellement plus de brokers, on risque quand m\xeame d'\xeatre lent parce qu'on a plus de r\xe9plicas \xe0 mettre \xe0 jour."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut ",(0,r.jsx)(n.strong,{children:"augmenter le replication factor de topics existants"}),", mais \xe7a n\xe9cessite de cr\xe9er un fichier de config de r\xe9assignement sous forme JSON, avec l'ordre des r\xe9plicas qu'on pr\xe9f\xe8rerait pour chaque partition (pour le choix des nouveaux leaders d'une mani\xe8re qui les r\xe9partit entre brokers).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour nous aider avec cette config, il y a l'outil ",(0,r.jsx)(t.U,{children:"kafka-reassign-tool"})," sur GitHub."]}),"\n",(0,r.jsx)(n.li,{children:"La cr\xe9ation d'un r\xe9plica suppl\xe9mentaire demande \xe0 copier les partitions pour lesquelles on augmente le replication factor, donc \xe7a peut prendre du temps et occuper le cluster."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour ",(0,r.jsx)(n.strong,{children:"d\xe9commissionner un broker"}),", il faut d'abord le vider de son r\xf4le de leader pour toutes les partitions o\xf9 il l'est.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut pour \xe7a utiliser la m\xeame technique avec le fichier de config de r\xe9assignement, en indiquant pour toutes les partitions o\xf9 il est leader, les IDs d'autres brokers."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Concernant l'",(0,r.jsx)(n.strong,{children:"acknowledgement"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Quand un producer choisit de ne pas en recevoir (",(0,r.jsx)(n.code,{children:"acks = 0"}),"), il n'a plus de garantie de durabilit\xe9 sur ce qu'il envoie (bien que la r\xe9plication se fasse comme d'habitude c\xf4t\xe9 serveur), et il n'est plus non plus inform\xe9 de l'offset des records qu'il publie (par retour de la m\xe9thode ",(0,r.jsx)(n.code,{children:"send()"})," par exemple).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ca peut par exemple \xeatre utile dans un cas de traitement de donn\xe9es de temp\xe9rature qu'on affiche en direct : la perte de quelques donn\xe9es n'est pas tr\xe8s grave."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Quand un producer choisit d'en recevoir un quand seulement le leader a valid\xe9 le record (",(0,r.jsx)(n.code,{children:"acks = 1"}),"), en r\xe9alit\xe9 il n'y a pas beaucoup plus de garantie qu'avec ",(0,r.jsx)(n.code,{children:"acks = 0"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le leader peut \xe9chouer \xe0 effectivement \xe9crire le record (il r\xe9pond avant que l'\xe9criture soit compl\xe8te), ou il peut lui-m\xeame \xeatre en situation d'\xe9chec juste apr\xe8s l'acknowledgement, et avant d'avoir envoy\xe9 le record aux autres r\xe9plicas."}),"\n",(0,r.jsx)(n.li,{children:"En fait \xe7a revient \xe0 se demander si la machine du leader est consid\xe9r\xe9e comme plus fiable que celle du producer pour ce qui est de d\xe9cider si un record est publi\xe9 ou pas."}),"\n",(0,r.jsxs)(n.li,{children:["De mani\xe8re g\xe9n\xe9rale ce mode est surtout utile ",(0,r.jsx)(n.strong,{children:"dans les cas o\xf9 la perte de quelques donn\xe9es est tol\xe9rable"}),", mais o\xf9 le client a besoin de conna\xeetre l'offset du record qu'il vient d'\xe9crire."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Quand un producer choisit de recevoir tous les acknowledgements (",(0,r.jsx)(n.code,{children:"acks = -1"})," ou ",(0,r.jsx)(n.code,{children:"all"}),"), il a la garantie de durabilit\xe9 maximale."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'auteur conseille comme heuristique par d\xe9faut d'adopter ",(0,r.jsx)(n.code,{children:"-1"})," ou ",(0,r.jsx)(n.code,{children:"all"})," pour la valeur de ",(0,r.jsx)(n.code,{children:"acks"})," (au lieu de ",(0,r.jsx)(n.code,{children:"1"})," par d\xe9faut), et au moins ",(0,r.jsx)(n.code,{children:"2"})," ",(0,r.jsx)(n.code,{children:"pour min.insync.replicas"})," (au lieu de ",(0,r.jsx)(n.code,{children:"1"})," par d\xe9faut) avec un replication factor d'au moins ",(0,r.jsx)(n.code,{children:"3"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si on est dans des cas o\xf9 la perte de donn\xe9es est tol\xe9rable, alors on pourra diminuer ces contraintes."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"14---data-retention",children:"14 - Data Retention"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les donn\xe9es de chaque partition sont par d\xe9faut dans des dossiers de la forme ",(0,r.jsx)(n.code,{children:"/tmp/kafka-logs/getting-started-0/"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le dossier contient un fichier nomm\xe9 ",(0,r.jsx)(n.code,{children:"leader-epoch-checkpoint"}),", qui contient toutes les r\xe9assignation de leader pour la partition. De cette mani\xe8re, chaque r\xe9plica peut ignorer les messages d'un coll\xe8gue broker qui se prendrait pour le leader de la partition sans l'\xeatre."]}),"\n",(0,r.jsxs)(n.li,{children:["Le contenu des records se trouve dans fichiers nomm\xe9s selon le 1er offset du record qu'ils ont, avec l'extension ",(0,r.jsx)(n.code,{children:".log"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Chaque fichier de log a un index nomm\xe9 de la m\xeame mani\xe8re mais avec une extension ",(0,r.jsx)(n.code,{children:".index"}),". Il contient un map entre les offsets des records (ou des batchs) du fichier de log, et l'offset physique dans le fichier de log pour aller les lire."]}),"\n",(0,r.jsxs)(n.li,{children:["On a enfin un autre fichier nomm\xe9 pareil mais avec l'extension ",(0,r.jsx)(n.code,{children:".timeindex"}),", et qui contient un map entre des timestamps des records et l'offset physique dans le fichier de log."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Kafka a des propri\xe9t\xe9s configurables, li\xe9es \xe0 la taille des fichiers de log et \xe0 leur anciennet\xe9, pour contr\xf4ler le moment o\xf9 on ",(0,r.jsx)(n.strong,{children:"switch au fichier suivant"})," pour \xe9crire.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Par exemple ",(0,r.jsx)(n.code,{children:"log.segment.bytes"})," (par d\xe9faut 1 GB), ",(0,r.jsx)(n.code,{children:"log.roll.hours"})," (par d\xe9faut 1 semaine)."]}),"\n",(0,r.jsx)(n.li,{children:"On peut aussi configurer un temps al\xe9atoire de d\xe9calage du switch, pour que l'ensemble des partitions ne changent pas de fichier de log en m\xeame temps."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les fichiers d'index ont une place pr\xe9-allou\xe9e, dont la taille est contr\xf4lable par une propri\xe9t\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut de la m\xeame mani\xe8re activer la pr\xe9-allocation des fichiers de log, pour gagner en performance sur certains filesystems."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le script ",(0,r.jsx)(n.code,{children:"kafka-dump-log.sh"})," dans les outils d'admin de Kafka permet de lire le contenu des fichiers qui composent les logs."]}),"\n",(0,r.jsxs)(n.li,{children:["Il existe des ",(0,r.jsx)(n.strong,{children:"cleanup policies"})," qui sont de deux types : supprimer les anciens records, ou faire de la compaction pour gagner en place.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"log.cleanup.policy"})," permet de contr\xf4ler le type de policy, cross-topic ou pour un topic sp\xe9cifique.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Par d\xe9faut la valeur est ",(0,r.jsx)(n.code,{children:"delete"}),", l'autre valeur \xe9tant ",(0,r.jsx)(n.code,{children:"compact"}),". On peut sp\xe9cifier les deux en m\xeame temps, en les s\xe9parant par une virgule."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le cleanup ne s'applique qu'aux fichiers de log ",(0,r.jsx)(n.strong,{children:"inactifs"}),", c'est-\xe0-dire les fichiers de log dont on a d\xe9j\xe0 switch\xe9 vers un autre fichier."]}),"\n",(0,r.jsxs)(n.li,{children:["Quand la policy est ",(0,r.jsx)(n.strong,{children:"delete"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Un background process va r\xe9guli\xe8rement (toutes les ",(0,r.jsx)(n.code,{children:"log.retention.check.interval.ms"}),", par d\xe9faut 5 minutes) v\xe9rifier pour chaque fichier de log inactif s'il est sujet \xe0 \xeatre supprim\xe9 ou non, en fonction des r\xe8gles de r\xe9tention configur\xe9es (par exemple ",(0,r.jsx)(n.code,{children:"log.retention.bytes"})," (non configur\xe9 par d\xe9faut), ",(0,r.jsx)(n.code,{children:"log.retention.hours"})," (par d\xe9faut 1 semaine))."]}),"\n",(0,r.jsxs)(n.li,{children:["Avec les valeurs par d\xe9faut, un fichier de log sera supprim\xe9 au bout d'1 semaine. Par contre, il sera supprim\xe9 d'un coup. Donc si on n'avait qu'un seul fichier qui n'avait pas atteint la taille d'1 GB pour switch de fichier avant les 1 semaine, on va perdre tous les records d'un coup, et \xe9crire les nouveaux dans un nouveau fichier.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Si on veut une plus grande granularit\xe9, on peut configurer de plus petites valeurs pour pour le switch de fichier de log actif (",(0,r.jsx)(n.code,{children:"log.segment.bytes"})," ou ",(0,r.jsx)(n.code,{children:"log.roll.hours"}),")."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Quand la policy est ",(0,r.jsx)(n.strong,{children:"compact"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La compaction est utile par exemple dans le cas o\xf9 on a des ",(0,r.jsx)(n.strong,{children:"events de type ECST"})," (l'auteur ne mentionne pas le terme).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Normalement il faut une logique en deux temps : hydrater notre app downstream avec les donn\xe9es de l'app upstream, puis laisser l'app upstream publier ses changements sur Kafka."}),"\n",(0,r.jsxs)(n.li,{children:["Pour \xe9viter d'avoir ce fonctionnement en deux temps, la compaction permet de publier d\xe8s le d\xe9but les ECST dans Kafka, et de ne pas avoir besoin de l'autre mode puisque ",(0,r.jsx)(n.strong,{children:"Kafka gardera toujours au moins le record le plus r\xe9cent pour chaque entit\xe9"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Par contre \xe7a ne marche qu'avec les events qui ont la totalit\xe9 de la donn\xe9e de l'entit\xe9 et qui donc “d\xe9pr\xe9cient” les events pr\xe9c\xe9dents pour cette entit\xe9. \xc7a ne marche pas avec les events qui indiquent seulement les champs qui ont chang\xe9 dans l'entit\xe9."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La compaction consiste \xe0 transformer Kafka en snapshot, o\xf9 on ne garde que les donn\xe9es les plus r\xe9centes pour chaque entit\xe9, qu'on ",(0,r.jsx)(n.strong,{children:"diff\xe9rencie par la key"})," associ\xe9e au record.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La lecture de l'ensemble du topic prendra donc un temps proportionnel au nombre de keys diff\xe9rents dont il existe des records."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["D'un point de vue technique, la compaction est faite par des threads en arri\xe8re plan.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["C\xf4t\xe9 config :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Leur nombre est contr\xf4l\xe9 par ",(0,r.jsx)(n.code,{children:"log.cleaner.threads"}),", par d\xe9faut ",(0,r.jsx)(n.code,{children:"1"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"log.cleaner.min.cleanable.ratio"})," (par d\xe9faut ",(0,r.jsx)(n.code,{children:"0.5"}),") indique le ratio de log “sale“ \xe0 partir duquel il sera \xe9ligible \xe0 \xeatre compact\xe9."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"log.cleaner.min.compaction.lag.ms"})," (par d\xe9faut ",(0,r.jsx)(n.code,{children:"0"}),") permet d'indiquer un temps minimal avant qu'un record ne puisse faire l'objet de compaction. Sachant que \xe7a ne peut pas concerner le fichier de log ",(0,r.jsx)(n.em,{children:"actif"}),", mais seulement ceux o\xf9 il y a d\xe9j\xe0 eu un switch de fichier."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"log.cleaner.min.compaction.lag.ms"})," (par d\xe9faut infini) permet d'indiquer un temps maximal \xe0 partir duquel le log sera quand m\xeame compact\xe9, m\xeame s'il ne satisfaisait pas le ratio de “salet\xe9”."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"log.cleaner.delete.retention.ms"})," (par d\xe9faut 24 heures) indique la dur\xe9e de vie des ",(0,r.jsx)(n.em,{children:"tombstones"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"On peut aussi d\xe9finir ces configs par topic (sauf pour le nombre de threads de compaction)."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour calculer le ",(0,r.jsx)(n.strong,{children:"ratio de “salet\xe9”"}),", Kafka maintient un ",(0,r.jsx)(n.em,{children:"cleaner point"})," correspondant au point jusqu'o\xf9 la compaction a d\xe9j\xe0 \xe9t\xe9 faite, pour chaque fichier de log.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le ratio consiste \xe0 diviser le nombre de records pas encore trait\xe9s par le nombre de records existants dans la partie d\xe9j\xe0 trait\xe9e."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La compaction laisse les records ",(0,r.jsx)(n.strong,{children:"dans le m\xeame ordre"}),", et ",(0,r.jsx)(n.strong,{children:"ne change pas leur offset"}),". Elle va juste \xe9liminer des records."]}),"\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"tombstones"})," sont cr\xe9\xe9s par les producers pour indiquer \xe0 Kafka que les entit\xe9s d'une key particuli\xe8re ne sont plus utiles.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ce sont simplement des records, avec une valeur nulle, et la key pour laquelle on veut faire la suppression."}),"\n",(0,r.jsx)(n.li,{children:"La raison pour laquelle ils restent un temps minimal (par d\xe9faut 24h) est de s'assurer que les consumers ont eu le temps d'avoir l'info de suppression du record, pour \xe9viter qu'ils gardent l'entit\xe9 en base alors qu'elle n'est plus cens\xe9e exister."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut aussi ",(0,r.jsx)(n.strong,{children:"combiner compaction et deletion"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Cette possibilit\xe9 est utile dans des cas particuliers o\xf9 les events perdent rapidement leur int\xe9r\xeat.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut alors potentiellement avoir une compaction plus agressive vu qu'on limite la taille des records en supprimant les plus anciens."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Un exemple peut \xeatre le topic ",(0,r.jsx)(n.code,{children:"__consumer_offsets"})," qui compacte pour que le group coordinator puisse rapidement reconstruire l'\xe9tat des consumers, et supprime les anciens offsets pour les groupes qui n'ont pas \xe9t\xe9 actifs depuis longtemps pour \xe9viter de trop grossir."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"15---group-membership-and-partition-assignment",children:"15 - Group Membership and Partition Assignment"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"consumer groups"})," permettent de faire du load balancing au niveau de la consommation.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Kafka garantit qu'il y aura ",(0,r.jsx)(n.strong,{children:"au plus un consumer d'un m\xeame groupe par partition"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"“au plus” pour prendre en compte le cas o\xf9 aucun consumer ne serait disponible dans le groupe."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'assignation des consumers se passe en deux temps :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"1 - La phase group membership"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il s'agit d'identifier les consumers d'un groupe, et d'\xe9lire un ",(0,r.jsx)(n.strong,{children:"group leader"})," parmi eux, pour que celui-ci d\xe9cide des assignations partition / consumer.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["1 - Les consumers envoient un message au ",(0,r.jsx)(n.strong,{children:"broker qui est coordinator"})," pour ce group, pour s'identifier comme membres de ce groupe.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ils savent qui est leur coordinator parce que son id leur est renvoy\xe9 par un des brokers, qui lui m\xeame peut le savoir par un m\xe9canisme d\xe9terministe de hachage entre le group id et une des partitions : le broker leader de cette partition devient le coordinator du group."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["2 - Le coordinator attend un certain temps avant de r\xe9pondre, pour que tous les consumers aient pu s'identifier comme membres du groupe, et pour \xe9viter les nombreux rebalancings au d\xe9but.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le d\xe9lai est appliqu\xe9 quand le groupe est vide."}),"\n",(0,r.jsxs)(n.li,{children:["Le d\xe9lai est contr\xf4lable avec ",(0,r.jsx)(n.code,{children:"group.initial.rebalance.delay.ms"})," (par d\xe9faut 3 secondes)."]}),"\n",(0,r.jsx)(n.li,{children:"C'est typiquement inutile dans les sc\xe9narios o\xf9 il n'y a qu'un consumer, comme dans des tests d'int\xe9gration par exemple o\xf9 on peut le mettre \xe0 0."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"3 - Il renvoie une r\xe9ponse \xe0 chacun, contenant les IDs des consumers du groupe et l'ID du consumer leader."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"2 - La phase state synchronisation"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"1 - Le group leader va faire l'assignation des partitions aux consumers dont il a re\xe7u la liste, et envoyer \xe7a au coordinator."}),"\n",(0,r.jsx)(n.li,{children:"2 - Le coordinator \xe0 son tour renvoie les assignations \xe0 chaque consumer."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A chaque fois qu'un consumer rejoint un groupe existant, le coordinator oblige les autres consumers \xe0 se r\xe9identifier, et se voir potentiellement r\xe9assigner des partitions (on appelle \xe7a le ",(0,r.jsx)(n.strong,{children:"rebalancing"}),").","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pendant le rebalancing, les consumers se verront refuser toutes leurs op\xe9rations (y compris heartbeats) par une r\xe9ponse ",(0,r.jsx)(n.code,{children:"REBALANCE_IN_PROGRESS"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"A chaque rebalancing, le coordinator va assigner \xe0 chaque consumer un id qui est incr\xe9ment\xe9 monotoniquement. Donc un consumer zombie qui aurait oubli\xe9 de se r\xe9identifier serait rejet\xe9 la prochaine fois qu'il voudrait consommer."}),"\n",(0,r.jsxs)(n.li,{children:["Le client met \xe0 disposition la possibilit\xe9 d'enregistrer des callbacks sur les events d'un rebalancing :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"onPartitionsRevoked()"})," est appel\xe9 d\xe8s que la consommation doit s'arr\xeater pour que le rebalancing puisse avoir lieu."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"onPartitionsAssigned()"})," indique au client les \xe9ventuelles nouvelles partitions qui lui ont \xe9t\xe9 assign\xe9es."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"onPartitionLost()"})," indique d'\xe9ventuelles partitions perdues par le consumer.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\xc7a peut se produire si le consumer n'avait pas \xe9mis de heartbeats et \xe9tait consid\xe9r\xe9 en \xe9chec."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le rebalancing par d\xe9faut (",(0,r.jsx)(n.em,{children:"eager rebalancing"}),") se fait en une \xe9tape.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il implique donc que les consumers doivent \xe0 chaque fois partir du principe que l'ensemble des assignations de partition sont potentiellement r\xe9voqu\xe9es et cleaner les messages en cours de traitement."}),"\n",(0,r.jsxs)(n.li,{children:["L'",(0,r.jsx)(n.strong,{children:"incremental cooperative rebalancing"})," permet d'\xe9viter \xe7a en pla\xe7ant les assignations \xe0 la fin, en utilisant \xe9ventuellement plusieurs \xe9tapes :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Une seule \xe9tape s'il n'y a que de nouvelles assignations de partitions."}),"\n",(0,r.jsx)(n.li,{children:"S'il y a aussi des r\xe9vocations : une premi\xe8re \xe9tape de r\xe9vocations, et une deuxi\xe8me \xe9tape d'assignations."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour que l'incremental cooperative rebalancing soit plus efficace, et contrebalance le fait qu'il n\xe9cessite plus d'appels r\xe9seau, il faut que la strat\xe9gie d'assignation de partition soit ",(0,r.jsx)(n.strong,{children:"sticky"})," (c'est-\xe0-dire qu'on essaye au maximum de garder les assignations qui existent pendant le rebalancing)."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Dans les syst\xe8mes distribu\xe9s, il y a deux propri\xe9t\xe9s importantes : la ",(0,r.jsx)(n.strong,{children:"liveness"})," qui est le fait qu'un syst\xe8me continue d'op\xe9rer et de progresser dans ses t\xe2ches, et la ",(0,r.jsx)(n.strong,{children:"safety"})," qui est le fait que les invariants du syst\xe8me soient pr\xe9serv\xe9s.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Kafka satisfait la liveness par :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les checks r\xe9guliers d'availability des consumers par le syst\xe8me de heartbeats \xe0 envoyer avant un timeout."}),"\n",(0,r.jsxs)(n.li,{children:["La v\xe9rification que les consumers progressent, en s'assurant qu'ils appellent r\xe9guli\xe8rement ",(0,r.jsx)(n.code,{children:"poll()"})," avant de d\xe9passer un timeout."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Plus les valeurs des deux timeouts sont petites et plus le client d\xe9tectera vite les \xe9checs, mais au prix de plus de consommation de ressources et de plus de faux positifs.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Globalement l'",(0,r.jsx)(n.strong,{children:"auteur trouve ces valeurs par d\xe9faut raisonnables"})," dans la plupart des cas."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Dans le cas o\xf9 on doit retenter une requ\xeate vers un composant externe (DB, broker etc) qui \xe9choue plusieurs fois, on risque d'\xe9chouer nous-m\xeames \xe0 respecter le timeout prouvant qu'on progresse (",(0,r.jsx)(n.code,{children:"max.poll.interval.ms"}),"), on alors 5 possibilit\xe9s :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["1 - Mettre une tr\xe8s grande valeur \xe0 ",(0,r.jsx)(n.code,{children:"max.poll.interval.ms"}),", pour “d\xe9sactiver” le timeout.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il s'agit d'un cas o\xf9 on veut que l'ordre soit absolument respect\xe9, et que les actions pour chaque record soient absolument r\xe9alis\xe9es, au prix d'une potentielle attente jusqu'\xe0 ce que la ressource externe r\xe9ponde correctement."}),"\n",(0,r.jsx)(n.li,{children:"Le probl\xe8me c'est qu'on ne prend pas en compte qu'on pourrait avoir un probl\xe8me en interne, notamment des bugs dans le consumer lui-m\xeame, et que notre timeout nous prot\xe9geait aussi de \xe7a."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["2 - Mettre une valeur raisonnable pour le timeout. Dans ce cas, tant que le service externe est down, le consumer va recommencer jusqu'au timeout, et \xeatre rebalanc\xe9 (exclu puis r\xe9int\xe9gr\xe9).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est le m\xeame comportement que le 1- o\xf9 on veut faire les records dans l'ordre co\xfbte que co\xfbte, mais l\xe0 on r\xe8gle les \xe9ventuels probl\xe8mes de consumer bloqu\xe9."}),"\n",(0,r.jsx)(n.li,{children:"Il y a par contre un risque de perdre en performance \xe0 force d'encha\xeener les rebalancings."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["3 - D\xe9tecter nous m\xeames dans le consumer le fait qu'on va bient\xf4t d\xe9passer le timeout, et se d\xe9connecter apr\xe8s avoir nettoy\xe9 ses t\xe2ches en cours, pour se reconnecter tout de suite apr\xe8s.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"En fait, vu qu'on se d\xe9connecte/reconnecte, on va entra\xeener un rebalancing de fait."}),"\n",(0,r.jsx)(n.li,{children:"Le petit avantage par rapport \xe0 la 2- c'est qu'on va pouvoir faire des checks suppl\xe9mentaires localement sur le fait de ne processer le record qu'une fois."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["4 - Mettre en place une deadline par record, et si la deadline est d\xe9pass\xe9e, consid\xe9rer qu'il a \xe9t\xe9 trait\xe9 en passant au suivant, mais le republier dans le topic pour qu'il soit retrait\xe9 plus tard.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cette solution implique que l'ordre de traitement des records n'est pas essentiel."}),"\n",(0,r.jsx)(n.li,{children:"On pourrait aussi avoir un temps maximal ou un nombre de retries maximal dans le record, indiquant combien de temps ou de fois il faut continuer \xe0 essayer de le republier avant que \xe7a ne serve plus \xe0 rien, dans le cas o\xf9 il devient obsol\xe8te avec le temps."}),"\n",(0,r.jsxs)(n.li,{children:["Les consumer groups \xe9tant ind\xe9pendants et pouvant lire dans un m\xeame topic, requeuer un message derri\xe8re le topic juste parce qu'un consumer group n'a pas pu le traiter \xe0 temps n'est pas vraiment ce qu'on veut.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Au lieu de \xe7a, on peut avoir une topologie de type ",(0,r.jsx)(n.em,{children:"fanout"}),", c'est-\xe0-dire un topic qui publie dans un fanout group, qui lui-m\xeame publie dans un topic par consumer group. Et dans ce deuxi\xe8me niveau on pourra requeuer un message non g\xe9r\xe9 par un consumer groupe sp\xe9cifique."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["5 - Mettre en place une deadline comme dans le 4-, mais sans requeuer le record du tout.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il peut \xeatre int\xe9ressant, tout comme pour le 4-, de penser \xe0 mettre les records non trait\xe9s dans une ",(0,r.jsx)(n.em,{children:"dead letter queue"})," pour pouvoir investiguer la lenteur plus tard."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Malgr\xe9 les garanties apport\xe9es par Kafka, il est possible que ",(0,r.jsx)(n.strong,{children:"deux consumers traitent le m\xeame record"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\xc7a arrive dans le cas suivant :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["1 - Un consumer met beaucoup de temps \xe0 traiter un record, et d\xe9passe le timeout pour appeler ",(0,r.jsx)(n.code,{children:"poll()"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"2 - Il se fait exclure parce que son thread responsable des heartbeats n'en \xe9met plus et demande m\xeame explicitement \xe0 \xeatre r\xe9voqu\xe9."}),"\n",(0,r.jsx)(n.li,{children:"3 - Le coordinator r\xe9voque le consumer et fait un rebalancing pour assigner sa partition \xe0 un autre consumer."}),"\n",(0,r.jsx)(n.li,{children:"4 - Le nouveau consumer commence \xe0 traiter les records non commit\xe9s."}),"\n",(0,r.jsx)(n.li,{children:"5 - pendant ce temps, le consumer r\xe9voqu\xe9 continue de traiter son record en cours, sans savoir qu'il a \xe9t\xe9 arr\xeat\xe9."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour \xe9viter \xe7a, Kafka ne propose pas grand chose. L'auteur propose 3 approches \xe0 faire soi-m\xeame :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["1 - Se d\xe9brouiller pour que le consumer ",(0,r.jsx)(n.strong,{children:"ne d\xe9passe jamais le timeout"}),", et que sinon on g\xe8re les cons\xe9quences \xe0 la main pour ne pas avoir de rebalancing."]}),"\n",(0,r.jsxs)(n.li,{children:["2 - Utiliser un ",(0,r.jsx)(n.strong,{children:"distributed lock manager"})," (DLM) pour prot\xe9ger les sections critiques d'\xeatre trait\xe9es en m\xeame temps par deux consumers.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La protection agit sur le fait de traiter ",(0,r.jsx)(n.em,{children:"en m\xeame temps"}),", pas le fait de traiter plusieurs fois en g\xe9n\xe9ral.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ceci dit, on peut du coup v\xe9rifier qu'on n'a pas d\xe9j\xe0 trait\xe9 la section critique du record avant de la traiter \xe0 nouveau."}),"\n",(0,r.jsx)(n.li,{children:"Attention \xe0 ne pas \xeatre tent\xe9 de faire l'optimisation de faire d\xe9connecter/reconnecter le consumer dans le cas o\xf9 on remarque que le record a d\xe9j\xe0 \xe9t\xe9 trait\xe9 : le consumer qui l'a trait\xe9 n'a peut-\xeatre pas encore commit\xe9, et donc on risquerait de le retraiter \xe0 nouveau."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"L'impact du DLM sur le throughput et la latence peuvent \xeatre minimis\xe9s en regroupant les records du buffer, par exemple par partition, et en faisant le lock avant et apr\xe8s le traitement de chacun de ces lots."}),"\n",(0,r.jsx)(n.li,{children:"A la place du DLM on pourrait aussi avoir n'importe quel store persistant, comme Redis ou une DB."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["3 - Utiliser un ",(0,r.jsx)(n.strong,{children:"process qui v\xe9rifie r\xe9guli\xe8rement"})," le process qui tourne pour consommer les records, pour s'assurer qu'il consomme bien r\xe9guli\xe8rement.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"S'il est bloqu\xe9 depuis un certain temps, le process v\xe9rificateur le restart avant que le timeout c\xf4t\xe9 Kafka soit d\xe9clench\xe9."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'id\xe9e des ",(0,r.jsx)(n.strong,{children:"static members"})," va tr\xe8s bien avec le fait d'avoir un syst\xe8me de health check externe \xe0 Kafka : par exemple Kubernetes qui s'assurerait de d\xe9tecter les consumers en \xe9chec, et de les arr\xeater puis restarter.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C\xf4t\xe9 liveness, \xe7a peut permettre d'\xe9viter des rebalancings de la part de Kafka, et donc d'avoir un throughput plus important, au prix de certaines partitions sp\xe9cifiques qui n'avancent plus pendant un temps plus long qu'en mode non static."}),"\n",(0,r.jsx)(n.li,{children:"C\xf4t\xe9 safety, Kubernetes peut jouer le r\xf4le d'orchestrateur pour s'assurer que les partitions ne sont pas trait\xe9es par plusieurs consumers en m\xeame temps."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La raison pour laquelle l'assignation des partitions se passe dans un consumer leader, c'est de permettre le ",(0,r.jsx)(n.strong,{children:"changement de strat\xe9gie d'assignation"})," pour chaque consumer, plut\xf4t que quelque chose de commun en tant que config Kafka.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il existe 4 assignors disponibles pour choisir ces strat\xe9gies :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"range assignor"})," est l'assignor par d\xe9faut, il consiste \xe0 classer les partitions pour un m\xeame topic et les consumers dans l'ordre du plus petit au plus grand, et ensuite d'attribuer des groupes de partitions de part \xe9gales aux consumers successifs.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Et on recommence la m\xeame chose pour chaque topic."}),"\n",(0,r.jsx)(n.li,{children:"Si le nombre de partitions n'est pas divisible par le nombre de consumers, les premiers consumers se verront attribuer une partition de plus."}),"\n",(0,r.jsxs)(n.li,{children:["Son d\xe9savantage c'est qu'il assigne les partitions \xe9quitablement par topic, mais si on prend en compte l'ensemble des partitions existantes dont les consumers doivent s'occuper, on peut tomber sur une r\xe9partition assez in\xe9gale.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\xc7a se produit en particulier quand le nombre de partition par topic est plus petit que le nombre de consumers : les premiers consumers re\xe7oivent une partition de chaque topic, alors que les derniers n'en re\xe7oivent pas."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"round robin assignor"})," consiste \xe0 rassembler les partitions de tous les topics, puis de les attribuer un par un, dans l'ordre, aux consumers, en rebouclant sur la liste de consumers s'il y a plus de partitions que de consumers.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La r\xe9partition est bien meilleure que pour le range assignor, puisqu'elle est cross-topic."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"sticky assignor"})," consiste \xe0 assigner de mani\xe8re \xe0 peu pr\xe8s \xe9quilibr\xe9e, mais surtout s'\xe9vertue \xe0 pr\xe9server le plus possible les assignations d\xe9j\xe0 faites, quand il faut faire une r\xe9assignation.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La r\xe9partition est de la m\xeame qualit\xe9 que pour le round robin assignor, mais celui-ci minimise le nombre de partitions chang\xe9es de main pendant un rebalancing."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"cooperative sticky assignor"})," consiste \xe0 faire la m\xeame chose que le sticky assignor, mais en utilisant le ",(0,r.jsx)(n.em,{children:"cooperative rebalancing protocol"})," qui permet de r\xe9duire les pauses de rebalancing.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les consumers ne sont plus oblig\xe9s de se pr\xe9parer \xe0 la r\xe9vocation de toutes leurs partitions \xe0 chaque rebalancing. Ils savent lesquelles seront r\xe9voqu\xe9es, et ensuite lesquelles leur seront assign\xe9es."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour ",(0,r.jsx)(n.strong,{children:"changer la strat\xe9gie d'assignation"}),", on ne peut pas simplement mettre \xe0 jour la propri\xe9t\xe9 de config qui le fait (",(0,r.jsx)(n.code,{children:"partition.assignment.strategy"}),").","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le premier consumer qui sortirait du groupe pour y revenir avec la nouvelle strat\xe9gie provoquerait un probl\xe8me d'inconsistance de strat\xe9gie au niveau de ce groupe."}),"\n",(0,r.jsx)(n.li,{children:"On assigne d'abord l'ancienne strat\xe9gie et la nouvelle, puis on supprime l'ancienne. Au final on aura eu 2 bounces."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"16---security",children:"16 - Security"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Kafka n'est pas configur\xe9 par d\xe9faut pour fonctionner de mani\xe8re s\xe9curis\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Par d\xe9faut, n'importe quel client peut se connecter, y compris \xe0 ZooKeeper."}),"\n",(0,r.jsx)(n.li,{children:"Les connexions ne sont pas chiffr\xe9es."}),"\n",(0,r.jsx)(n.li,{children:"M\xeame une fois l'authentification mise en place, les autorisations sont maximales."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La premi\xe8re s\xe9curit\xe9 est le ",(0,r.jsx)(n.strong,{children:"blocage au niveau r\xe9seau"})," avec un firewall.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["L'auteur propose une topologie r\xe9seau en 4 blocs s\xe9par\xe9s par des firewalls :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le bloc ZooKeeper, acc\xe9d\xe9 uniquement par les brokers."}),"\n",(0,r.jsx)(n.li,{children:"Le bloc Kafka brokers, acc\xe9d\xe9 par les clients."}),"\n",(0,r.jsx)(n.li,{children:"Le bloc clients : consumers, publishers, admin clients."}),"\n",(0,r.jsx)(n.li,{children:"Le bloc externe qui passe par internet, et peut contenir un site distant, ou encore des t\xe9l\xe9travailleurs acc\xe9dant via VPN."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Ensuite il faut activer le ",(0,r.jsx)(n.strong,{children:"chiffrement TLS"})," support\xe9 par Kafka.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Chaque broker a besoin d'une cl\xe9 RSA et d'un certificat CA, correspondant \xe0 son hostname."}),"\n",(0,r.jsxs)(n.li,{children:["La configuration SSL/TLS peut se faire dans ",(0,r.jsx)(n.code,{children:"server.properties"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il faut notamment utiliser le protocole existant ",(0,r.jsx)(n.code,{children:"SSL"})," sur un port diff\xe9rent de ",(0,r.jsx)(n.code,{children:"PLAINTEXT"}),", \xe0 la fois pour ",(0,r.jsx)(n.code,{children:"listeners"})," et ",(0,r.jsx)(n.code,{children:"advertised.listeners"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Pour activer le chiffrement pour les communications inter-broker, on peut ajouter ",(0,r.jsx)(n.code,{children:"inter.broker.listener.name=SSL"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Il suffit ensuite de connecter le client sur le bon port de Kafka, en indiquant les bonnes creds et le protocole utilis\xe9."}),"\n",(0,r.jsxs)(n.li,{children:["Une fois qu'on s'est assur\xe9 que la connexion chiffr\xe9e fonctionne, l'auteur recommande de d\xe9sactiver le socket non chiffr\xe9 dans le serveur, en enlevant la version qui utilise ",(0,r.jsx)(n.code,{children:"PLAINTEXT"})," dans ",(0,r.jsx)(n.code,{children:"listeners"})," et ",(0,r.jsx)(n.code,{children:"advertised.listeners"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut m\xeame configurer le firewall pour interdire les connexions sur le port 9092."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Kafka n'a pas de ",(0,r.jsx)(n.strong,{children:"m\xe9canisme de chiffrement de la donn\xe9e elle-m\xeame"}),", par d\xe9faut elle sera stock\xe9e en clair sur le filesystem des brokers.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Une des possibilit\xe9s peut \xeatre d'utiliser un chiffrement au niveau du filesystem ou du disque dur entier des machines des brokers."}),"\n",(0,r.jsxs)(n.li,{children:["La m\xe9thode la plus s\xfbre est de recourir \xe0 du ",(0,r.jsx)(n.strong,{children:"chiffrement de bout en bout"})," de la donn\xe9e, en chiffrant dans le publisher, et d\xe9chiffrant dans le consumer.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il existe plusieurs projets open source qui permettent de le faire. Par exemple, le projet ",(0,r.jsx)(t.U,{children:"Kafka Encryption"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Si on publie des messages d\xe9j\xe0 chiffr\xe9s, il devient inutile d'activer la compression dans Kafka, puisque l'entropie des messages sera alors maximale."}),"\n",(0,r.jsxs)(n.li,{children:["Le chiffrement de bout en bout ne rend pas l'utilisation de TLS inutile.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"TLS prot\xe8ge l'ensemble du record, y compris les headers par exemple."}),"\n",(0,r.jsx)(n.li,{children:"Il prot\xe8ge contre les attaques man in the middle, en assurant l'identit\xe9 de l'\xe9metteur."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Kafka supporte plusieurs types d'",(0,r.jsx)(n.strong,{children:"authentification"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"mutual TLS"})," permet d'utiliser le m\xe9canisme TLS habituellement utilis\xe9 pour que le client fasse confiance au serveur aussi dans l'autre sens : le client lui aussi envoie un certificat sign\xe9 par un CA auquel le serveur fait confiance.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["C\xf4t\xe9 serveur, on peut activer la fonctionnalit\xe9 avec la propri\xe9t\xe9 ",(0,r.jsx)(n.code,{children:"ssl.client.auth"})," :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Elle vaut ",(0,r.jsx)(n.code,{children:"none"})," par d\xe9faut."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"required"})," permet de forcer les clients \xe0 fournir un certificat valide s'ils veulent se connecter."]}),"\n",(0,r.jsxs)(n.li,{children:["Il y a une 3\xe8me option utile pour faire une migration progressive : ",(0,r.jsx)(n.code,{children:"requested"})," permet d'accepter l'authentification par ce moyen, mais sans le rendre obligatoire le temps que tous les clients aient \xe9t\xe9 migr\xe9s."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"C\xf4t\xe9 client, il faut obtenir un certificat certifi\xe9 par un CA valide du point de vue du serveur, et se connecter avec les propri\xe9t\xe9s de config qui sont le miroir de celles qu'utilise le serveur pour lui-m\xeame configurer TLS."}),"\n",(0,r.jsxs)(n.li,{children:["Pour obtenir l'information sur l'",(0,r.jsx)(n.strong,{children:"identit\xe9 du client"})," qui se connecte, c'est par d\xe9faut le champ CN du certificat qui sera utilis\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La propri\xe9t\xe9 ",(0,r.jsx)(n.code,{children:"ssl.principal.mapping.rules"})," permet de personnaliser le champ \xe0 prendre par des r\xe8gles de type regex."]}),"\n",(0,r.jsxs)(n.li,{children:["Par contre, la fiabilit\xe9 de la m\xe9thode pour d\xe9terminer l'identit\xe9 d\xe9pend de la rigueur avec laquelle les certificats sont \xe9tablis :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si un des clients peut mettre l'identit\xe9 d'un autre client dans le champ CN d'un certificat qu'il fait g\xe9n\xe9rer par l'autorit\xe9 de confiance, alors il pourra se faire passer pour l'autre client."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Un autre probl\xe8me aussi c'est que Kafka ne permet pas de r\xe9voquer un certificat pour un client particulier.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le mieux qu'on puisse faire c'est de d\xe9ployer un nouveau CA, et de faire signer tous les certificats des clients par ce CA."}),"\n",(0,r.jsx)(n.li,{children:"Il faut aussi penser \xe0 utiliser des CA diff\xe9rents si on a plusieurs clusters Kafka."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"L'authentification mutual TLS ne peut pas \xeatre utilis\xe9e en m\xeame temps que d'autres types d'authentification au niveau applicatif, m\xeame si la mutual TLS se trouve dans une couche r\xe9seau diff\xe9rente."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"SASL"})," (Simple Authentication and Security Layer) consiste \xe0 ajouter une m\xe9thode d'authentification \xe0 un protocole utilisateur.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il est en g\xe9n\xe9ral utilis\xe9 avec du TLS."}),"\n",(0,r.jsxs)(n.li,{children:["L'une des variantes support\xe9es est ",(0,r.jsx)(n.strong,{children:"GSSAPI"})," (Generic Security Service API), aussi connu sous le nom de son impl\xe9mentation principale qui est Kerberos.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cet outil va avec l'usage de r\xe9pertoires centralis\xe9s type Active Directory."}),"\n",(0,r.jsxs)(n.li,{children:["Il est surtout adapt\xe9 aux utilisateurs individuels, mais Kafka a besoin d'avoir une authentification plut\xf4t orient\xe9e autour de ",(0,r.jsx)(n.em,{children:"service accounts"}),", parce qu'on ne peut pas d\xe9marrer et arr\xeater un client \xe0 chaque interaction utilisateur.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le probl\xe8me avec l'approche ",(0,r.jsx)(n.em,{children:"service accounts"})," c'est que Kerberos n'\xe9tant pas forc\xe9ment compatible avec toutes les ressources (par exemple Redis), on va pouvoir d\xe9sactiver un account mais sans \xeatre s\xfbr que l'ensemble des ressources le sont pour cet account."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"L'auteur trouve que Kerberos est un syst\xe8me complexe pour ce qu'il apporte, et conseille plut\xf4t les autres m\xe9thodes SASL."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les autres variantes SASL support\xe9es par Kafka sont ",(0,r.jsx)(n.strong,{children:"PLAIN"})," et ",(0,r.jsx)(n.strong,{children:"SCRAM"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"PLAIN est le diminutif de plaintext, pour dire que le user et mot de passe sont transmis en clair."}),"\n",(0,r.jsxs)(n.li,{children:["SCRAM est l'acronyme de ",(0,r.jsx)(n.em,{children:"Salted Challenge Response Authentication Mechanism"}),", et il a la particularit\xe9 de ",(0,r.jsx)(n.strong,{children:"ne pas impliquer d'envoyer les credentials directement au serveur"}),". Il apporte donc une meilleure s\xe9curit\xe9."]}),"\n",(0,r.jsxs)(n.li,{children:["Comme dit plus haut, l'authentification SASL n'est pas compatible avec l'authentification SSL c\xf4t\xe9 client (avec le client qui fournit un certificat sign\xe9 par un CA de confiance) : Kafka ne saurait pas quoi prendre comme identifiant entre le username dans SASL et le champ CN du certificat.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si on fournit les deux, la configuration pour l'authentification SSL c\xf4t\xe9 client ne sera pas prise en compte."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Avec SCRAM, les versions hash\xe9es des credentials valides sont stock\xe9es dans ZooKeeper, par exemple avec le script ",(0,r.jsx)(n.code,{children:"kafka-config.sh"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["PLAIN quant \xe0 lui les stocke en clair dans ",(0,r.jsx)(n.code,{children:"server.properties"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut aussi utiliser SASL pour la communication inter-broker au lieu de juste SSL.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Attention \xe0 bien prot\xe9ger le fichier ",(0,r.jsx)(n.code,{children:"server.properties"})," qui va du coup contenir le username et password en clair, par exemple avec un petit ",(0,r.jsx)(n.code,{children:"chmod 600"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Une autre solution peut \xeatre de cr\xe9er un fichier dans ",(0,r.jsx)(n.code,{children:"config/"})," qu'on prot\xe8ge, et d'y mettre la config jaas. Il faudra alors passer ce fichier dans l'option CLI ",(0,r.jsx)(n.code,{children:"java.security.auth.login.config"})," au moment de d\xe9marrer le broker."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut \xe0 chaque fois utiliser ",(0,r.jsx)(n.code,{children:'netstat -an | egrep "9092|9093|9094"'})," pour v\xe9rifier sur quels ports il y a Kafka en \xe9coute et sur quels ports il y a une connexion \xe9tablie."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La version de SASL avec ",(0,r.jsx)(n.strong,{children:"OAuth bearer"})," est l\xe0 seulement dans un objectif de ",(0,r.jsx)(n.strong,{children:"testing"}),". Elle n'est pas s\xe9curis\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'application peut sp\xe9cifier un user arbitraire dans un token JWT."}),"\n",(0,r.jsxs)(n.li,{children:["On peut utiliser une impl\xe9mentation open source comme ",(0,r.jsx)(n.em,{children:"Kafka OAuth"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"delegation tokens"})," sont un m\xe9canisme compl\xe9mentaire \xe0 SASL, permettant de faciliter la gestion des credentials sur un grand nombre de brokers.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour Kerberos il va s'agir de remplacer le d\xe9ploiement des TGT ou keytab, et pour PLAIN et SCRAM \xe7a va \xeatre les user / password."}),"\n",(0,r.jsx)(n.li,{children:"Les delegation tokens sont limit\xe9s dans le temps et donc permettent de ne pas compromettre les vrais credentials."}),"\n",(0,r.jsx)(n.li,{children:"C'est particuli\xe8rement pratique dans le cas o\xf9 les brokers sont cr\xe9\xe9s de mani\xe8re \xe9ph\xe9m\xe8re dans des workers."}),"\n",(0,r.jsxs)(n.li,{children:["Il faut faire la configuration c\xf4t\xe9 broker en mettant en place ",(0,r.jsx)(n.code,{children:"delegation.token.master.key"})," \xe0 la m\xeame valeur pour tous les brokers du cluster.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On cr\xe9e ensuite les tokens avec une commande CLI ",(0,r.jsx)(n.code,{children:"kafka-delegation-tokens.sh"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Le token doit \xeatre renouvel\xe9 avant la p\xe9riode d'expiration (par d\xe9faut 1 jour) avec le m\xeame fichier de commande CLI."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["C\xf4t\xe9 client, il faut indiquer qu'on utilise l'authentification avec delegation token, et indiquer les valeurs de ",(0,r.jsx)(n.code,{children:"TOKENID"})," et ",(0,r.jsx)(n.code,{children:"HMAC"})," qu'on a pu r\xe9cup\xe9rer au moment de cr\xe9er le token sur le broker."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut configurer une ",(0,r.jsx)(n.strong,{children:"authentification sur ZooKeeper"}),", en utilisant SASL.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\xc7a concerne du coup les brokers et les clients admin."}),"\n",(0,r.jsx)(n.li,{children:"ZooKeeper a en plus un m\xe9canisme d'autorisation \xe0 base d'ACL, permettant d'attribuer 5 types de droits aux utilisateurs anonymes et utilisateurs authentifi\xe9s par SASL."}),"\n",(0,r.jsx)(n.li,{children:"De l'aveu de l'auteur, ajouter une authentification \xe0 un ZooKeeper qu'on a d\xe9j\xe0 isol\xe9 dans un r\xe9seau \xe0 part peut \xeatre excessif. Le niveau de s\xe9curit\xe9 dont on a besoin d\xe9pendra du contexte."}),"\n",(0,r.jsxs)(n.li,{children:["Pour activer l'authentification, il faut modifier ",(0,r.jsx)(n.code,{children:"zookeeper.properties"})," et y ajouter la config pour activer SASL.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il ne faut pas oublier de changer les autorisations qui existent pour les utilisateurs anonymes avec la commande CLI ",(0,r.jsx)(n.code,{children:"zookeeper-security-migration.sh"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il faut ensuite activer l'authentification s\xe9curis\xe9e \xe0 ZooKeeper depuis le broker, en ajoutant la propri\xe9t\xe9 ",(0,r.jsx)(n.code,{children:"zookeeper.set.acl=true"}),", et en red\xe9marrant le broker avec l'option ",(0,r.jsx)(n.code,{children:"java.security.auth.login.config"})," pointant vers le fichier de config contenant les identifiants SASL."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"clients admin"}),", que ce soit en script CLI ou de type Kafdrop, doivent aussi \xeatre configur\xe9s pour se connecter aux brokers qui ont une authentification activ\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour les scripts CLI, on peut changer le fichier ",(0,r.jsx)(n.code,{children:"client.properties"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Pour Kafdrop, il faut modifier le fichier ",(0,r.jsx)(n.code,{children:"kafka.properties"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Concernant l'",(0,r.jsx)(n.strong,{children:"autorisation"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Kafka a un syst\xe8me d'autorisations sous forme d'ACL centr\xe9es sur les ressources.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il s'agit d'un syst\xe8me distinct de celui de ZooKeeper."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On a la possibilit\xe9 d'autoriser des droits :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Par utilisateur."}),"\n",(0,r.jsx)(n.li,{children:"Par host."}),"\n",(0,r.jsx)(n.li,{children:"Pour un type de ressource particulier (par exemple Topic ou Group)."}),"\n",(0,r.jsxs)(n.li,{children:["Pour un pattern sp\xe9cifique \xe0 appliquer aux ressources (par exemple toutes les ressources commen\xe7ant par un pr\xe9fix, ou avec des ",(0,r.jsx)(n.code,{children:"*"})," pour dire qu'on peut avoir n'importe quoi dans une partie du nom)."]}),"\n",(0,r.jsxs)(n.li,{children:["Pour une op\xe9ration particuli\xe8re (par exemple ",(0,r.jsx)(n.code,{children:"Read"}),", ",(0,r.jsx)(n.code,{children:"Write"}),", ",(0,r.jsx)(n.code,{children:"Describe"})," etc.)."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour commencer, il faut activer l'autorisation dans le serveur en ajoutant la classe d'autorisation et la liste des super users dans ",(0,r.jsx)(n.code,{children:"server.properties"})," :","\n",(0,r.jsx)(n.pre,{"data-language":"text","data-theme":"default",children:(0,r.jsxs)(n.code,{"data-language":"text","data-theme":"default",children:[(0,r.jsx)(n.span,{className:"line",children:(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer"})}),"\n",(0,r.jsx)(n.span,{className:"line",children:(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"super.users=User:admin"})})]})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les super users sont s\xe9par\xe9s par des point-virgules."}),"\n",(0,r.jsx)(n.li,{children:"A partir de l\xe0, seuls les super users auront la possibilit\xe9 de faire des choses. Tous les autres seront bloqu\xe9s."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Parmi les scripts CLI, ",(0,r.jsx)(n.code,{children:"kafka-acls.sh"})," permet de visualiser et configurer les ACLs."]}),"\n",(0,r.jsxs)(n.li,{children:["La bonne pratique c'est d'",(0,r.jsx)(n.strong,{children:"assigner des utilisateurs distincts"})," \xe0 chaque application (publisher, consumer etc.).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La m\xeame chose vaut pour le user utilis\xe9 pour l'inter-broker communication : il vaut mieux lui donner les bons droits plut\xf4t que le mettre en super admin."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Kafka donne la possibilit\xe9 d'",(0,r.jsx)(n.strong,{children:"autoriser ou interdire"})," pour une r\xe8gle d'autorisation donn\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les r\xe8gles d'interdiction prennent toujours le pas sur les r\xe8gles d'autorisation, quelles que soient les granularit\xe9s."}),"\n",(0,r.jsxs)(n.li,{children:["On peut gr\xe2ce \xe0 \xe7a, par exemple :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Partir du fait que le d\xe9faut dans Kafka c'est que tout est interdit pour tout le monde."}),"\n",(0,r.jsxs)(n.li,{children:["Puis mettre une r\xe8gle qui autorise un droit de lecture sur un topic pour tous les utilisateurs (en utilisant le wildcard “",(0,r.jsx)(n.code,{children:"*"}),"”)."]}),"\n",(0,r.jsxs)(n.li,{children:["Et enfin mettre des r\xe8gles interdisant ce droit d'\xe9criture pour certains utilisateurs particuliers (par exemple un utilisateur ",(0,r.jsx)(n.em,{children:"guest"})," dont on donne les identifiants \xe0 ceux qui veulent essayer)."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il y a des moyens de filtrer plus ou moins de choses quand on liste des droits avec le script CLI ",(0,r.jsx)(n.code,{children:"kafka-acls.sh"})," :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On a la possibilit\xe9 de lister tous les droits qui pourraient s'appliquer au nom qu'on indique (parce qu'ils comportent des r\xe8gles de wildcard ou de pr\xe9fix etc.), gr\xe2ce \xe0 l'option ",(0,r.jsx)(n.code,{children:"--resource-pattern-type=any"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Ou alors lister seulement les droits qui portent sur le nom exact qu'on indique, gr\xe2ce \xe0 l'option ",(0,r.jsx)(n.code,{children:"--resource-pattern-type=match"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Kafka permet de cr\xe9er des r\xe8gles d'autorisation ou d'interdiction pour les clients bas\xe9 sur leurs adresses IP.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'auteur d\xe9conseille cette fonctionnalit\xe9, \xe9tant donn\xe9 la nature mouvante des topologies de client dans le cloud."}),"\n",(0,r.jsx)(n.li,{children:"Il conseille \xe0 la limite d'utiliser le firewall pour faire ce genre de restrictions."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Voil\xe0 quelques ",(0,r.jsx)(n.strong,{children:"sc\xe9narios d'autorisation habituels"})," qu'on met en place :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Cr\xe9er des topics"})," : l'op\xe9ration ",(0,r.jsx)(n.code,{children:"Create"})," qu'on attribue pour les topics commen\xe7ant par un pr\xe9fixe."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Supprimer des topics"})," : l'op\xe9ration ",(0,r.jsx)(n.code,{children:"Delete"})," sur les topics avec le m\xeame pr\xe9fixe."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Publier dans un topic"})," : l'op\xe9ration ",(0,r.jsx)(n.code,{children:"Write"})," ou ",(0,r.jsx)(n.code,{children:"IdempotentWrite"})," (pour que \xe7a marche avec la publication en mode idempotent), qu'on attribue pour les topics commen\xe7ant par un pr\xe9fixe."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Consommer depuis un topic"})," :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour un consumer sans groupe, il faut l'op\xe9ration ",(0,r.jsx)(n.code,{children:"Read"})," sur le topic. En g\xe9n\xe9ral on met le topic exact pour \xe9viter d'augmenter l'exposition des donn\xe9es."]}),"\n",(0,r.jsxs)(n.li,{children:["Si le consumer fait partie d'un groupe, alors il faudra aussi l'op\xe9ration ",(0,r.jsx)(n.code,{children:"Read"})," sur le groupe."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"17---quotas",children:"17 - Quotas"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les quotas servent \xe0 :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Emp\xeacher les ",(0,r.jsx)(n.strong,{children:"attaques DOS"})," en faisant du throttling."]}),"\n",(0,r.jsxs)(n.li,{children:["Aider \xe0 ",(0,r.jsx)(n.strong,{children:"planifier la capacit\xe9"})," de la machine pour assurer une bonne qualit\xe9 de service.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"En particulier quand on commence \xe0 avoir suffisamment de clients Kafka pour que les quelques brokers initialement n\xe9cessaires commencent \xe0 manquer de ressources."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les quotas s'appliquent aux ",(0,r.jsx)(n.strong,{children:"utilisateurs"})," au niveau de ",(0,r.jsx)(n.strong,{children:"chaque broker"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ca veut dire qu'il faut prendre en compte le nombre de brokers, et potentiellement revoir les quotas quand on ajoute des brokers."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il existe deux types de quotas :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"1 - Network bandwidth quotas"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["V\xe9rifie que les producers et consumers ne d\xe9passent pas une certaine quantit\xe9 de donn\xe9es transf\xe9r\xe9es (en bytes / seconde).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ca permet d'englober de nombreux aspects : bande passante r\xe9seau, ressources I/O, ressources m\xe9moire \xe0 cause du buffering, ressources CPU dans le cas du chiffrement TLS."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le broker calcule l'utilisation de la bande passante de chaque client par fen\xeatre glissante.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Quand il y a un d\xe9passement, le broker va ",(0,r.jsx)(n.strong,{children:"introduire artificiellement un d\xe9lai"})," avant de r\xe9pondre. Le client ne saura donc pas s'il a subi une restriction ou si c'est juste des lenteurs r\xe9seau."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"2 - Request rate quotas"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["V\xe9rifie que les producers et consumers n'utilisent pas plus d'un certain pourcentage de CPU d'un thread I/O.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"50% correspond \xe0 la moiti\xe9 de l'utilisation du thread I/O, 200% correspond \xe0 l'utilisation pleine de 2 threads."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.em,{children:"network bandwidth quota"})," couvre d\xe9j\xe0 une grande partie des cas. ",(0,r.jsx)(n.em,{children:"Request rate quotas"})," vient le compl\xe9ter dans les cas o\xf9 ",(0,r.jsx)(n.strong,{children:"un client a fait un mauvais r\xe9glage"})," qui l'am\xe8ne \xe0 faire un tr\xe8s grand nombre de requ\xeates vers le serveur, sans qu'il n'y ait forc\xe9ment beaucoup de donn\xe9es dans ces requ\xeates.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ca peut \xeatre par exemple si un consumer a configur\xe9 une valeur de ",(0,r.jsx)(n.code,{children:"fetch.max.wait.ms"})," tr\xe8s basse, le poussant \xe0 faire des requ\xeates tr\xe8s r\xe9guli\xe8res pour demander plus de records."]}),"\n",(0,r.jsx)(n.li,{children:"Comme autre cas de mauvaise configuration, \xe7a peut aussi \xeatre de nombreuses requ\xeates qui aboutissent \xe0 “unauthorized”, ou encore une configuration diff\xe9rente de la compression entre client et serveur, aboutissant \xe0 une sur-utilisation du CPU inutile."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Ce mode de quota fonctionne aussi par fen\xeatre glissante, et ajoute aussi des p\xe9nalit\xe9s d'attente silencieuses en cas de d\xe9passement."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les quotas sont ",(0,r.jsx)(n.strong,{children:"attribu\xe9s aux usernames et aux client IDs"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.em,{children:"usernames"})," sont ceux qui sont utilis\xe9s et v\xe9rifi\xe9s par Kafka par les m\xe9canismes d'authentification (champ CN du certificat en cas d'authentification par mutual TLS, et champ username en cas d'authentification SASL) et d'autorisation."]}),"\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.em,{children:"client IDs"})," sont les identifiants qu'un client ",(0,r.jsx)(n.strong,{children:"d\xe9clare librement"})," au moment de se connecter au serveur, avec le champ ",(0,r.jsx)(n.code,{children:"client.id"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"On utilise souvent une combinaison des deux : le username pour l'authentification, et le client ID pour distinguer plusieurs machines appartenant \xe0 la m\xeame personne ou au m\xeame groupe de personnes."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'attribution se fait via ",(0,r.jsx)(n.strong,{children:"configuration dynamique"}),", via le script CLI ",(0,r.jsx)(n.code,{children:"kafka-configs.sh"})," ou un autre client admin.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il est possible de sp\xe9cifier des quotas pour un couple username / client ID, sachant que chaque membre du couple de valeurs peut avoir soit une valeur, soit la valeur ",(0,r.jsx)(n.code,{children:"&lt;default>"}),", soit ne pas avoir de valeur.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le fait de savoir quelle r\xe8gle de quota va s'appliquer se fait par matching parmi les r\xe8gles existantes, avec une ",(0,r.jsx)(n.strong,{children:"priorit\xe9 aux r\xe8gles les plus pr\xe9cises"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["En fonction de la r\xe8gle de quota qui est retenue pour chaque consumer, ",(0,r.jsx)(n.strong,{children:"si deux consumers partagent la m\xeame r\xe8gle, ils partageront aussi la valeur du quota"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["D'un point de vue s\xe9curit\xe9, l'auteur conseille de sp\xe9cifier d'abord des valeurs par d\xe9faut qui sont tr\xe8s basses (en commen\xe7ant par le couple username / client ID : ",(0,r.jsx)(n.code,{children:"&lt;default>"})," / ",(0,r.jsx)(n.code,{children:"&lt;default>"}),"), et ensuite de les \xe9craser par des r\xe8gles plus sp\xe9cifiques ayant des quotas plus larges."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La propri\xe9t\xe9 ",(0,r.jsx)(n.strong,{children:"buffer.memory"})," (par d\xe9faut 32 Mo) c\xf4t\xe9 client permet de le bloquer quand le buffer d\xe9passe cette taille, ce qui peut permettre d'\xe9viter le throttling c\xf4t\xe9 serveur."]}),"\n",(0,r.jsxs)(n.li,{children:["Le fait que ",(0,r.jsx)(n.strong,{children:"le client ne sache pas s'il fait l'objet de p\xe9nalit\xe9s d'attente"})," ou s'il y a simplement de la congestion sur le r\xe9seau, peut poser probl\xe8me dans certains cas.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il peut bombarder de requ\xeates et finir par subir une attente si longue qu'elle d\xe9passerait le delivery timeout. Il pourrait alors avoir tendance \xe0 r\xe9essayer plusieurs fois, menant \xe0 une forme de ",(0,r.jsx)(n.em,{children:"congestive collapse"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["En g\xe9n\xe9ral on peut r\xe9soudre ce probl\xe8me en diminuant la propri\xe9t\xe9 ",(0,r.jsx)(n.strong,{children:"buffer.memory"})," (par d\xe9faut 32 Mo) c\xf4t\xe9 client pour obliger le client \xe0 attendre avant de publier plus que ce qu'il a en buffer."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Parfois on se trouve dans un cas o\xf9 le client veut publier beaucoup de messages, et parmi eux la plupart des messages sans urgence particuli\xe8re, et certains messages urgents dont il ne veut pas qu'ils fassent l'objet de ralentissement.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Dans ce cas, il est oblig\xe9 d'essayer de deviner (par des moyens probabilistes) s'il fait l'objet de p\xe9nalit\xe9s li\xe9es au quotas ou pas, pour \xe9viter d'envoyer les autres messages le temps d'envoyer les messages urgents.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"1 - Il peut noter le nombre records envoy\xe9s mais pas encore acknowledg\xe9s par le broker : normalement ce chiffre devrait augmenter en cas de throttling, et diminuer pour atteindre presque 0 dans le cas contraire."}),"\n",(0,r.jsx)(n.li,{children:"2 - Il peut noter le timestamp du dernier record, et le comparer au temps actuel : s'il y a une diff\xe9rence importante, il est possible qu'il y ait eu du throttling."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La m\xe9thode de ",(0,r.jsx)(n.strong,{children:"fen\xeatres glissantes"})," qui calcule s'il faut appliquer des p\xe9nalit\xe9s d'attente est configurable.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le calcul se fait sur N samples d'une dur\xe9e de S secondes, qui se renouvellent sample par sample.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["N est configurable par ",(0,r.jsx)(n.code,{children:"quota.window.num"})," (par d\xe9faut ",(0,r.jsx)(n.code,{children:"11"})," samples)."]}),"\n",(0,r.jsxs)(n.li,{children:["S est configurable par ",(0,r.jsx)(n.code,{children:"quota.window.size.seconds"})," (par d\xe9faut ",(0,r.jsx)(n.code,{children:"1"})," seconde)."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Une fois qu'un client a d\xe9pass\xe9 le quota dans la fen\xeatre de samples, il pourra \xe0 chaque sample de temps publier une quantit\xe9 minimale, jusqu'\xe0 ce que sa consommation totale sur la fen\xeatre redescende en dessous de sa limite de quota.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\xc7a implique qu'un client qui publie \xe0 fond produise des pics tous les N samples, suivis de tr\xe8s faibles quantit\xe9s publi\xe9es."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos de la strat\xe9gie de tuning de ces r\xe8gles :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Plus on va ",(0,r.jsxs)(n.strong,{children:["augmenter ",(0,r.jsx)(n.em,{children:"quota.window.num"})]}),", et plus ",(0,r.jsx)(n.strong,{children:"le pic ponctuel pourra \xeatre \xe9lev\xe9"})," avant de subir une p\xe9nalit\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'auteur conseille d'\xe9ventuellement modifier ce param\xe8tre en cons\xe9quence."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Plus on va ",(0,r.jsxs)(n.strong,{children:["augmenter ",(0,r.jsx)(n.em,{children:"quota.window.size.seconds"})]}),", et plus ",(0,r.jsx)(n.strong,{children:"le temps d'attente de p\xe9nalit\xe9 sera long"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'auteur conseille de ne pas y toucher et de le laisser au minimum, c'est \xe0 dire 1 seconde."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Attention cependant, ce comportement non uniforme qui provoque des pics n'est pas document\xe9, et pourrait \xeatre modifi\xe9 sans avoir besoin d'un process long."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"18---transactions",children:"18 - Transactions"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les transactions permettent de r\xe9aliser des ",(0,r.jsx)(n.strong,{children:"exactly-once deliveries \xe0 travers une pipeline de plusieurs jobs"})," (qu'on appelle ",(0,r.jsx)(n.em,{children:"stages"}),") cha\xeen\xe9s via des topics Kafka successifs.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ils y arrivent parce qu'ils permettent de ",(0,r.jsx)(n.strong,{children:"r\xe9aliser l'idempotence \xe0 travers plusieurs stages"}),", et qu'en combinant \xe7a avec l'",(0,r.jsx)(n.em,{children:"at-least-one delivery"}),", on obtient l'",(0,r.jsx)(n.em,{children:"exactly-one delivery"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"probl\xe9matique"})," est la suivante :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On part d'un cas o\xf9 on a un ",(0,r.jsx)(n.em,{children:"stage"})," qui a besoin de consommer un topic Kafka, et pour chaque record consomm\xe9, publier un record dans un autre topic Kafka.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On ne s'int\xe9resse pas ici \xe0 d'autres side-effects comme l'\xe9criture en DB pour laquelle les transactions Kafka ne peuvent rien, mais bien seulement aux messages Kafka publi\xe9s et consomm\xe9s."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les probl\xe8mes suivants peuvent se produire :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Des ",(0,r.jsx)(n.strong,{children:"erreurs r\xe9seau et des crashs du serveur"}),", pour lesquelles on n'a pas besoin des transactions.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le consumer peut les g\xe9rer gr\xe2ce au m\xe9canisme de retries tant qu'il n'a pas fait le commit d'offset."}),"\n",(0,r.jsx)(n.li,{children:"Le producer peut les g\xe9rer gr\xe2ce au m\xe9canisme de retries tant qu'il n'a pas re\xe7u d'acknowledgement, et au m\xe9canisme d'idempotence qui garantit l'ordre et la d\xe9duplication."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour les ",(0,r.jsx)(n.strong,{children:"crashs du process client"})," on a un point faible : le cas o\xf9 le client a d\xe9j\xe0 commenc\xe9 \xe0 ex\xe9cuter la callback du record, et est arriv\xe9 jusqu'\xe0 publier le record sortant, mais ",(0,r.jsx)(n.strong,{children:"n'a pas encore fait le commit de son offset"})," en tant que consumer.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"S'il crash \xe0 ce moment-l\xe0, la prochaine fois qu'il se r\xe9veille il va traiter le m\xeame record entrant, et va publier encore le record qu'il avait d\xe9j\xe0 publi\xe9."}),"\n",(0,r.jsx)(n.li,{children:"On a donc un risque de publier le message sortant plusieurs fois, sans que la publication avec l'option d'idempotence ne puisse rien y faire, puisqu'il ne s'agit pas de retries d'un m\xeame message."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Le m\xeame probl\xe8me peut se g\xe9n\xe9raliser avec la publication de plusieurs messages qui doivent tous n'\xeatre publi\xe9s qu'une fois par le stage."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Alors que Kafka permet de base une bonne ",(0,r.jsx)(n.em,{children:"durability"})," (notamment gr\xe2ce \xe0 la r\xe9plication des donn\xe9es dans chaque broker), avec le m\xe9canisme de transactions il se voit dot\xe9 d'autres caract\xe9ristiques d'",(0,r.jsx)(n.strong,{children:"ACID"})," :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Atomicity : l'ensemble des messages publi\xe9s dans une m\xeame transaction sont soit tous valid\xe9s, soit tous non valid\xe9s, y compris dans des topics et partitions diff\xe9rents."}),"\n",(0,r.jsx)(n.li,{children:"Consistency : on ne se retrouve pas dans un demi-\xe9tat, soit tous les records sont valid\xe9s, soit aucun."}),"\n",(0,r.jsx)(n.li,{children:"Isolation : les transactions faites en parall\xe8le ont le m\xeame r\xe9sultat que si elles \xe9taient faites les unes apr\xe8s les autres."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"D'un point de vue performance, on n'a que 3 \xe0 5% de diminution du throughput quand on utilise les transactions."}),"\n",(0,r.jsxs)(n.li,{children:["Pour ce qui est du ",(0,r.jsx)(n.strong,{children:"fonctionnement d\xe9taill\xe9"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"transaction coordinators"})," tournent sur les brokers.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ils ont pour r\xf4le :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"1 - d'assigner un ID \xe0 chaque producer (Producer ID, ou PID) qui en fait la demande."}),"\n",(0,r.jsxs)(n.li,{children:["2 - g\xe9rer le statut des transactions dans un topic cach\xe9 de Kafka (dont le nom est ",(0,r.jsx)(n.code,{children:"__transaction_state"}),")."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour que le syst\xe8me de transactions fonctionne, il faut que ",(0,r.jsx)(n.strong,{children:"le PID du producer reste le m\xeame entre deux records consomm\xe9s"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Et pour \xe7a, il faut que le producer du stage suivant d\xe9clare le m\xeame ",(0,r.jsx)(n.code,{children:"transactional.id"})," que le pr\xe9c\xe9dent.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ce qui a pour effet que le transaction coordinator va assigner le m\xeame PID, tant que le d\xe9lai ",(0,r.jsx)(n.code,{children:"transactional.id.expiration"})," (par d\xe9faut 1 semaine) n'est pas d\xe9pass\xe9."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'association [ transactional ID, PID ] contient une propri\xe9t\xe9 ",(0,r.jsx)(n.strong,{children:"epoch"})," qui indique la date de la derni\xe8re mise \xe0 jour de cette association.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ce m\xe9canisme permet de bloquer les process client zombies, c'est-\xe0-dire qui ont \xe9t\xe9 \xe9ject\xe9s, mais qui continuent de penser que c'est \xe0 eux de publier : si leur epoch est plus ancien, ils ne pourront pas publier."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Garder le m\xeame PID permet aussi au producteur successeur de terminer les transactions non termin\xe9es du producer qui vient de crash ou timeout."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'essentiel de l'aspect transactionnel se passe c\xf4t\xe9 ",(0,r.jsx)(n.strong,{children:"API du producer"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le client producer Java a ces m\xe9thodes :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"initTransactions()"})," permet d'initialiser le syst\xe8me de transactions pour un producer donn\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On ne l'appelle qu'une fois, et \xe7a assigne un PID et un epoch pour l'association [ transactional ID, PID ]."}),"\n",(0,r.jsxs)(n.li,{children:["\xc7a va aussi attendre que les transactions pr\xe9c\xe9dentes associ\xe9es \xe0 ce transactional ID soient termin\xe9es (soit COMMITED, soit ABORTED).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dans le cas o\xf9 le consumer pr\xe9c\xe9dent n'a pas eu le temps de dire s'il voulait commit ou abort, par d\xe9faut le broker va d\xe9clarer la transaction ABORTED."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"beginTransaction()"})," permet de commencer la transaction."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"sendOffsetsToTransaction()"})," envoie les offsets du consumer.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le consumer va donc faire son commit \xe0 travers l'API du producer, et non pas avec sa m\xe9thode commit habituelle."}),"\n",(0,r.jsx)(n.li,{children:"Il faut bien s\xfbr que l'auto-commit soit d\xe9sactiv\xe9 pour le consumer."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"commitTransaction()"})," permet de valider la transaction."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"abortTransaction()"})," permet de l'annuler."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"choix du transactional ID"})," est un des sujets majeurs de confusion autour des transactions Kafka.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Parmi les possibilit\xe9s na\xefves qu'on pourrait imaginer :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si on lui attribue une m\xeame valeur parmi l'ensemble des producer process d'un m\xeame stage, seul l'instance de producer la plus r\xe9cente pourra prendre la main, en transformant les producers qui sont issus de la lecture de toutes les autres partitions, en zombies."}),"\n",(0,r.jsxs)(n.li,{children:["Si on lui attribue une valeur compl\xe8tement al\xe9atoire et unique du type UUID, alors aucun producer ne sera transform\xe9 en zombie, pas m\xeame ceux qui auront \xe9t\xe9 \xe9ject\xe9s \xe0 cause d'un timeout.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ces process \xe0 qui on aurait enlev\xe9 la responsabilit\xe9 de leurs partitions, et qui seraient encore en train d'attendre qu'une transaction se termine, pourraient encore bloquer le fait que de nouveaux messages apparraissent dans leurs anciennes partitions pendant ",(0,r.jsx)(n.code,{children:"transactional.id.expiration.ms"})," (par d\xe9faut 1 heure)."]}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas o\xf9 ces process auraient encore des messages dans leur buffer, ils pourraient aussi continuer \xe0 ex\xe9cuter leurs callbacks."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La bonne solution est d'assigner un transactional ID compos\xe9 de la ",(0,r.jsx)(n.strong,{children:"concat\xe9nation entre l'input topic et l'index de la partition de ce topic"})," qu'on est en train de consommer.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le r\xe9sultat c'est potentiellement un grand nombre de producers cr\xe9\xe9s, avec chacun son transactional ID compos\xe9 du topic et de l'index de la partition.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour \xe9viter d'en avoir trop, l'approche privil\xe9gi\xe9e est de ne cr\xe9er que les producers pour les partitions assign\xe9es \xe0 un consumer donn\xe9, et de les supprimer si les partitions sont rebalanc\xe9es et enlev\xe9es."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["C\xf4t\xe9 ",(0,r.jsx)(n.strong,{children:"consumers"}),", la notion de transaction se mat\xe9rialise dans le choix de ce qui sera lu.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Quand le producer publie des messages dans des topics dans le cadre d'une transaction, il va les ",(0,r.jsx)(n.strong,{children:"publier directement et de mani\xe8re irr\xe9vocable"}),", mais ils seront entour\xe9s de ",(0,r.jsx)(n.strong,{children:"markers"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il y a un marker pour indiquer le d\xe9but de la transaction dans la partition, et un autre pour indiquer la fin de transaction r\xe9ussie (COMMITTED) ou \xe9chou\xe9e (ABORTED)."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le consumer dispose d'une option ",(0,r.jsx)(n.code,{children:"isolation.level"})," (par d\xe9faut ",(0,r.jsx)(n.code,{children:"read_uncommited"}),").","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La valeur ",(0,r.jsx)(n.code,{children:"read_uncommited"})," permet de lire tous les records de la partition, ceux qui ne font pas partie d'une transaction comme ceux qui en font partie, que la transaction soit valid\xe9e, annul\xe9e, ou toujours en cours."]}),"\n",(0,r.jsxs)(n.li,{children:["La valeur ",(0,r.jsx)(n.code,{children:"read_commited"})," permet de ne lire que les records qui ne font pas partie d'une transaction, ou ceux qui sont dans une transaction valid\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour un consumer qui a ",(0,r.jsx)(n.code,{children:"read_commited"})," activ\xe9, l'End Offset est remplac\xe9 par la notion de ",(0,r.jsx)(n.strong,{children:"LSO (Last Stable Offset)"}),", qui pointe vers le dernier record qui ne fait pas partie d'une transaction non termin\xe9e."]}),"\n",(0,r.jsx)(n.li,{children:"Tant que la transaction est en cours, le consumer ne pourra pas lire plus loin."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les transactions ont un certain nombre de ",(0,r.jsx)(n.strong,{children:"limitations"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le syst\xe8me de transaction de Kafka n'est pas compatible avec d'autres syst\xe8mes de transaction comme XA ou JTA."}),"\n",(0,r.jsx)(n.li,{children:"Une transaction est limit\xe9e \xe0 un m\xeame producer (m\xeame transactional ID, m\xeame PID)."}),"\n",(0,r.jsxs)(n.li,{children:["La transaction peut \xeatre ",(0,r.jsx)(n.strong,{children:"lue de mani\xe8re partielle"})," par des consumers sans qu'ils s'en rendent compte : il suffit que le consumer n'ait \xe0 sa charge que certaines partitions o\xf9 la transaction a publi\xe9 des messages, mais pas les autres."]}),"\n",(0,r.jsx)(n.li,{children:"La exactly-once delivery ne s‘applique pas aux side effects en dehors de Kafka : par exemple on peut jouer une callback plusieurs fois, et ajouter plusieurs entr\xe9es en DB, m\xeame si c\xf4t\xe9 Kafka les messages sont bien publi\xe9s exactly-once."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Faut-il utiliser les transactions ?"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut se poser la question de la complexit\xe9 additionnelle par rapport \xe0 ce que \xe7a apporte : une d\xe9duplication des messages \xe0 travers les stages.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dans le cas o\xf9 la consommation de nos messages n'a que des side-effects idempotents, alors avoir des messages en double dans Kafka peut ne pas \xeatre probl\xe9matique."}),"\n",(0,r.jsx)(n.li,{children:"D'un autre c\xf4t\xe9, la complexit\xe9 en question peut \xeatre abstraite dans une couche adapter."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}n.default=(0,i.j)({MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,l.a)(),e.components);return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(o,{...e})}):o(e)},pageOpts:{filePath:"pages/books/effective-kafka.mdx",route:"/books/effective-kafka",title:"Effective Kafka",headings:a},pageNextRoute:"/books/effective-kafka"})},8397:function(e,n,s){"use strict";s.d(n,{U:function(){return i}});var r=s(5893);function i(e){let{children:n}=e;return(0,r.jsx)("em",{style:{color:"#3d85c6",fontWeight:"bold",fontStyle:"normal"},children:n})}}},function(e){e.O(0,[673,888,774,179],function(){return e(e.s=5980)}),_N_E=e.O()}]);