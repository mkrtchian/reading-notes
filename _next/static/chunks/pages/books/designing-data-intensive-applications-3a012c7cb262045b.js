(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[30],{2869:function(e,n,s){(window.__NEXT_P=window.__NEXT_P||[]).push(["/books/designing-data-intensive-applications",function(){return s(5163)}])},5163:function(e,n,s){"use strict";s.r(n),s.d(n,{__toc:function(){return a}});var r=s(5893),i=s(2673),t=s(2643),l=s(8397);let a=[{depth:2,value:"1 - Reliable, scalable and maintainable applications",id:"1---reliable-scalable-and-maintainable-applications"},{depth:2,value:"2 - Data Models and Query Languages",id:"2---data-models-and-query-languages"},{depth:2,value:"3 - Storage and retrieval",id:"3---storage-and-retrieval"},{depth:2,value:"4 - Encoding and evolution",id:"4---encoding-and-evolution"},{depth:2,value:"5 - Replication",id:"5---replication"},{depth:2,value:"6 - Partitioning",id:"6---partitioning"},{depth:2,value:"7 - Transactions",id:"7---transactions"},{depth:2,value:"8 - The trouble with distributed systems",id:"8---the-trouble-with-distributed-systems"},{depth:2,value:"9 - Consistency and Consensus",id:"9---consistency-and-consensus"},{depth:2,value:"10 - Batch Processing",id:"10---batch-processing"},{depth:2,value:"11 - Stream Processing",id:"11---stream-processing"},{depth:2,value:"12 - The Future of Data Systems",id:"12---the-future-of-data-systems"}];function u(e){let n=Object.assign({h1:"h1",h2:"h2",ul:"ul",li:"li",strong:"strong",em:"em"},(0,t.a)(),e.components);return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h1,{children:"Designing Data-Intensive Applications"}),"\n",(0,r.jsx)(n.h2,{id:"1---reliable-scalable-and-maintainable-applications",children:"1 - Reliable, scalable and maintainable applications"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Data-intensive d\xe9signe le fait que les donn\xe9es soient le bottleneck, par opposition \xe0 compute-intensive qui fait r\xe9f\xe9rence au CPU."}),"\n",(0,r.jsxs)(n.li,{children:["Les fronti\xe8res entre les diff\xe9rentes cat\xe9gories (base de donn\xe9es, cache, syst\xe8me de queuing etc.) deviennent parfois floues. Par ex : ",(0,r.jsx)(l.U,{children:"Redis"})," est un cache utilis\xe9 comme syst\xe8me de queuing, ou encore ",(0,r.jsx)(l.U,{children:"Kafka"})," qui est un syst\xe8me de queuing avec une garantie de persistance comme une BDD."]}),"\n",(0,r.jsxs)(n.li,{children:["Il y a 3 enjeux principaux auxquels on r\xe9pond quand on con\xe7oit un syst\xe8me de donn\xe9es :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"fiabilit\xe9"})," (",(0,r.jsx)(n.strong,{children:"reliability"}),") consiste \xe0 fonctionner correctement malgr\xe9 les fautes mat\xe9rielles, logicielles, ou humaines.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les disques durs sont connus pour faire des fautes tous les 10 \xe0 50 ans, ce qui veut dire que sur un parc de 10 000 disques, il y en a un qui saute tous les jours. On peut pr\xe9venir ce genre de probl\xe8me par de la redondance (RAID par ex)."}),"\n",(0,r.jsx)(n.li,{children:"Les fautes logicielles sont beaucoup plus insidieuses, et peuvent causer des d\xe9g\xe2ts en cha\xeene. Pour les pr\xe9venir on peut mettre en place du monitoring, pr\xe9voir des restarts de processus en cas de crash etc. Mais \xe7a reste bien maigre en soi."}),"\n",(0,r.jsx)(n.li,{children:"Les fautes humaines sont in\xe9vitables, il faut concevoir les syst\xe8mes de mani\xe8re \xe0 d\xe9courager les actions probl\xe9matiques, faire beaucoup de tests automatis\xe9s, rendre facile le fallback etc."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"scalabilit\xe9"})," consiste \xe0 accompagner le syst\xe8me dans sa mont\xe9e en charge en termes de donn\xe9es, de trafic ou de complexit\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Parler de scalabilit\xe9 tout court n'a pas vraiment de sens, il faut pr\xe9ciser sur quel aspect on scale.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il faut d'abord ",(0,r.jsx)(n.strong,{children:"d\xe9crire le load"})," sur lequel on veut scaler. Par ex (page 11) : pour ",(0,r.jsx)(n.strong,{children:"twitter"})," le load cl\xe9 c'est le nombre de followers par personne :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"la 1\xe8re solution consiste \xe0 recr\xe9er la timeline de tweets de chaque utilisateur depuis la base de donn\xe9es"}),"\n",(0,r.jsx)(n.li,{children:"la 2\xe8me \xe0 constituer des timelines \xe0 jour dans un cache, et de mettre \xe0 jour les timelines des followers \xe0 chaque tweet. Du coup avec la solution 2 tout d\xe9pend du nombre de followers."}),"\n",(0,r.jsx)(n.li,{children:"Twitter a fini par adopter une solution hybride : la 2\xe8me solution par d\xe9faut, et la 1\xe8re pour les comptes avec \xe9norm\xe9ment de followers. Par d\xe9faut la timeline est dans le cache, mais si une c\xe9l\xe9brit\xe9 est suivie, une requ\xeate sera faite pour r\xe9cup\xe9rer les tweets."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Ensuite il faut ",(0,r.jsx)(n.strong,{children:"d\xe9crire la m\xe9trique de performance"}),". Il s'agit d'augmenter le load qu'on a d\xe9crit pour voir jusqu'o\xf9 on tient.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Si notre m\xe9trique concerne un service en ligne, on va en g\xe9n\xe9ral prendre le temps de r\xe9ponse.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["(Le ",(0,r.jsx)(n.strong,{children:"temps de r\xe9ponse"})," et la ",(0,r.jsx)(n.strong,{children:"latence"})," sont diff\xe9rents : la latence concerne le temps pendant lequel la requ\xeate est latente, c'est-\xe0-dire qu'elle attend d'\xeatre trait\xe9e. Le temps de r\xe9ponse est plus long que \xe7a.)"]}),"\n",(0,r.jsxs)(n.li,{children:["Il faut reproduire la requ\xeate un grand nombre de fois, et prendre la ",(0,r.jsx)(n.strong,{children:"m\xe9diane"})," pour avoir une id\xe9e du temps que \xe7a prend. Dans la m\xeame id\xe9e on peut prendre les ",(0,r.jsx)(n.strong,{children:"percentiles"})," pour voir par ex. si on arrive \xe0 rester sous un certain seuil pour 99.9% de nos requ\xeates (appel\xe9 p999)."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour r\xe9pondre aux probl\xe9matiques de scalabilit\xe9 :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Une r\xe9ponse \xe0 un certain load ne marchera pas pour un load beaucoup plus important : il faut repenser r\xe9guli\xe8rement son architecture si on scale vraiment."}),"\n",(0,r.jsxs)(n.li,{children:["Il y a le ",(0,r.jsx)(n.strong,{children:"scale vertical"})," (machine plus puissante) et le ",(0,r.jsx)(n.strong,{children:"scale horizontal"})," (plus de machines, qu'on appelle aussi ",(0,r.jsx)(n.strong,{children:"shared-nothing architecture"}),").","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"En r\xe9alit\xe9, on utilise souvent un mix des deux : des machines puissantes pour certaines t\xe2ches, et du scaling horizontal pour d'autres."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"La cr\xe9ation de machines suppl\xe9mentaires peut \xeatre manuelle ou “\xe9lastique”. La version \xe9lastique permet d'adapter aux grandes variations mais est plus complexe aussi."}),"\n",(0,r.jsx)(n.li,{children:"Habituellement, avoir une application stateful qui est sur plusieurs machines est difficile \xe0 g\xe9rer, donc on essaye de garder la BDD sur une seule machine jusqu'\xe0 ce que ce ne soit plus possible. Avec l'\xe9volution des outils, ceci sera sans doute amen\xe9 \xe0 changer."}),"\n",(0,r.jsxs)(n.li,{children:["Il n'y a pas de ",(0,r.jsx)(n.em,{children:"magic scaling sauce"})," : chaque application de grande \xe9chelle a ses propres contraintes, ses propres bottlenecks, et donc sa propre architecture."]}),"\n",(0,r.jsx)(n.li,{children:"Quand on cr\xe9e un produit, il vaut au d\xe9but passer surtout du temps \xe0 d\xe9velopper les fonctionnalit\xe9s qu'\xe0 penser son hypoth\xe9tique scaling."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"maintenabilit\xe9"})," consiste \xe0 pouvoir \xe0 la fois perp\xe9tuer le syst\xe8me et le faire \xe9voluer en un temps de travail raisonnable.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour qu'un syst\xe8me soit maintenable dans le temps, il faut travailler sur ces aspects :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"operability"})," : la facilit\xe9 pour les ops de faire tourner le syst\xe8me.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il faut faciliter la vie au maximum pour les ops. Ex : fournir un bon monitoring, permettre d'\xe9teindre une machine individuellement sans affecter le reste, avoir de bonnes valeurs par d\xe9faut et un comportement auto-r\xe9parateur, tout en permettant aux ops de prendre la main."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"simplicity"})," : que le syst\xe8me soit le moins complexe possible pour le comprendre rapidement et pouvoir travailler dessus.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut par exemple r\xe9duire la ",(0,r.jsx)(n.strong,{children:"complexit\xe9 accidentelle"}),", c'est-\xe0-dire la complexit\xe9 non n\xe9cessaire li\xe9e seulement \xe0 l'impl\xe9mentation mauvaise."]}),"\n",(0,r.jsxs)(n.li,{children:["Sinon globalement une bonne chose \xe0 faire c'est d'introduire des ",(0,r.jsx)(n.strong,{children:"abstractions"})," pour appr\xe9hender le syst\xe8me plus facilement. Par ex. les langages haut niveau sont des abstractions de ce qui se passe dans la machine."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"evolvability"})," : la facilit\xe9 \xe0 changer ou ajouter des fonctionnalit\xe9s au syst\xe8me.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il s'agit ici de l'agilit\xe9 mais appliqu\xe9e \xe0 tout un syst\xe8me, et pas \xe0 de petites fonctionnalit\xe9s."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2---data-models-and-query-languages",children:"2 - Data Models and Query Languages"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"mod\xe8le de donn\xe9es relationnel"})," a domin\xe9 le stockage depuis les ann\xe9es 70, en apportant de l'abstraction autour de la mani\xe8re dont les donn\xe9es \xe9taient structur\xe9es, contrairement aux autres alternatives.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Toutes les tentatives de d\xe9tr\xf4ner SQL ont \xe9chou\xe9, la hype est retomb\xe9e."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"NoSQL"})," arrive dans les ann\xe9es 2010 et regroupe tout un ensemble de technologies qui permettent de pallier aux probl\xe9matiques de scalabilit\xe9, et d'offrir une plus grande flexibilit\xe9 que les BDD relationnelles","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Parmi elles, il y a notamment les BDD bas\xe9es sur le ",(0,r.jsx)(n.strong,{children:"mod\xe8le de document"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Il est probable que les BDD relationnelles et NoSQL soient utilis\xe9es conjointement dans le futur."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il y a un d\xe9calage entre la POO et le format de BDD relationnel, qui oblige \xe0 une forme de conversion. Pour certaines donn\xe9es on pourrait utiliser une structure en document comme JSON par exemple au lieu du relationnel. Par ex pour le cas des infos d'un CV, on pourrait la ville d'un job autant de fois qu'elle appara\xeet.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On r\xe9p\xe8te alors \xe9ventuellement plusieurs fois certaines informations dans les entr\xe9es, ou alors on les met dans une table \xe0 part mais on fait les jointures \xe0 la main depuis le code applicatif.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["En r\xe9alit\xe9, ce probl\xe8me est apparu d\xe8s les ann\xe9es 70. Le ",(0,r.jsx)(n.strong,{children:"mod\xe8le hi\xe9rarchique"})," (proche du mod\xe8le sous forme de document qui a fait r\xe9surgence r\xe9cemment donc) faisait face \xe0 2 autres mod\xe8les : le ",(0,r.jsx)(n.strong,{children:"mod\xe8le relationnel"})," et le ",(0,r.jsx)(n.strong,{children:"mod\xe8le en r\xe9seau (network model)"})," qui a fini par \xeatre abandonn\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le mod\xe8le en r\xe9seau consistait \xe0 avoir un mod\xe8le hi\xe9rarchique mais avec la possibilit\xe9 pour chaque donn\xe9e d'avoir plusieurs parents. Mais \xe7a rendait le code applicatif difficile \xe0 maintenir."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"normalisation"})," consiste justement dans les BDD relationnelles \xe0 trouver ce genre de r\xe9p\xe9tition, et \xe0 les factoriser en une nouvelle table. Le but est d'\xe9viter la duplication, et donc de renforcer la consistance des donn\xe9es. \xc7a permet aussi de les modifier facilement en un seul endroit."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Comparaison aujourd'hui du mod\xe8le relationnel et du mod\xe8le de document :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Simplicit\xe9 du code applicatif :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le mod\xe8le de document m\xe8ne \xe0 un code applicatif plus simple dans le cas o\xf9 il y a peu de relations many to many ou many to one (pour les one to many c'est ok puisqu'on r\xe9p\xe8te de toute fa\xe7on la donn\xe9e dans la table du mod\xe8le de document)."}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas contraire il faudrait faire les jointures \xe0 la main donc le mod\xe8le relationnel serait meilleur (code applicatif plus simple et jointures par la BDD plus efficaces)."}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas o\xf9 il y a une forte interconnexion entre les donn\xe9es (de nombreuses relations many to many), c'est alors le mod\xe8le en graphe qui serait le plus pertinent."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Flexibilit\xe9 du sch\xe9ma de donn\xe9es :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est un peu comme la diff\xe9rence entre le typage statique et dynamique des langages de programmation : le mod\xe8le relationnel force \xe0 d\xe9clarer un type de donn\xe9es et \xe0 s'y conformer ou faire une migration. Le mod\xe8le de document permet de changer de type de donn\xe9es en cours de route et donc la gestion des donn\xe9es est enti\xe8rement confi\xe9e \xe0 l'application, qui gagne en libert\xe9 et du coup en responsabilit\xe9."}),"\n",(0,r.jsx)(n.li,{children:"Le mod\xe8le de document est vraiment meilleur quand les donn\xe9es sont de type h\xe9t\xe9rog\xe8ne, ou encore si elles sont d\xe9termin\xe9es par un syst\xe8me ext\xe9rieur sur lequel la BDD n'a pas le contr\xf4le."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Localit\xe9 des donn\xe9es :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Vu que dans le mod\xe8le de document les donn\xe9es sont copi\xe9es dans chaque entr\xe9e, elles sont locales \xe0 celles-ci. On peut donc les avoir avec juste une requ\xeate, et on utilise moins le disque dur qu'avec le mod\xe8le relationnel. En revanche on va chercher le document entier, donc si on a souvent besoin d'un tout petit morceau \xe7a n'en vaut peut \xeatre pas le coup."}),"\n",(0,r.jsxs)(n.li,{children:["Certaines BDD relationnelles permettent aussi de localiser des tables vis-\xe0-vis d'autres (ex : ",(0,r.jsx)(l.U,{children:"Spanner database"})," de ",(0,r.jsx)(l.U,{children:"Google"}),", ",(0,r.jsx)(l.U,{children:"Oracle"}),", ou encore ",(0,r.jsx)(l.U,{children:"Bigtable"})," data model (utilis\xe9 dans ",(0,r.jsx)(l.U,{children:"Cassandra"})," et ",(0,r.jsx)(l.U,{children:"Hbase"}),")."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les diff\xe9rentes impl\xe9mentations de BDD ont tendance \xe0 converger : la plupart des BDD relationnelles supportent les op\xe9rations dans du contenu XML ou JSON, et ",(0,r.jsx)(l.U,{children:"RethinkDB"})," et ",(0,r.jsx)(l.U,{children:"MongoDB"})," permettent de faire une forme de jointure automatique, m\xeame si moins efficace."]}),"\n",(0,r.jsxs)(n.li,{children:["Le mod\xe8le relationnel offre un langage ",(0,r.jsx)(n.strong,{children:"d\xe9claratif"}),", alors que le mod\xe8le hi\xe9rarchique n'offre qu'un langage ",(0,r.jsx)(n.strong,{children:"imp\xe9ratif"}),". L'avantage du d\xe9claratif c'est que \xe7a abstrait des d\xe9tails qui peuvent \xeatre laiss\xe9s \xe0 la discr\xe9tion de l'outil de BDD qu'on utilise pour faire des optimisations.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"MapReduce"}),", qui est un mod\xe8le popularis\xe9 par Google et disponible dans ",(0,r.jsx)(l.U,{children:"MongoDB"}),", ",(0,r.jsx)(l.U,{children:"CouchDB"})," et ",(0,r.jsx)(l.U,{children:"Hadoop"})," est entre le d\xe9claratif et l'imp\xe9ratif. Il abstrait certaines op\xe9rations mais permet aussi d'ajouter du code en plein milieu d'une requ\xeate qui aurait \xe9t\xe9 atomique en SQL."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Dans les ",(0,r.jsx)(n.strong,{children:"bases de donn\xe9es de graphes"}),", les donn\xe9es sont repr\xe9sent\xe9es sous forme d'entit\xe9s reli\xe9s par des traits.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ex : Facebook utilise un graphe g\xe9ant o\xf9 sont pr\xe9sentes des entit\xe9s vari\xe9es (personne, lieu, commentaire), reli\xe9s entre eux avec des types de liens diff\xe9rents."}),"\n",(0,r.jsxs)(n.li,{children:["Mod\xe8le ",(0,r.jsx)(n.strong,{children:"property graph"})," (impl\xe9ment\xe9 par ",(0,r.jsx)(l.U,{children:"Neo4j"}),", ",(0,r.jsx)(l.U,{children:"Titan"}),", ",(0,r.jsx)(l.U,{children:"InfiniteGraph"}),") :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il y a deux tables : les entit\xe9s (vertices) et les traits (edges) avec chacun leurs propri\xe9t\xe9s, et pour les edges la liste des couples d'entit\xe9s reli\xe9s par son biais."}),"\n",(0,r.jsx)(n.li,{children:"On peut facilement cr\xe9er de nouveaux types de liens, sans avoir besoin de vraiment modifier la structure de la BDD."}),"\n",(0,r.jsxs)(n.li,{children:["Le langage Cypher est un langage d\xe9claratif invent\xe9 pour ",(0,r.jsx)(l.U,{children:"Neo4j"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"L'avantage c'est que le langage de graphe permet de trouver des donn\xe9es en parcourant un nombre ind\xe9termin\xe9 de chemins, et donc de faire un nombre non connu \xe0 l'avance de jointures. C'est possible en SQL mais avec une syntaxe beaucoup plus longue."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Mod\xe8le ",(0,r.jsx)(n.strong,{children:"triple-store"})," (impl\xe9ment\xe9 par ",(0,r.jsx)(l.U,{children:"Datomic"}),", ",(0,r.jsx)(l.U,{children:"AllegroGraph"}),") :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il s'agit de la m\xeame chose que le property graph, mais pr\xe9sent\xe9 diff\xe9remment : on a un groupe de 3 donn\xe9es qui sont (sujet, pr\xe9dicat, objet)."}),"\n",(0,r.jsx)(n.li,{children:"Turtle et SPARQL sont des langages qui permettent d'utiliser le triple-store."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"3---storage-and-retrieval",children:"3 - Storage and retrieval"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Un des moyens d'organiser les donn\xe9es dans une BDD est d'utiliser un syst\xe8me de log : l'ajout de donn\xe9es est fait en ajoutant le contenu \xe0 la fin d'un fichier (ce qui est tr\xe8s rapide), et la lecture est faite en parcourant l'ensemble des donn\xe9es (ce qui est tr\xe8s lent O(n)).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour acc\xe9l\xe9rer la lecture, on peut cr\xe9er des ",(0,r.jsx)(n.strong,{children:"index"})," sur les champs dont on estime qu'ils vont souvent servir \xe0 faire des recherches. \xc7a acc\xe9l\xe8re la lecture, mais \xe7a ralentit l'\xe9criture puisqu'il faudra mettre \xe0 jour l'index \xe0 chaque fois.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut utiliser des ",(0,r.jsx)(n.strong,{children:"Hash index"})," tels que impl\xe9ment\xe9s dans ",(0,r.jsx)(l.U,{children:"Bitcast"}),", le moteur de stockage de ",(0,r.jsx)(l.U,{children:"Riak"}),". Il s'agit d'avoir une structure associant une cl\xe9 \xe0 un offset ",(0,r.jsx)(n.strong,{children:"en m\xe9moire vive"}),". A chaque recherche on n'a qu'\xe0 trouver la cl\xe9 et on peut directement lire la donn\xe9e sur disque.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour des raisons pratiques (consistance des donn\xe9es, performance gr\xe2ce aux op\xe9rations s\xe9quentielles et non pas random), les fichiers de BDD ne sont jamais modifi\xe9s. On \xe9crit les nouvelles donn\xe9es s\xe9quentiellement (donc pas de concurrence pour l'\xe9criture) toujours \xe0 la fin du fichier, et on fait du m\xe9nage dans le fichier dans un nouveau fichier de BDD r\xe9guli\xe8rement. Pareil pour supprimer une donn\xe9e : on ins\xe8re une commande dans le fichier et ce sera supprim\xe9 \xe0 la prochaine copie / optimisation du fichier de BDD."}),"\n",(0,r.jsx)(n.li,{children:"Les limitations c'est qu'il faut que les cl\xe9s tiennent en m\xe9moire vive sinon c'est foutu, et que les recherches de “ranges” de cl\xe9s ne sont pas efficaces, \xe7a revient \xe0 chercher les cl\xe9s une par une."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut aussi stocker les donn\xe9es sous forme tri\xe9e d\xe8s le d\xe9but. On a alors les ",(0,r.jsx)(n.strong,{children:"Sorted String Table (SSTable)"}),". Ca consiste \xe0 avoir une structure d'arbre tri\xe9e en m\xe9moire o\xf9 vont les nouvelles donn\xe9es (qu'on va appeler la ",(0,r.jsx)(n.strong,{children:"memtable"}),"). Et tous les quelques Mo on \xe9crit \xe7a sur DD. Puis r\xe9guli\xe8rement on va faire des op\xe9rations en t\xe2che de fond pour grouper les arbres tri\xe9s en un seul. Lors d'une recherche, on va d'abord chercher dans le bloc le plus r\xe9cent, puis de moins en moins r\xe9cent, jusqu'\xe0 arriver au gros bloc, sachant que tous les blocs sont d\xe9j\xe0 tri\xe9s.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Un des avantages c'est qu'on n'a plus \xe0 faire entrer toutes les cl\xe9s en RAM. On peut avoir en m\xe9moire un nombre de cl\xe9s beaucoup plus \xe9pars qui indique les offsets."}),"\n",(0,r.jsx)(n.li,{children:"Autre avantage aussi qui r\xe9pond au probl\xe8me du hash index : on peut faire des recherches de “range” d'index, vu que tout est d\xe9j\xe0 tri\xe9."}),"\n",(0,r.jsx)(n.li,{children:"Et aussi, comme tout est d\xe9j\xe0 tri\xe9 et qu'on a les offsets des donn\xe9es groupe par groupe, on peut compresser des groupes de donn\xe9es ensemble."}),"\n",(0,r.jsxs)(n.li,{children:["Ce m\xe9canisme est aussi appel\xe9 ",(0,r.jsx)(n.strong,{children:"Log Structure Merge Tree (LSM Tree)"})," en r\xe9f\xe9rence \xe0 un papier d\xe9crivant le m\xe9canisme."]}),"\n",(0,r.jsxs)(n.li,{children:["De nombreux moteurs de BDD utilisent ce principe :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"LevelDB"})," (peut \xeatre utilis\xe9 dans ",(0,r.jsx)(l.U,{children:"Riak"}),") et ",(0,r.jsx)(l.U,{children:"RocksDB"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Cassandra"})," et ",(0,r.jsx)(l.U,{children:"HBase"}),", inspir\xe9s du papier Bigtable et Google."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Lucene"})," (moteur d'",(0,r.jsx)(l.U,{children:"Elasticsearch"})," et de ",(0,r.jsx)(l.U,{children:"Solr"}),") utilise un m\xe9canisme similaire pour indexer le texte."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["En terme d'optimisations :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La recherche peut \xeatre lente : on cherche dans la structure en m\xe9moire, puis dans le premier bloc en BDD et ainsi de suite tant qu'on ne trouve pas, jusqu'\xe0 avoir cherch\xe9 dans le bloc d\xe9j\xe0 compact\xe9. Pour rem\xe9dier \xe0 \xe7a on peut approximer la recherche avec des structures efficaces appel\xe9es ",(0,r.jsx)(n.strong,{children:"Bloom Filters"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Il y a 2 types de strat\xe9gies de compaction :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"size-tiered"})," : les nouveaux et petits blocs sont r\xe9guli\xe8rement fusionn\xe9s avec les anciens et plus gros blocs.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"HBase"})," utilise cette technique, alors que ",(0,r.jsx)(l.U,{children:"Cassandra"})," supporte les deux."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"leveled"})," : les blocs sont plus petits et la compaction se fait de mani\xe8re plus incr\xe9mentale, utilisant moins d'espace disque.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"LevelDB"})," tient son nom du fait qu'il utilise cette technique. On a aussi ",(0,r.jsx)(l.U,{children:"RocksDB"})," ici."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La structure de BDD la plus utilis\xe9e et depuis longtemps est le ",(0,r.jsx)(n.strong,{children:"B-Tree"}),". La plupart des BDD relationnelles l'utilisent, mais aussi une bonne partie des BDD NoSQL.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il s'agit d'avoir des pages de taille fixe (en g\xe9n\xe9ral 4 ko), organis\xe9s en couches (rarement plus de 4 couches). Chaque page contient des cl\xe9s et des r\xe9f\xe9rences vers des zones physiques de disque pour aller chercher les cl\xe9s entre deux cl\xe9s indiqu\xe9es (sorte de dichotomie donc). On descend de couche en couche jusqu'\xe0 arriver \xe0 une page qui contient des donn\xe9es et pas de r\xe9f\xe9rences vers d'autres pages."}),"\n",(0,r.jsx)(n.li,{children:"Comme avec les LSM-Tree, pour que les B-Tree survivent \xe0 un crash sans perte de donn\xe9es, on va \xe9crire toutes les op\xe9rations dans un fichier de log avant de modifier la BDD elle-m\xeame. Ensuite on peut d\xe9truire ce fichier de log."}),"\n",(0,r.jsx)(n.li,{children:"Il peut y avoir des probl\xe8mes de concurrence avec les B-Tree, on va alors utiliser des locks locaux pour bloquer correctement une partie de la BDD pour le thread qui \xe9crit dedans. Ce probl\xe8me n'existe pas avec les LSM-Tree puisque les op\xe9rations de restructuration sont faites en arri\xe8re plan."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Comparaison B-Tree / LSM-Tree :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"Chacun a des avantages et inconv\xe9nients, le mieux selon Kleppmann c'est de tester empiriquement dans notre cas particulier lequel a la meilleure performance."})}),"\n",(0,r.jsxs)(n.li,{children:["A priori, la plupart du temps l'\xe9criture serait plus rapide sur les LSM-Tree (\xe0 priori parce qu'il y aurait souvent une ",(0,r.jsx)(n.em,{children:"write amplification"})," moins importante), alors que la lecture serait plus rapide sur les B-Tree (parce que les LSM-Tree ont besoin de lire plusieurs groupes de donn\xe9es tri\xe9es jusqu'\xe0 ce que la compaction soit faite en arri\xe8re-plan)."]}),"\n",(0,r.jsx)(n.li,{children:"Les LSM-Tree sont meilleurs en particulier sur les disques durs m\xe9caniques \xe9tant donn\xe9 qu'ils organisent leurs donn\xe9es s\xe9quentiellement et ne font pas d'acc\xe8s random."}),"\n",(0,r.jsx)(n.li,{children:"Les LSM-Tree stockent leurs donn\xe9es sur moins d'espace gr\xe2ce \xe0 la compression, mais en m\xeame temps au moment o\xf9 les donn\xe9es arrivent, ils les stockent dans un autre fichier que la BDD principale. Jusqu'\xe0 ce que les op\xe9rations d'arri\xe8re-plan soient ex\xe9cut\xe9es, il y a des copies plus ou moins r\xe9centes des donn\xe9es qui coexistent sur le disque."}),"\n",(0,r.jsx)(n.li,{children:"Les B-Tree offrent plus de pr\xe9dictibilit\xe9. M\xeame si une op\xe9ration d'\xe9criture peut prendre plus de temps, on reste constant et \xe9vite des pics dans les hauts percentiles, qui peuvent arriver avec les LSM-Tree dans le cas o\xf9 le disque serait par exemple surcharg\xe9 et que les op\xe9rations d'arri\xe8re plan prendraient du retard."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["En plus des index primaires il est possible de faire des ",(0,r.jsx)(n.strong,{children:"index secondaires"}),", qui vont indexer en fonction d'une autre colonne dont on estime qu'elle sera utile pour la recherche de donn\xe9es. La diff\xe9rence avec l'index primaire c'est qu'on n'a pas besoin d'avoir une unicit\xe9 sur les donn\xe9es de la colonne index\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Cet index peut soit contenir une r\xe9f\xe9rence vers l'endroit o\xf9 est stock\xe9e la donn\xe9e (qu'on appelle ",(0,r.jsx)(n.em,{children:"heap file"}),"), soit une version dupliqu\xe9e de la donn\xe9e elle-m\xeame (on parle de ",(0,r.jsx)(n.strong,{children:"clustered index"}),"). Il y a des avantages et inconv\xe9nients \xe9vidents \xe0 le faire et ne pas le faire (rapidit\xe9 de recherche vs temps d'\xe9criture et consistance)."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut aussi faire des ",(0,r.jsx)(n.strong,{children:"index multi-colonnes"}),". \xc7a permet de chercher par plusieurs champs en m\xeame temps.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le plus connu est l'",(0,r.jsx)(n.strong,{children:"index concat\xe9n\xe9"}),", qui consiste \xe0 accoler plusieurs champs ensemble dans l'index, par ex “NomPr\xe9nom”, qui permet de chercher par “Nom”, ou par “NomPr\xe9nom”, mais pas par “Pr\xe9nom”."]}),"\n",(0,r.jsxs)(n.li,{children:["Il y a aussi les ",(0,r.jsx)(n.strong,{children:"index multi-dimensionnels"}),", qui permettent de pouvoir chercher avec plusieurs colonnes ind\xe9pendamment, utile par exemple pour la recherche de coordonn\xe9es g\xe9ospatiales longitude / latitude.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["C'est impl\xe9ment\xe9 par ex par ",(0,r.jsx)(l.U,{children:"PostGIS"})," dans ",(0,r.jsx)(l.U,{children:"PostgreSQL"}),", qui utilise des R-trees en interne."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Lucene"})," permet de faire des recherches de termes avec des distances (une distance de 1 signifie qu'avec une lettre diff\xe9rente dans le mot, il sera retenu) gr\xe2ce \xe0 sa structure de cl\xe9s en m\xe9moire particuli\xe8re."]}),"\n",(0,r.jsxs)(n.li,{children:["La RAM \xe9tant de moins en moins ch\xe8re, on peut imaginer des BDD enti\xe8rement en RAM.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour pallier le risque de perte de donn\xe9es, on peut \xe9crire sur disque en parall\xe8le, avoir de la RAM avec batterie, ou encore faire des r\xe9plications en m\xe9moire."}),"\n",(0,r.jsxs)(n.li,{children:["Plusieurs moteurs de BDD fonctionnent comme \xe7a :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"VoltDB"}),", ",(0,r.jsx)(l.U,{children:"MemSQL"})," et ",(0,r.jsx)(l.U,{children:"Oracle TimesTen"}),", ainsi que ",(0,r.jsx)(l.U,{children:"RAMCloud"})," qui est open source."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Redis"})," et ",(0,r.jsx)(l.U,{children:"Couchbase"})," offrent une durabilit\xe9 faible en \xe9crivant sur disque de mani\xe8re asynchrone."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Contrairement \xe0 ce qu'on pourrait penser, le gain de performance d'utiliser des BDD in-memory ne vient pas forc\xe9ment de l'\xe9criture/lecture sur DD en elle-m\xeame, puisque l'OS met de toute fa\xe7on les donn\xe9es r\xe9cemment manipul\xe9es en cache dans la RAM. En fait, le gain vient surtout du temps de conversion des donn\xe9es dans un format qu'on peut \xe9crire sur DD."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Ce qu'on appelle ",(0,r.jsx)(n.strong,{children:"transaction"})," n'a pas forc\xe9ment besoin d'\xeatre ACID (atomic, consistant, isol\xe9, durable). Il s'agit simplement d'un terme d\xe9signant des lectures/\xe9critures avec faible latence, par opposition \xe0 ",(0,r.jsx)(n.strong,{children:"batch"}),", qui lui d\xe9signe les jobs faits p\xe9riodiquement dans le temps."]}),"\n",(0,r.jsxs)(n.li,{children:["La transaction classique est appel\xe9e ",(0,r.jsx)(n.strong,{children:"OLTP"})," (OnLine Transaction Processing). Il existe un autre type de transaction : ",(0,r.jsx)(n.strong,{children:"OLAP"})," (OnLine Analytic Processing) qui consiste \xe0 agir sur peu de colonnes mais un tr\xe8s grand nombre d'entr\xe9es, pour faire des analyses de donn\xe9es (par exemple des comptages, statistiques etc.)."]}),"\n",(0,r.jsxs)(n.li,{children:["Depuis les ann\xe9es 80 les grandes entreprises stockent une copie de leur BDD dans un ",(0,r.jsx)(n.strong,{children:"Data Warehouse"})," : une base de donn\xe9es structur\xe9e de mani\xe8re \xe0 optimiser les requ\xeates d'analyse, et ne risquant pas d'affecter la prod.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["SQL permet d'\xeatre performant sur l'OLTP comme sur l'OLAP, globalement c'est \xe7a qu'on va utiliser sur les data warehouses. Par contre les BDD sont structur\xe9es bien diff\xe9remment pour optimiser l'analyse.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Un certain nombre d'acteurs proposent des data warehouses avec des licences commerciales on\xe9reuses : ",(0,r.jsx)(l.U,{children:"Teradata"}),", ",(0,r.jsx)(l.U,{children:"Vertica"}),", ",(0,r.jsx)(l.U,{children:"SAP HANA"}),", ",(0,r.jsx)(l.U,{children:"ParAccel"})," (ainsi que ",(0,r.jsx)(l.U,{children:"Amazon RedShift"})," qui est une version host\xe9e de ParAccel)"]}),"\n",(0,r.jsxs)(n.li,{children:["D'autres acteurs open source de type SQL-on-Hadoop concurrencent les premiers : ",(0,r.jsx)(l.U,{children:"Apache Hive"}),", ",(0,r.jsx)(l.U,{children:"Spark SQL"}),", ",(0,r.jsx)(l.U,{children:"Cloudera Impala"}),", ",(0,r.jsx)(l.U,{children:"Facebook Presto"}),", ",(0,r.jsx)(l.U,{children:"Apache Tajo"}),", ",(0,r.jsx)(l.U,{children:"Apache Drill"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["De nombreux data warehouses sont organis\xe9s selon un ",(0,r.jsx)(n.strong,{children:"star schema"}),". On a la ",(0,r.jsx)(n.strong,{children:"fact table"})," au centre avec en g\xe9n\xe9ral des dizaines voir centaines de champs, et repr\xe9sentant les \xe9v\xe9nements \xe9tudi\xe9s. Et autour on a les ",(0,r.jsx)(n.strong,{children:"dimension tables"}),", r\xe9pondant aux questions ",(0,r.jsx)(n.em,{children:"who, what, where, when, how, why"})," et li\xe9es \xe0 la fact table par des foreign keys, ils repr\xe9sentent en quelques sortes les metadata.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Une variation du star model s'appelle ",(0,r.jsx)(n.strong,{children:"snowflakes"}),", il s'agit d'une version plus normalis\xe9e, o\xf9 on va davantage d\xe9couper les dimention tables en sous-tables."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La plupart du temps, les data warehouses utilisent un ",(0,r.jsx)(n.strong,{children:"column-oriented storage"})," plut\xf4t qu'un row-oriented. Il s'agit de stocker les donn\xe9es des colonnes physiquement c\xf4te \xe0 c\xf4te, parce que les requ\xeates vont avoir besoin de lire en g\xe9n\xe9ral quelques colonnes enti\xe8res.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La plupart du temps les bases en colonne sont relationnelles, mais il y a par ex ",(0,r.jsx)(l.U,{children:"Parquet"}),", bas\xe9 sur ",(0,r.jsx)(l.U,{children:"Google Dremel"}),", qui est orient\xe9 colonne mais non-relationnel."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Cassandra"})," et ",(0,r.jsx)(l.U,{children:"HBase"})," ont un concept de ",(0,r.jsx)(n.em,{children:"column families"}),", mais \xe7a consiste seulement \xe0 stocker toutes les colonnes d'une entr\xe9e ensemble, elles sont en r\xe9alit\xe9 essentiellement row oriented."]}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas o\xf9 les valeurs dans les colonnes se r\xe9p\xe8tent (en particulier s'il y a beaucoup plus de valeurs que de valeurs possibles), on peut faire une compression sur les colonnes. Par exemple une compression de type bitmap encoding"}),"\n",(0,r.jsx)(n.li,{children:"Un des avantages des column oriented storages c'est que \xe7a se pr\xeate bien \xe0 un traitement optimal entre la RAM et le cache du CPU, avec de petits cycles de traitement de donn\xe9es compress\xe9es provenant de la m\xeame colonne."}),"\n",(0,r.jsxs)(n.li,{children:["On peut profiter du m\xe9canisme des LSM-Trees avec les donn\xe9es en m\xe9moire et le reste de la BDD sur disque, pour trier les entr\xe9es d'une fa\xe7on particuli\xe8re. Par exemple, on peut choisir la colonne qui est souvent la plus recherch\xe9e, et trier les entr\xe9es de mani\xe8re \xe0 avoir toutes les entr\xe9es avec la m\xeame valeur dans cette colonne c\xf4te \xe0 c\xf4te. Et ainsi de suite pour les colonnes secondaires. \xc7a permet une meilleure recherche mais aussi une meilleure compression pour ces colonnes-l\xe0.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut \xe9galement choisir de trier diff\xe9remment chaque copie de la BDD qu'on poss\xe8de, pour choisir celle qui nous arrange le plus au moment de faire une requ\xeate. ",(0,r.jsx)(l.U,{children:"C-Store"})," et ",(0,r.jsx)(l.U,{children:"Vertica"})," font \xe7a."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour optimiser les requ\xeates dans les column oriented databases, \xe0 la place d'un inde on peut mettre en place une ",(0,r.jsx)(n.strong,{children:"materialized view"}),", qui consiste \xe0 ajouter une valeur ou une colonne de valeurs contenant des calculs (MIN, MAX, SUM etc.).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Un cas particulier s'appelle le ",(0,r.jsx)(n.strong,{children:"data cube"}),", il s'agit de prendre deux colonnes comme composant les deux dimensions d'une valeur qu'on cherche \xe0 analyser, et d'ajouter une colonne repr\xe9sentant un agr\xe9gat (par ex la somme des valeurs sur une des dimensions)."]}),"\n",(0,r.jsx)(n.li,{children:"Cette pratique permet d'acc\xe9l\xe9rer les requ\xeates parce que certaines choses sont pr\xe9-calcul\xe9es, mais \xe7a offre aussi moins de flexibilit\xe9. Donc en g\xe9n\xe9ral on s'en sert comme boost de performance tout en laissant aux data analyst la possibilit\xe9 de faire les requ\xeates qu'ils veulent."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"4---encoding-and-evolution",children:"4 - Encoding and evolution"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Quand on change les fonctionnalit\xe9s, y compris la BDD, il est utile de pouvoir faire une ",(0,r.jsx)(n.strong,{children:"rolling upgrade"})," (ou staged rollout). Il s'agit de d\xe9ployer le code sur certains nœuds, s'assurer que tout va bien, puis d\xe9ployer progressivement sur les autres.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cela implique que le code et la BDD doivent \xeatre backward-compatibles (supporter les fonctionnalit\xe9s du code pr\xe9c\xe9dent) mais aussi forward-compatibles (que le code pr\xe9c\xe9dent ignore les nouvelles fonctionnalit\xe9s)."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les donn\xe9es ont besoin d'au moins 2 repr\xe9sentations : une en m\xe9moire avec des pointeurs vers des zones m\xe9moire, et une quand on veut transmettre la donn\xe9e sur disque ou \xe0 travers le r\xe9seau. Il faut alors que tout soit contenu dans le bloc de donn\xe9es. La conversion de la m\xe9moire vers la version transportable s'appelle ",(0,r.jsx)(n.strong,{children:"encoding"})," (ou ",(0,r.jsx)(n.strong,{children:"serialization"})," ou marshalling).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il existe des formats li\xe9s \xe0 des langages, comme ",(0,r.jsx)(n.em,{children:"pickle"})," pour python, mais ces formats ne sont ni performants, ni ne g\xe8rent bien la r\xe9tro (et forward) compatibility. Et le format de donn\xe9es est trop centr\xe9 sur un langage particulier."]}),"\n",(0,r.jsxs)(n.li,{children:["On a les formats plus standards comme ",(0,r.jsx)(n.strong,{children:"XML"}),", ",(0,r.jsx)(n.strong,{children:"JSON"})," et ",(0,r.jsx)(n.strong,{children:"CSV"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"XML et CSV ne distinguent pas les nombres des strings, alors qu'en JSON on distingue les nombres mais pas les flottants des entiers par exemple."}),"\n",(0,r.jsx)(n.li,{children:"XML et JSON ont la possibilit\xe9 d'avoir des sch\xe9mas associ\xe9s mais ceux-ci ne font pas consensus."}),"\n",(0,r.jsx)(n.li,{children:"Globalement ces formats sont suffisants pour une communication entre organisations, tant que celles-ci s'accordent sur des conventions. En r\xe9alit\xe9, la plus grande difficult\xe9 est que des organisations diff\xe9rentes s'accordent sur quoique ce soit."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On a enfin les formats binaires non sp\xe9cifiques \xe0 un langage et con\xe7us pour la performance.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il existe des versions binaires (ne faisant pas consensus) pour JSON et XML. Par exemple pour JSON il y a ",(0,r.jsx)(l.U,{children:"MessagePack"}),", ",(0,r.jsx)(l.U,{children:"BSON"}),", ",(0,r.jsx)(l.U,{children:"BJSON"}),", ",(0,r.jsx)(l.U,{children:"UBJSON"}),", ",(0,r.jsx)(l.U,{children:"BISON"})," et ",(0,r.jsx)(l.U,{children:"Smile"}),". Le souci de ces formats c'est qu'ils sont assez peu compacts parce qu'ils embarquent le nom des champs r\xe9p\xe9t\xe9 \xe0 chaque entr\xe9e de donn\xe9e."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Apache Thrift"}),", d\xe9velopp\xe9 par Facebook, et ",(0,r.jsx)(l.U,{children:"Protocol Buffers"})," (ou ",(0,r.jsx)(l.U,{children:"protobuf"}),"), d\xe9velopp\xe9 par Google sont deux formats binaires apparus en open source en 2007/2008. Leur particularit\xe9 est qu'ils ont besoin d'un sch\xe9ma, et qu'ils ne r\xe9p\xe8tent pas le nom des champs pour gagner de la place. Ils ont tous les deux des adaptations dans la plupart des langages pour s\xe9rialiser / d\xe9s\xe9rialiser des donn\xe9es dans ce format \xe0 partir des structures du langage.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["A propos des formats :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Concernant Thrift : Il a deux formats diff\xe9rents :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"BinaryProtocol"})," qui remplace le nom des champs par des chiffres faisant r\xe9f\xe9rence aux champs du sch\xe9ma."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"CompactProtocol"})," qui poss\xe8de des optimisations suppl\xe9mentaires pour gagner de la place en encodant le num\xe9ro du champ et le type de champ sur un seul byte, et en utilisant par ex des entiers de longueur variable."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Concernant Protobuf : il est globalement assez similaire au CompactProtocol de Thrift, avec des petites diff\xe9rences dans la mani\xe8re d'encoder les bytes."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos de l'\xe9volution des sch\xe9mas (Protobuf et Thrift) :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ajout de champ : comme les champs sont repr\xe9sent\xe9s par un num\xe9ro report\xe9 dans le sch\xe9ma, on peut facilement ajouter un champ. Ce sera backward-compatible puisque le nouveau code pourra toujours lire les donn\xe9es qui n'ont pas les nouveaux champs, et ce sera forward-compatible parce que l'ancien code pourra juste ignorer les champs ayant un num\xe9ro qu'il ne conna\xeet pas.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On ne peut juste pas ajouter une donn\xe9e obligatoire apr\xe8s une donn\xe9e optionnelle, parce que le nouveau code ne pourrait plus lire les donn\xe9es anciennes qui n'auraient pas ce champ obligatoire."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Suppression de champ : c'est possible \xe0 condition qu'ils soient optionnels (les obligatoires ne pourront jamais \xeatre enlev\xe9s)."}),"\n",(0,r.jsxs)(n.li,{children:["Modification de type de donn\xe9es : c'est parfois possible, mais il y a parfois le d\xe9savantage que notre donn\xe9e peut \xeatre tronqu\xe9e par le code ancien qui ne lit pas toute la longueur prise par la donn\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Protobuf ne poss\xe8de pas de tableaux mais demande \xe0 ajouter un m\xeame champ plusieurs fois si on le veut dans un tableau. Cela permet de pouvoir transformer un champ unique en tableau du m\xeame type et inversement.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Thrift ne fournit pas cette flexibilit\xe9 de transformation puisqu'il a un type pour le tableau, mais il supporte les tableaux imbriqu\xe9s."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Apache Avro"})," a \xe9t\xe9 d\xe9velopp\xe9 en 2009 pour ",(0,r.jsx)(l.U,{children:"Hadoop"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il est similaire \xe0 Thrift et Protobuf, et a deux sch\xe9mas : un (",(0,r.jsx)(n.strong,{children:"Avro VDL"}),") lisible par les humains, et un autre plus pratique pour les machines."]}),"\n",(0,r.jsx)(n.li,{children:"Pour aller chercher un format encore plus compact, Avro ne mentionne pas de num\xe9ros pour les champs, il les met simplement les uns \xe0 la suite des autres dans le bon ordre, avec juste leur type et le contenu."}),"\n",(0,r.jsxs)(n.li,{children:["Le support de l'\xe9volution du sch\xe9ma dans Avro se fait en consid\xe9rant que la machine qui a \xe9crit la donn\xe9e a son sch\xe9ma, et la machine qui lit a le sien. A partir de ces 2 sch\xe9mas, et \xe0 condition qu'ils soient compatibles, Avro calcule exactement la conversion n\xe9cessaire pour que les donn\xe9es lues soient correctement interpr\xe9t\xe9es.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Tous les champs ",(0,r.jsx)(n.strong,{children:"avec une valeur par d\xe9faut"})," dans le sch\xe9ma peuvent \xeatre ajout\xe9s, supprim\xe9s ou chang\xe9s d'ordre d'apparition."]}),"\n",(0,r.jsx)(n.li,{children:"On peut modifier les types de champs, avec les m\xeames probl\xe9matiques que pour Protobuf et Thrift."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'information du sch\xe9ma de celui qui a \xe9crit la donn\xe9e \xe9tant centrale dans l'encodage / d\xe9codage, elle doit \xeatre fournie avec la donn\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour un grand fichier contenant plein de donn\xe9es, on met le sch\xe9ma au d\xe9but du fichier et il concerne toutes les donn\xe9es."}),"\n",(0,r.jsxs)(n.li,{children:["Pour une base de donn\xe9es qui a potentiellement des donn\xe9es avec des sch\xe9mas diff\xe9rents, on peut ajouter un nombre faisant r\xe9f\xe9rence au sch\xe9ma \xe0 chaque entr\xe9e de donn\xe9e, et avoir une table avec tous les sch\xe9mas. C'est ce que fait ",(0,r.jsx)(l.U,{children:"Espresso"})," (la base de donn\xe9es de document de Linkedin, qui utilise Avro)"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour une connexion par r\xe9seau, les deux entit\xe9s connect\xe9es peuvent se communiquer le sch\xe9ma au d\xe9but de la connexion et le garder tout au long de celle-ci. C'est ce qui se fait pour le ",(0,r.jsx)(l.U,{children:"Avro RPC"})," protocol."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Un de principaux avantages d'Avro sur Thrift et Protobuf est que comme le num\xe9ro des champs n'est pas dans les donn\xe9es, on peut facilement g\xe9n\xe9rer des donn\xe9es organis\xe9es dans n'importe quel ordre, ou avec des champs en plus etc. les mettre au format Avro avec un sch\xe9ma associ\xe9, et ils pourront \xeatre lus sans probl\xe8mes. Avro a \xe9t\xe9 con\xe7u pour g\xe9rer des donn\xe9es g\xe9n\xe9r\xe9es dynamiquement, ce qui n'est pas le cas de Thrift et Protobuf."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Il est int\xe9ressant de noter que les donn\xe9es associ\xe9es \xe0 des sch\xe9mas sont pratiques \xe0 bien des \xe9gards, que ce soit pour la flexibilit\xe9, le faible espace occup\xe9, la documentation vivante que \xe7a fournit. Et ces donn\xe9es se couplent bien avec les bases de donn\xe9es “schemaless” (les non relationnelles principalement donc) qui permettent de g\xe9rer les sch\xe9mas au niveau de l'application."}),"\n",(0,r.jsxs)(n.li,{children:["Quand on passe les donn\xe9es d'un processus \xe0 un autre il faut s'assurer que la donn\xe9e est bien comprise malgr\xe9 les versions des programmes tournant sur ces processus. Il y a 3 mani\xe8res de passer les donn\xe9es encod\xe9es d'un processus \xe0 un autre :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["1- Dataflow through databases","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dans le cas des bases de donn\xe9es, le processus qui \xe9crit encode la donn\xe9e, et le processus qui lit la d\xe9code. Ces processus peuvent embarquer des versions diff\xe9rentes du code, et donc il faut une backward compatibility pour pouvoir lire les donn\xe9es avec l'ancien sch\xe9ma, et \xe9ventuellement une forward compatibility dans le cas o\xf9 un noeud avec le nouveau code aurait \xe9crit des donn\xe9es, et que ces donn\xe9es doivent \xeatre lues avec un noeud dont le code est ancien."}),"\n",(0,r.jsx)(n.li,{children:"Il y a aussi une autre chose \xe0 laquelle il faut penser dans le code applicatif : pour le cas de la forward compatibility, si un vieux code traite des donn\xe9es poss\xe9dant de nouveaux champs, il pourra ignorer ceux-ci, mais il faut absolument qu'il pense \xe0 les garder s'il veut mettre \xe0 jour ces donn\xe9es, sinon elles pourraient \xeatre supprim\xe9es sans le vouloir."}),"\n",(0,r.jsx)(n.li,{children:"Contrairement au code qui finit par \xeatre charg\xe9 \xe0 la version la plus r\xe9cente sur tous les nœuds, la base de donn\xe9es a en g\xe9n\xe9ral diverses versions des donn\xe9es, certaines de plusieurs ann\xe9es. Dans la mesure du possible on ne remplit pas le contenu des nouveaux champs dans les anciennes entr\xe9es, mais on met juste null dedans. Le format Avro fournit une bonne mani\xe8re de travailler avec des donn\xe9es nouvelles et anciennes de mani\xe8re transparente."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["2- Dataflow through services","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La communication par r\xe9seau se fait souvent avec une architecture client / serveur. Par exemple, le navigateur est client et le serveur fournit une API sur laquelle le navigateur va faire des demandes.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On a le m\xeame principe c\xf4t\xe9 serveur avec l'",(0,r.jsx)(n.strong,{children:"architecture orient\xe9e services (SOA)"})," (contrairement au nom SOAP n'est pas sp\xe9cifiquement li\xe9 \xe0 SOA) ou plus r\xe9cemment avec quelques changements ce qu'on appelle l'",(0,r.jsx)(n.strong,{children:"architecture microservices"}),". Il s'agit d'avoir des entit\xe9s ind\xe9pendantes qui communiquent entre-elles via messages, et qui peuvent \xeatre mises \xe0 jour de mani\xe8re ind\xe9pendante, tout en communiquant avec le m\xeame format de donn\xe9es qui assure leur compatibilit\xe9."]}),"\n",(0,r.jsxs)(n.li,{children:["Quand des services utilisent le protocole HTTP, on appelle \xe7a des ",(0,r.jsx)(n.strong,{children:"web services"}),". On peut les trouver entre les utilisateurs et les organisations, entre deux services d'une m\xeame organisation, ou entre deux organisations avec par exemple les syst\xe8mes de carte de cr\xe9dit ou le protocole OAuth pour l'authentification."]}),"\n",(0,r.jsxs)(n.li,{children:["Il y a 2 approches populaires pour les web services : REST et SOAP (et GraphQL qui a \xe9t\xe9 open sourc\xe9 en 2015 et ne figure donc pas dans le livre ?).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"REST"})," : principes de design g\xe9n\xe9raux utilisant \xe0 fond les fonctionnalit\xe9s du protocole HTTP et collant \xe0 son fonctionnement (par exemple pour le contr\xf4le du cache, pour le fait d'identifier les ressources avec des URLs).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"OpenAPI (Swagger) permet de documenter convenablement les API REST."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"SOAP"})," : protocole bas\xe9 sur XML appel\xe9 Web Service Description Language (WSDL). SOAP se base beaucoup sur la g\xe9n\xe9ration de code et les outils. Les messages sont en eux-m\xeames difficiles \xe0 lire par un \xeatre humain. Malgr\xe9 les efforts ostentatoires, l'interop\xe9rabilit\xe9 n'est pas tr\xe8s bonne entre les diverses impl\xe9mentations de SOAP. SOAP est surtout utilis\xe9 dans les grandes entreprises parce qu'il est plus ancien."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["En plus des web services, il y a un autre groupe de protocoles de communication \xe0 travers le r\xe9seau appel\xe9 ",(0,r.jsx)(n.strong,{children:"Remote Procedure Call (RPC)"}),". Il s'agit en RPC d'appeler des m\xe9thodes sur des objets, et d'attendre une r\xe9ponse de ces appels.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il y a d'anciens protocoles sp\xe9cifiques \xe0 un langage ou super complexes comme EJB (Java), DCOM (Microsoft), COBRA (trop complexe et non backward compatible). Mais il y a aussi de nouveau protocoles comme ",(0,r.jsx)(l.U,{children:"gRPC"})," utilisant Protobuf, ",(0,r.jsx)(l.U,{children:"Finagle"})," qui utilise Thrift, ",(0,r.jsx)(l.U,{children:"Rest.li"})," qui utilise JSON sur HTTP, et Avro et Thrift qui ont leur propres impl\xe9mentations de RPC."]}),"\n",(0,r.jsxs)(n.li,{children:["Les protocoles RPC essayent de faire passer les appels r\xe9seau pour des appels \xe0 des m\xe9thodes, mais ces choses sont de nature compl\xe8tement diff\xe9rente : un appel r\xe9seau est impr\xe9dictible, il peut prendre un temps variable, il peut finir en timeout, il peut r\xe9ussir tout en n'envoyant pas de r\xe9ponse, il ne peut pas stocker de valeurs en m\xe9moire li\xe9s par des pointeurs etc. REST quant \xe0 lui assume que les appels r\xe9seau sont de nature bien diff\xe9rente en les pr\xe9sentant comme tels.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ceci est \xe0 temp\xe9rer un peu avec les impl\xe9mentations r\xe9centes de RPC qui sont plus explicites sur la nature diff\xe9rente en fournissant par exemple des promesses pour encapsuler les appels asynchrones."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Bien que les protocoles RPC avec un encodage binaire permettent une plus grande performance que du JSON par dessus REST, REST b\xe9n\xe9ficie d'un d\xe9buggage plus facile avec la possibilit\xe9 de tester \xe0 travers les navigateurs, il est support\xe9 partout, et il est compatible avec un large panel d'outils construits autour (serveurs, caches, proxies etc.). Pour toutes ces raisons, le RPC est utilis\xe9 seulement au sein d'une m\xeame organisation, typiquement dans un m\xeame datacenter."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["3- Message-passing dataflow","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il existe une mani\xe8re de transmettre des donn\xe9es entre 2 processus qui se situe entre les appels RPC et les messages pass\xe9s par une base de donn\xe9es : il s'agit de la ",(0,r.jsx)(n.strong,{children:"transmission de messages asynchrone"}),". On ne passe pas par le r\xe9seau mais par un ",(0,r.jsx)(n.strong,{children:"message broker"})," (ou ",(0,r.jsx)(n.strong,{children:"message queue"}),").","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les avantages de cette approche compar\xe9 \xe0 RPC sont :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le broker peut faire buffer le temps que le(s) consommateur soit disponible."}),"\n",(0,r.jsx)(n.li,{children:"Le message peut \xeatre red\xe9livr\xe9 en cas d'\xe9chec ou de crash."}),"\n",(0,r.jsx)(n.li,{children:"Celui qui envoie et qui re\xe7oit ne se connaissent pas, il y a un d\xe9couplage \xe0 ce niveau."}),"\n",(0,r.jsx)(n.li,{children:"Il peut y avoir plusieurs consommateurs d'une m\xeame queue."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Un des inconv\xe9nients potentiels c'est que le receveur n'est pas cens\xe9 r\xe9pondre. L'envoyeur envoie puis oublie."}),"\n",(0,r.jsxs)(n.li,{children:["Les message brokers sont historiquement des logiciels propri\xe9taires comme ",(0,r.jsx)(l.U,{children:"TIBCO"}),", ",(0,r.jsx)(l.U,{children:"IBM WebSphere"}),", et ",(0,r.jsx)(l.U,{children:"webMethods"}),". Plus r\xe9cemment on a des brokers open source comme ",(0,r.jsx)(l.U,{children:"RabbitMQ"}),", ",(0,r.jsx)(l.U,{children:"ActiveMQ"}),", ",(0,r.jsx)(l.U,{children:"HornetQ"}),", ",(0,r.jsx)(l.U,{children:"NATS"})," et ",(0,r.jsx)(l.U,{children:"Apache Kafka"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Les message brokers n'imposent en g\xe9n\xe9ral pas de format de donn\xe9es, donc on peut tr\xe8s bien utiliser les formats Avro / Thrive / Protobuf, et profiter de leur flexibilit\xe9 pour pouvoir d\xe9ployer ind\xe9pendamment les producteurs et consommateurs."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'",(0,r.jsx)(n.strong,{children:"actor model"})," consiste \xe0 se d\xe9barrasser de la probl\xe9matique de concurrence avec la gestion de threads et de ressources partag\xe9es en cr\xe9ant des actors ind\xe9pendants, ayant chacun leurs \xe9tats encapsul\xe9s, et communiquant avec les autres actors via messages asynchrones.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Dans la version distribu\xe9e, ces interlocuteurs peuvent alors \xeatre sur le m\xeame nœud ou sur un nœud diff\xe9rent, auquel cas le message sera s\xe9rialis\xe9 pour \xeatre transmis via le r\xe9seau de mani\xe8re transparente.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il y a une plus grande transparence vis-\xe0-vis du fait que les messages peuvent \xeatre perdus qu'avec RPC."}),"\n",(0,r.jsxs)(n.li,{children:["Un framework actor distribu\xe9 inclut un broker pour transmettre les messages. Il y en a 3 qui sont populaires :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Akka"})," qui utilise la s\xe9rialisation de Java, mais peut \xeatre utilis\xe9 avec par exemple Protobuf pour permettre une meilleure backward/forward compatibilit\xe9."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Orleans"})," supporte les rolling upgrades avec son propre syst\xe8me de versionning."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Erlang OTP"})," supporte les rolling upgrades mais il faut les planifier avec attention."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"5---replication",children:"5 - Replication"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il y a 3 raisons pour vouloir faire de la r\xe9plication :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Garder une copie des donn\xe9es proche des utilisateurs et donc avoir une faible latence."}),"\n",(0,r.jsx)(n.li,{children:"Permettre au syst\xe8me de fonctionner m\xeame si certains composants sont foutus."}),"\n",(0,r.jsx)(n.li,{children:"Pour scaler le nombre de machines et donc le nombre de requ\xeates qu'on peut traiter."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Tout l'enjeu de la r\xe9plication r\xe9side dans le fait de propager les changements dans tous les r\xe9plicats. Il y a 3 algorithmes pour ce faire : ",(0,r.jsx)(n.strong,{children:"single-leader"}),", ",(0,r.jsx)(n.strong,{children:"multi-leader"}),", et ",(0,r.jsx)(n.strong,{children:"leaderless"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"La r\xe9plication des BDD distribu\xe9es a \xe9t\xe9 \xe9tudi\xe9e depuis les ann\xe9es 70 et n'a pas chang\xe9 depuis parce que la nature des r\xe9seaux n'a pas chang\xe9. En revanche, l'utilisation industrielle de ces techniques est quant \xe0 elle r\xe9cente."}),"\n",(0,r.jsxs)(n.li,{children:["La r\xe9plication la plus \xe9vidente est la ",(0,r.jsx)(n.strong,{children:"leader-based replication"}),". Pour \xe9crire une donn\xe9e il faut le faire aupr\xe8s du nœud leader, qui va mettre \xe0 jour sa copie de la BDD et envoyer un log (ou stream) de mise \xe0 jour \xe0 tous les nœuds suiveurs qui vont l'appliquer.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ce type de r\xe9plication est int\xe9gr\xe9 au sein :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["des BDD relationnelles suivantes : ",(0,r.jsx)(l.U,{children:"PostgreSQL"}),", ",(0,r.jsx)(l.U,{children:"MySQL"}),", ",(0,r.jsx)(l.U,{children:"Oracle Data Guard"}),", ",(0,r.jsx)(l.U,{children:"SQL Server's AlwaysOn Availability Groups"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["des BDD non relationnelles suivantes : ",(0,r.jsx)(l.U,{children:"MongoDB"}),", ",(0,r.jsx)(l.U,{children:"RethinkDB"}),", ",(0,r.jsx)(l.U,{children:"Espresso"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Et m\xeame au sein de message brokers distribu\xe9s comme : ",(0,r.jsx)(l.U,{children:"Kafka"})," et ",(0,r.jsx)(l.U,{children:"RabbitMQ"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La r\xe9plication peut \xeatre ",(0,r.jsx)(n.strong,{children:"synchrone"})," ou ",(0,r.jsx)(n.strong,{children:"asynchrone"}),". Si elle est synchrone, alors le nœud leader doit attendre que tous les suiveurs aient r\xe9pondu “ok” de leur c\xf4t\xe9 pour r\xe9pondre \xe0 son tour que la transaction s'est bien pass\xe9e. Si elle est asynchrone, il r\xe9pond tout de suite m\xeame s' il y a eu un probl\xe8me du c\xf4t\xe9 des followers.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dans la pratique on choisit rarement le mode synchrone parce que n'importe lequel des nœuds pourrait mettre plusieurs minutes \xe0 r\xe9pondre \xe0 cause de probl\xe8mes r\xe9seau."}),"\n",(0,r.jsxs)(n.li,{children:["On choisit parfois une r\xe9plication ",(0,r.jsx)(n.strong,{children:"semi-synchrone"}),", qui consiste \xe0 avoir un seul nœud suiveur synchrone, et le reste asynchrones. De cette mani\xe8re on est assur\xe9s d'avoir les donn\xe9es \xe0 jour sur au moins 2 nœuds. Et si le nœud suiveur synchrone ne r\xe9pond plus, on promeut un autre nœud suiveur comme synchrone pour le remplacer."]}),"\n",(0,r.jsx)(n.li,{children:"La r\xe9plication asynchrone est \xe9galement souvent choisie, surtout si les suiveurs sont nombreux ou distribu\xe9s g\xe9ographiquement."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"L'ajout d'un noeud suiveur suppl\xe9mentaire se fait en faisant un snapshot de la base de donn\xe9es du noeud leader, en copiant \xe7a sur le nouveau noeud, puis en demandant au leader tous les logs de mise \xe0 jour (toutes les transactions) qui ont eu lieu depuis le snapshot. Le nouveau nœud peut alors rattraper son retard et devenir un nœud suiveur normal."}),"\n",(0,r.jsxs)(n.li,{children:["En cas d'\xe9chec :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["d'un nœud suiveur : le nœud sait \xe0 quel log il s'est arr\xeat\xe9, donc d\xe8s qu'il va mieux, il peut demander au nœud leader l'ensemble des transactions qu'il a rat\xe9es, et se remettre \xe0 jour. \xc7a s'appelle le ",(0,r.jsx)(n.strong,{children:"catch-up recovery"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["d'un nœud leader : c'est plus compliqu\xe9 \xe0 g\xe9rer. Il faut un timeout pour d\xe9terminer qu'un nœud leader est en \xe9chec, et pass\xe9 ce timeout on entame un processus de ",(0,r.jsx)(n.strong,{children:"failover"})," c'est-\xe0-dire de remplacement du leader.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La proc\xe9dure peut \xeatre automatique ou manuelle. Un timeout trop long peut mener \xe0 une interruption du service trop longue, et un timeout trop court dans un contexte de surcharge peut mener \xe0 g\xe9rer encore moins bien la charge. Pour cette raison, certaines organisations pr\xe9f\xe8rent la m\xe9thode manuelle."}),"\n",(0,r.jsx)(n.li,{children:"Le choix du nouveau leader est un probl\xe8me de consensus, discut\xe9 plus tard dans le livre. A priori le nœud le plus \xe0 jour serait le meilleur choix."}),"\n",(0,r.jsx)(n.li,{children:"Il est possible que l'ancien leader revienne et pense qu'il est toujours le leader en acceptant les op\xe9rations en \xe9criture. C'est une situation dangereuse qu'il faut pr\xe9voir correctement."}),"\n",(0,r.jsxs)(n.li,{children:["Dans le cas de r\xe9plication asynchrone, certaines transactions peuvent ne pas avoir \xe9t\xe9 pass\xe9es aux suiveurs. Si l'ancien leader revient en tant que suiveur ensuite, que faire de ces transactions ? En g\xe9n\xe9ral on les supprime, mais c'est pas trop trop.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Et \xe7a peut \xeatre m\xeame probl\xe9matique si les transactions sont en lien avec d'autres outils. Par exemple chez Github, un suiveur asynchrone MySQL \xe9tait devenu leader avec des transactions manquantes. Il se trouve que la cl\xe9 primaire \xe9tait aussi utilis\xe9e dans un cache Redis qui lui avait les nouvelles transactions. Comme les nouvelles entr\xe9es ont \xe9t\xe9 assign\xe9es \xe0 des valeurs de la cl\xe9 primaire qui avaient exist\xe9 auparavant, des utilisateurs ont pu avoir acc\xe8s \xe0 des cl\xe9s priv\xe9es d'autres utilisateurs, issus du cache."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Fonctionnement de la r\xe9plication au niveau des messages (logs) :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Statement-based replication"})," : il s'agit de faire suivre toutes les instructions de base de donn\xe9es aux suiveurs. Par exemple un INSERT, un UPDATE, un DELETE etc.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dans le cas d'instructions non d\xe9terministes comme RAND(), on va se retrouver avec des valeurs diff\xe9rentes dans les suiveurs."}),"\n",(0,r.jsx)(n.li,{children:"Pour les champs auto-incr\xe9ment\xe9s, il faut absolument que l'ordre des requ\xeates soit exactement le m\xeame, ce qui limite les transactions concurrentes."}),"\n",(0,r.jsxs)(n.li,{children:["Il est possible de travailler \xe0 rendre d\xe9terministe toutes les instructions qui pourraient poser probl\xe8me, en envoyant une valeur plut\xf4t qu'une instruction dans ces cas-l\xe0, mais il y a plein d'edge cases \xe0 traiter.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["En g\xe9n\xe9ral cette approche n'est pas tr\xe8s utilis\xe9e pour cette raison-l\xe0. ",(0,r.jsx)(l.U,{children:"MySQL"})," l'utilisait jusqu'\xe0 une certaine version, mais utilise l'approche row-based replication depuis. ",(0,r.jsx)(l.U,{children:"VoltDB"})," utilise en revanche cette approche."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Write-ahead log (WAL) shipping"})," : il s'agit d'envoyer aux suiveurs le log des messages bas niveau (tel qu'il est utilis\xe9 par les BDD LSM-Tree, ou tel qu'il est utilis\xe9 par les B-Tree le temps que l'op\xe9ration se fasse, et pour pouvoir la refaire \xe0 partir de ce log en cas d'\xe9chec).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'avantage c'est que c'est d\xe9terministe, mais l'inconv\xe9nient c'est que les messages sont coupl\xe9s \xe0 une impl\xe9mentation bas niveau de la BDD. Ce qui veut dire qu'on ne peut pas faire tourner une version diff\xe9rente entre le leader et les followers. Et donc exit les zero-downtime rolling updates : il faut une p\xe9riode de downtime."}),"\n",(0,r.jsxs)(n.li,{children:["Ce m\xe9canisme est utilis\xe9 par ",(0,r.jsx)(l.U,{children:"PostgreSQL"})," et ",(0,r.jsx)(l.U,{children:"Oracle"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Logical (row-based) log replication"})," : il s'agit de faire un peu la m\xeame chose qu'avec le WAL, mais on utilise un format de log ind\xe9pendant de la BDD, avec les fonctionnalit\xe9s minimales pour pouvoir mettre \xe0 jour correctement la BDD.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On est donc d\xe9coupl\xe9 du format bas niveau utilis\xe9 par la BDD, et on peut faire du zero-downtime."}),"\n",(0,r.jsx)(n.li,{children:"\xc7a permet aussi d'envoyer les logs \xe0 une autre base de donn\xe9es de type data warehouse en temps r\xe9el."}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"MySQL binlog"})," peut \xeatre configur\xe9 pour utiliser ce m\xe9canisme."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Trigger-based replication"})," : dans le cas o\xf9 on recherche plus de flexibilit\xe9, plut\xf4t que d'utiliser les m\xe9canismes built-in des BDD, on peut bouger la logique de r\xe9plication au niveau applicatif.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Oracle GoldenGate"})," permet de mettre \xe0 disposition les logs de la BDD pour le code applicatif et impl\xe9menter ce m\xe9canisme."]}),"\n",(0,r.jsxs)(n.li,{children:["Un autre moyen de l'impl\xe9menter est d'utiliser les ",(0,r.jsx)(n.strong,{children:"triggers"})," et ",(0,r.jsx)(n.strong,{children:"stored procedures"})," qui existent dans la plupart des BDD relationnelles. On peut gr\xe2ce \xe0 \xe7a ex\xe9cuter du code applicatif \xe0 chaque transaction. Le r\xe9sultat est plac\xe9 dans une table \xe0 part et lu par un processus \xe0 part.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Databus for Oracle"})," et ",(0,r.jsx)(l.U,{children:"Bucardo for Postgres"})," font \xe7a par exemple."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Ce m\xe9canisme arrive avec son lot de bugs, et est moins performant. Mais il offre de la flexibilit\xe9."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Dans le cas o\xf9 on choisit la leader-based replication avec des followers asynchrones parce qu'on cherche \xe0 scaler en lecture en ayant plein de followers, les followers vont se retrouver r\xe9guli\xe8rement en retard. En g\xe9n\xe9ral c'est une fraction de seconde, mais dans la mont\xe9e en charge ou avec des probl\xe8mes de r\xe9seau \xe7a peut devenir des minutes. Ce retard s'appelle le ",(0,r.jsx)(n.strong,{children:"replication lag"}),". Et on parle d'",(0,r.jsx)(n.strong,{children:"eventual consistency"})," pour d\xe9signer ce probl\xe8me de consistance momentan\xe9 des donn\xe9es."]}),"\n",(0,r.jsxs)(n.li,{children:["Parmi les probl\xe8mes survenant il y a :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"read-after-write consistency :"})," le fait, pour un utilisateur, de pouvoir lire ses propres writes juste apr\xe8s : s'il \xe9crit un message et recharge la page, et qu'il ne voit pas son message, il pourrait se mettre \xe0 paniquer.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut lire toute donn\xe9e qui a potentiellement \xe9t\xe9 modifi\xe9e par l'utilisateur depuis le leader, et les autres depuis les suiveurs. Par exemple, le profil d'un utilisateur ne peut \xeatre modifi\xe9 que par lui, donc on le lit depuis le leader."}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas o\xf9 la plupart des donn\xe9es sont potentiellement modifiables par l'utilisateur, on perdrait l'int\xe9r\xeat du scaling \xe0 tout lire depuis le leader. On peut alors par exemple ne lire depuis le leader que les donn\xe9es qui ont \xe9t\xe9 modifi\xe9es dans les derni\xe8res minutes, ou encore monitorer le replication lag pour ne pas lire depuis les suiveurs qui sont trop en retard."}),"\n",(0,r.jsx)(n.li,{children:"Le client peut retenir le timestamp (temps ou donn\xe9e d'ordre logique) de la derni\xe8re \xe9criture, et l'envoyer avec la requ\xeate. Le serveur peut alors n'utiliser que les suiveurs qui sont \xe0 jour jusqu'\xe0 ce timestamp, ou attendre qu'ils le soient avant de r\xe9pondre."}),"\n",(0,r.jsx)(n.li,{children:"Difficult\xe9 suppl\xe9mentaire dans le cas de dispersion g\xe9ographique : toute requ\xeate envoy\xe9e au leader ne sera pas forc\xe9ment proche de l'utilisateur."}),"\n",(0,r.jsxs)(n.li,{children:["Autre probl\xe9matique : si on veut que l'utilisateur puisse voir ses \xe9critures depuis tous ses outils (navigateur, mobile etc.).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\xc7a rend inop\xe9rant la technique de se souvenir de la derni\xe8re modification c\xf4t\xe9 client puisqu'il y a alors plusieurs clients."}),"\n",(0,r.jsx)(n.li,{children:"On a aussi des probl\xe8mes suppl\xe9mentaires dans le cas o\xf9 il y a plusieurs datacenters. Les deux appareils pourraient \xeatre dirig\xe9s vers des datacenters diff\xe9rents."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"monotonic reads"})," : un utilisateur pourrait obtenir des donn\xe9es r\xe9centes depuis un replica \xe0 jour, puis recharger la page et obtenir des donn\xe9es anciennes depuis un replica moins \xe0 jour. \xc7a donne l'impression d'aller dans le pass\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour \xe9viter ce ph\xe9nom\xe8ne on peut servir un m\xeame utilisateur toujours avec le m\xeame nœud suiveur tant que celui-ci est vivant."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Consistent prefix reads"})," : il s'agit ici de respecter l'ordre causal des choses. Il faut que les donn\xe9es \xe9crites en BDD le soient toujours dans le bon ordre. C'est un probl\xe8me qui survient quand on partitionne la BDD (on en parlera au chapitre suivant).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut alors essayer de mettre les informations li\xe9es entre-elles dans la m\xeame partition."}),"\n",(0,r.jsx)(n.li,{children:"On peut aussi utiliser des algorithmes qui emp\xeachent les donn\xe9es d'\xeatre dans un ordre non causal."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Concernant le replication lag et l'eventual consistency qui en r\xe9sulte, une des solutions pour y r\xe9pondre s'appelle ",(0,r.jsx)(n.strong,{children:"les transactions"}),". Leur but est d'abstraire tout l'aspect distribu\xe9 du code applicatif, et de s'occuper de r\xe9pondre aux probl\xe8mes d\xe9crits ici (read-after etc.). Certaines personnes disent d'abandonner les transactions qui seraient trop co\xfbteuses, mais on nuancera \xe7a par la suite."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On a ensuite la ",(0,r.jsx)(n.strong,{children:"multi-leader replication"}),". On a plusieurs leaders qui mettent \xe0 jour des suiveurs, et qui se mettent aussi \xe0 jour entre eux.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"En g\xe9n\xe9ral la complexit\xe9 suppl\xe9mentaire induite par le fait d'avoir plusieurs leaders n'en vaut pas la peine si on n'a qu'un seul datacenter."}),"\n",(0,r.jsxs)(n.li,{children:["Les avantages du multi-leader dans un environnement multi datacenter :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut par exemple avoir un leader par datacenter, ce qui permet d'\xe9viter de traverser la terre pour faire des requ\xeates d'\xe9criture, donnant une perception de performance aux utilisateurs."}),"\n",(0,r.jsx)(n.li,{children:"Un datacenter entier et son leader peut avoir un probl\xe8me, puis rattraper son retard sur les autres datacenters d\xe8s que c'est bon."}),"\n",(0,r.jsx)(n.li,{children:"Les erreurs r\xe9seau hors du datacenter impactent moins ce qui se passe dans le datacenter, \xe9tant donn\xe9 qu'on n'est pas oblig\xe9 d'aller chercher un nœud leader d'un autre datacenter pour \xe9crire."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Certaines BDD supportent le multi-leader nativement, mais en g\xe9n\xe9ral il faut un outil externe. C'est le cas pour ",(0,r.jsx)(l.U,{children:"Tungsten Replicator"})," pour ",(0,r.jsx)(l.U,{children:"MySQL"}),", ",(0,r.jsx)(l.U,{children:"BDR"})," pour ",(0,r.jsx)(l.U,{children:"PostgreSQL"})," et ",(0,r.jsx)(l.U,{children:"GoldenGate"})," pour ",(0,r.jsx)(l.U,{children:"Oracle"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il y a \xe9galement ",(0,r.jsx)(l.U,{children:"CouchDB"})," qui a \xe9t\xe9 con\xe7u pour permettre de r\xe9soudre facilement les situations de multi-leader."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Ces deux exemples illustrent le m\xeame principe que la r\xe9plication multi-leader :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Une application de calendrier pour mobile, desktop etc. pourrait fonctionner en maintenant une copie de la BDD dans chaque client, les laissant ajouter des \xe9v\xe9nements m\xeame en \xe9tant hors ligne, et synchroniser les BDD quand les clients sont \xe0 nouveau en ligne. On a bien plusieurs leaders qui peuvent \xe9crire, une possibilit\xe9 d'eventual consistency le temps que le r\xe9seau revienne, et un travail de r\xe9solution des conflits \xe0 faire."}),"\n",(0,r.jsx)(n.li,{children:"Les applications d'\xe9dition collaborative de texte comme Etherpad ou Google Docs fonctionnent comme si plusieurs leaders pouvaient faire des changements sur leur propre version locale, et propager ces changements de mani\xe8re asynchrone. Ca aurait pu \xeatre du single-leader si chaque personne prenait un lock avant de faire un changement (un peu comme dans dropbox), mais l\xe0 chaque changement est ajout\xe9 \xe0 un niveau vraiment atomique au document."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le probl\xe8me principal de la multi-leader replication c'est les conflits entre leaders ayant eu chacun une transaction en \xe9criture sur une m\xeame donn\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On pourrait demander aux leaders d'attendre que l'autre leader ait fini sa transaction avant d'en accepter une, mais alors on reviendrait \xe0 la position de single-leader, on perdrait l'avantage d'avoir plusieurs leaders acceptant des connexions en m\xeame temps."}),"\n",(0,r.jsx)(n.li,{children:"Dans la mesure du possible, vu que la r\xe9solution de conflit est complexe et en g\xe9n\xe9ral mal g\xe9r\xe9e, il vaut mieux \xe9viter les conflits. On peut par exemple rediriger les requ\xeates d'un m\xeame utilisateur toujours vers le m\xeame datacenter."}),"\n",(0,r.jsxs)(n.li,{children:["Parfois un datacenter est hors d'usage, ou un utilisateur peut se d\xe9placer et se rapprocher d'un autre datacenter, et on va vouloir le rediriger vers un autre leader. Il faut alors faire converger le conflit vers un \xe9tat consistent :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut donner un identifiant \xe0 chaque transaction, bas\xe9 sur un timestamp, un nombre al\xe9atoire etc. et se dire que le plus grand nombre gagnera lors du conflit pour faire valider sa transaction, annulant l'autre. Dans le cas du timestamp c'est du ",(0,r.jsx)(n.strong,{children:"last write wins (LWW)"}),". C'est tr\xe8s populaire mais on perd des transactions."]}),"\n",(0,r.jsx)(n.li,{children:"On peut donner un identifiant \xe0 chaque leader, et se dire que celui qui a le plus grand gagne toujours la r\xe9solution de conflit. Mais c'est pareil qu'avec l'identifiant de transaction : on va perdre des donn\xe9es."}),"\n",(0,r.jsxs)(n.li,{children:["On peut choisir une strat\xe9gie de fusion des donn\xe9es des 2 requ\xeates, par exemple ordonner le texte alphab\xe9tiquement et le concat\xe9ner.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Bucardo"})," par exemple permet d'\xe9crire un bout de code en perl pour choisir quoi faire des requ\xeates en conflit d\xe8s que le conflit appara\xeet au moment de l'\xe9criture."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Enregistrer le conflit avec les 2 donn\xe9es quelque part, et laisser le code applicatif g\xe9rer \xe7a par exemple en demandant \xe0 l'utilisateur quoi faire pour ce conflit.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"CouchDB"})," fonctionne de cette mani\xe8re-l\xe0 : il stocke les 2 donn\xe9es, puis \xe0 la lecture les envoie toutes les deux \xe0 l'application.."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Un conflit peut \xeatre de mani\xe8re \xe9vidente la modification d'un m\xeame champ, mais \xe7a peut aussi \xeatre plus subtile et difficile \xe0 d\xe9tecter. Par exemple une v\xe9rification au niveau applicatif qu'une chambre d'h\xf4tel ne peut \xeatre r\xe9serv\xe9e et donc mentionn\xe9e que par une seule r\xe9servation. Si le code applicatif a valid\xe9 la requ\xeate, mais qu'on en l'a faite une dans chaque leader, on va r\xe9server deux fois."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Quand on a 2 leaders, ils vont forc\xe9ment s'envoyer chacun des updates. Mais si on en a plus, alors on peut avoir diverses ",(0,r.jsx)(n.strong,{children:"topologies de propagation"})," des mises \xe0 jour entre leaders :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"star topology"})," consiste \xe0 avoir un leader au centre qui va mettre \xe0 jour tous les autres, et prendre des mises \xe0 jours d'eux."]}),"\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"circular topology"})," consiste \xe0 ce que chaque leader mette \xe0 jour son voisin, et finissant en boucle. Une information au niveau de la requ\xeate permet alors de savoir si elle a d\xe9j\xe0 \xe9t\xe9 trait\xe9e par le nœud courant pour arr\xeater la boucle."]}),"\n",(0,r.jsxs)(n.li,{children:["La plus g\xe9n\xe9rale est le ",(0,r.jsx)(n.strong,{children:"all-to-all topology"}),", o\xf9 tous les leaders mettent \xe0 jour tous les autres.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Un des avantages du all-to-all est que si un nœud ne fonctionne plus, c'est transparent. Pour le circular et star il pourrait bloquer l'information et il faut alors reconfigurer la topologie."}),"\n",(0,r.jsxs)(n.li,{children:["L'inconv\xe9nient des all-to-all est que certaines connexions peuvent \xeatre plus rapides que d'autres, et alors si on se basait sur des timestamp pour l'ordre des transactions par exemple, cet ordre pourrait ne pas \xeatre bon.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour pouvoir faire quand m\xeame respecter la causalit\xe9 dans ce cas, on peut utiliser la technique des ",(0,r.jsx)(n.strong,{children:"version vectors"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Globalement la r\xe9solution de conflits est plut\xf4t mal g\xe9r\xe9e dans les solutions existantes : par exemple ",(0,r.jsx)(l.U,{children:"PostgreSQL BDR"})," ne fournit pas de garantie causale des \xe9critures, et ",(0,r.jsx)(n.strong,{children:"Tungsten Replicator pour MySQL"})," ne d\xe9tecte m\xeame pas les conflits."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On a enfin la ",(0,r.jsx)(n.strong,{children:"leaderless replication"}),", qui consiste \xe0 ce que tous les nœuds puissent accepter les requ\xeates en lecture et \xe9criture.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Cette id\xe9e \xe9tait tomb\xe9e dans l'oubli depuis longtemps et a \xe9t\xe9 remise au go\xfbt du jour quand Amazon l'a impl\xe9ment\xe9e dans sa base de donn\xe9es ",(0,r.jsx)(l.U,{children:"Dynamo system"}),". Elle est depuis utilis\xe9e dans les BDD open source ",(0,r.jsx)(l.U,{children:"Riak"}),", ",(0,r.jsx)(l.U,{children:"Cassandra"})," et ",(0,r.jsx)(l.U,{children:"Voldemort"}),". Elles sont connues pour \xeatre les “BDD Dynamo-style”."]}),"\n",(0,r.jsxs)(n.li,{children:["En cas de probl\xe8me dans un des nœuds, celui-ci va rater des requ\xeates. Et quand il reviendra, ses donn\xe9es seront anciennes et le client risque d'obtenir des donn\xe9es pas \xe0 jour en lisant depuis ce nœud.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour r\xe9soudre le probl\xe8me chez le client, le client peut envoyer la requ\xeate \xe0 tous les nœuds, et \xe0 la r\xe9ception utiliser la version la plus \xe0 jour parmi ceux re\xe7us, gr\xe2ce \xe0 des num\xe9ros de version dans ces messages."}),"\n",(0,r.jsxs)(n.li,{children:["Pour s'assurer que le noeud se remet \xe0 jour il y a 2 moyens impl\xe9ment\xe9s dans les syst\xe8mes Dynamo-style :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Read repair"})," : Quand le client lit une valeur en parall\xe8le depuis tous les r\xe9plicas, s'il constate une diff\xe9rence chez l'un d'entre eux qui aurait une version de transaction plus ancienne, il le met \xe0 jour avec une requ\xeate d'\xe9criture. Ceci permet de mettre \xe0 jour les valeurs souvent lues."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Anti-entropy process"})," : Pour les valeurs peu lues, on peut avoir des t\xe2ches de fond qui tournent, et dont le but est de rep\xe9rer les diff\xe9rences entre nœuds, et mettre \xe0 jour ceux qui sont en retard."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour savoir si une requ\xeate a r\xe9ussi, on peut utiliser le ",(0,r.jsx)(n.strong,{children:"quorum consistency"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Soit :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"n"})," le nombre de nœuds \xe0 qui on envoie les reads et writes."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"w"})," le nombre de nœuds qui doivent confirmer un write pour le consid\xe9rer comme r\xe9ussi."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"r"})," le nombre de nœuds qui doivent confirmer un read pour qu'il soit consid\xe9r\xe9 comme r\xe9ussi."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Alors pour respecter le principe du quorum il faut que ",(0,r.jsx)(n.strong,{children:"w + r > n"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Typiquement on choisit ",(0,r.jsx)(n.em,{children:"n"})," impair, et ",(0,r.jsx)(n.em,{children:"w = r = (n + 1) / 2"})," (arrondi au sup\xe9rieur)."]}),"\n",(0,r.jsxs)(n.li,{children:["Si on a beaucoup de lectures et peu d'\xe9critures, on pourra mettre ",(0,r.jsx)(n.em,{children:"r = 1"}),", comme \xe7a d\xe8s qu'un seul nœud valide la lecture alors la transaction est valid\xe9e. Les lectures sont alors plus rapides mais un seul nœud qui est down emp\xeache alors l'\xe9criture en BDD pour respecter la formule w + r > n)."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Avantages et inconv\xe9nients du quorum :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'int\xe9r\xeat de ce quorum c'est que les reads et writes se chevauchent, et donc qu'il y ait forc\xe9ment au moins un nœud qui soit compl\xe8tement \xe0 jour, pour \xeatre s\xfbr que la donn\xe9e lue qui sera gard\xe9e sera compl\xe8tement \xe0 jour."}),"\n",(0,r.jsx)(n.li,{children:"On peut tr\xe8s bien choisir de ne pas respecter la formule du quorum et avoir moins de reads et writes n\xe9cessaires pour la validation. On aura alors une plus faible latence, une plus grande availability, mais une moins bonne consistance (on aura r\xe9guli\xe8rement des lectures renvoyant des donn\xe9es pas tout \xe0 fait \xe0 jour)."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["M\xeame avec le quorum, on peut se retrouver avec des donn\xe9es pas \xe0 jour dans certains cas :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Si on utilise le ",(0,r.jsx)(n.strong,{children:"sloppy quorum"}),", on peut se retrouver avec les writes sur d'autres nœuds que les reads, et donc le chevauchement n'est plus garanti.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il s'agit d'une option activable sur les BDD qui permet, dans le cas o\xf9 une large partie de noeuds est momentan\xe9ment non disponible, de choisir de prendre quand m\xeame les writes sur d'autres noeuds partitionn\xe9s qui ne font pas habituellement partie de ",(0,r.jsx)(n.em,{children:"n"})," pour ces valeurs-l\xe0. Et quand les nœuds sont de retour, on leur donne ces valeurs (hinted handoff). Le probl\xe8me c'est que pendant le temps o\xf9 ils n'\xe9taient pas l\xe0, ils avaient peut \xeatre certaines valeurs plus \xe0 jours qu'eux seuls avaient, et les reads ont pu \xeatre servis avec des valeurs pas \xe0 jour."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas de writes concurrents, on est en pr\xe9sence d'un conflit qu'il faut r\xe9soudre comme discut\xe9 pr\xe9c\xe9demment. Si on choisit de r\xe9soudre en annulant une des requ\xeates, alors on perd des donn\xe9es."}),"\n",(0,r.jsx)(n.li,{children:"Si un read se fait en concurrence avec un read, le write pourrait \xeatre effectif chez certains replicas, et on ne sait pas ce que retournera alors le read."}),"\n",(0,r.jsx)(n.li,{children:"Si un write a r\xe9ussi sur certains r\xe9plicas mais pas tous, et que la transaction est en voie d'annulation, les r\xe9plicas o\xf9 \xe7a a r\xe9ussi peuvent renvoyer cette valeur qui sera fausse."}),"\n",(0,r.jsx)(n.li,{children:"Si le nœud \xe0 jour \xe9choue, le nombre de nœuds en \xe9criture tombe en dessous de w, et on peut n'avoir aucun nœud qui a la version \xe0 jour par rapport aux \xe9critures d\xe9j\xe0 valid\xe9es au moment de r\xe9pondre."}),"\n",(0,r.jsx)(n.li,{children:"Des probl\xe8mes de timing dont on parlera plus tard peuvent aussi survenir."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"On voit bien que les Dynamo-style databases ne garantissent qu'une eventual consistency, m\xeame en respectant le quorum. Pour avoir des garanties plus fortes comme le “read your writes”, “monotonic reads” etc. il faudra faire appel aux transactions et au consensus."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Malgr\xe9 l'eventual consistency de la leaderless replication, il peut \xeatre important de quantifier \xe0 quel point les donn\xe9es sont peu \xe0 jour dans les divers nœuds. Il faudrait mettre en place du monitoring mais c'est beaucoup moins simple que pour le leader-based o\xf9 on peut facilement observer le replication lag du leader vers les followers. L\xe0 on peut avoir des valeurs peu lues tr\xe8s anciennes."}),"\n",(0,r.jsxs)(n.li,{children:["La leaderless replication est tout \xe0 fait aussi adapt\xe9e au multi-datacenter :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Cassandra"})," et ",(0,r.jsx)(l.U,{children:"Voldemort"})," traitent les nœuds dans les divers datacenters comme des nœuds normaux, avec le n global et un n configurable pour chaque datacenter. En g\xe9n\xe9ral les clients n'attendent que le quorum du datacenter le plus proche pour maximiser le temps de r\xe9ponse."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Riak"})," ne fait du leaderless classique qu'au sein des datacenters, la synchronisation cross-datacenter se fait de mani\xe8re asynchrone, un peu \xe0 la mani\xe8re du multi-leader replication."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos de la gestion des \xe9critures concurrentes :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il faut noter que malheureusement \xe7a ne se fera pas automatiquement par les impl\xe9mentations des BDD qui sont relativement mauvaises. En tant que d\xe9veloppeur, il faut conna\xeetre ces probl\xe8mes et impl\xe9menter des solutions nous-m\xeames."}),"\n",(0,r.jsxs)(n.li,{children:["Voici quelques \xe9l\xe9ments de r\xe9flexion :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Last write wins"})," (LWW) : on en avait parl\xe9, il s'agit d'\xe9liminer une des deux transactions concurrentes en d\xe9terminant par une m\xe9thode arbitraire laquelle est la derni\xe8re dans le cas o\xf9 il n'y a pas de relation de causalit\xe9. C'est arbitraire parce que la causalit\xe9 entre des \xe9v\xe9nements qui ne se connaissent pas n'a pas de sens. C'est \xe7a qu'on appelle des transactions concurrentes.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est probl\xe9matique parce que m\xeame apr\xe8s avoir dit au client que la transaction s'est bien pass\xe9e, elle peut \xeatre annul\xe9e en arri\xe8re-plan de mani\xe8re silencieuse."}),"\n",(0,r.jsxs)(n.li,{children:["LWW est la seule m\xe9thode de r\xe9solution de conflit support\xe9e par ",(0,r.jsx)(l.U,{children:"Cassandra"}),", et une feature optionnelle dans ",(0,r.jsx)(l.U,{children:"Riak"}),". Dans Cassandra il est recommand\xe9 d'utiliser un UUID comme cl\xe9 pour \xe9viter autant que possible des \xe9critures concurrentes."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Ce qu'il nous faut donc c'est pouvoir distinguer deux \xe9v\xe9nements concurrents de deux \xe9v\xe9nements causaux. Dans le cas o\xf9 c'est causal on pourra faire respecter l'ordre. C'est seulement dans le cas de la concurrence qu'on est condamn\xe9 \xe0 perdre des donn\xe9es, fusionner les donn\xe9es ou avertir l'utilisateur.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour fusionner les donn\xe9es, on peut utiliser des structures sp\xe9ciales qui le permettent facilement comme les structures CRDT support\xe9s par ",(0,r.jsx)(l.U,{children:"Riak"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["En interne il s'agit de fusionner les \xe9l\xe9ments dans une liste en cas d'ajout, et de poser des ",(0,r.jsx)(n.strong,{children:"tombstones"})," dans le cas d'une suppression plut\xf4t que de supprimer directement. Cela permet de mieux g\xe9rer la suppression au niveau de plusieurs nœuds qui en prennent connaissance au fur et \xe0 mesure, et ont besoin d'effectuer l'op\xe9ration eux-aussi."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour distinguer les \xe9v\xe9nements causaux des concurrents, on peut utiliser les ",(0,r.jsx)(n.strong,{children:"version vectors"}),". Chaque replica a sa version qu'il incr\xe9mente \xe0 chaque traitement, et l'ensemble de ces versions sont appel\xe9es version vector. Ces valeurs sont utilis\xe9es par chaque r\xe9plica pour d\xe9terminer s'il y a de la causalit\xe9 ou si on garde les deux versions concurrentes.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les version vectors sont disponibles dans ",(0,r.jsx)(l.U,{children:"Riak"})," 2.0, et sont appel\xe9s ",(0,r.jsx)(n.em,{children:"causal context"}),". Le version vector est envoy\xe9 aux clients quand les valeurs sont lues, et renvoy\xe9 par les clients quand une valeur est \xe9crite."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"6---partitioning",children:"6 - Partitioning"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les partitions sont appel\xe9es :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"shard"})," dans ",(0,r.jsx)(l.U,{children:"MongoDB"}),", ",(0,r.jsx)(l.U,{children:"Elasticsearch"})," et ",(0,r.jsx)(l.U,{children:"SolrCloud"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"region"})," dans ",(0,r.jsx)(l.U,{children:"HBase"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tablet"})," dans ",(0,r.jsx)(l.U,{children:"Bigtable"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"vnode"})," dans ",(0,r.jsx)(l.U,{children:"Cassandra"})," et ",(0,r.jsx)(l.U,{children:"Riak"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"vBucket"})," dans ",(0,r.jsx)(l.U,{children:"Couchbase"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Un cluster ",(0,r.jsx)(n.strong,{children:"shared-nothing"})," signifie qu'il s'agit de plusieurs machines distinctes, par opposition au scaling vertical o\xf9 c'est la m\xeame machine qui partage le processeur, la RAM etc. l\xe0 on ne partage rien \xe0 part \xe0 travers le r\xe9seau."]}),"\n",(0,r.jsx)(n.li,{children:"Les partitions existent depuis les ann\xe9es 80, et ont \xe9t\xe9 red\xe9couvertes par les BDD NoSQL et les Data warehouses Hadoop-based."}),"\n",(0,r.jsx)(n.li,{children:"Vis-\xe0-vis de la r\xe9plication, la notion de partition vient s'y superposer. On peut par exemple avoir des nœuds (ordinateurs) avec plusieurs partitions, et chacun d'entre eux peut \xeatre soit leader soit follower pour telle ou telle copie de telle ou telle partition."}),"\n",(0,r.jsxs)(n.li,{children:["La raison principale de vouloir des partitions est la scalabilit\xe9. Avec la r\xe9plication on pouvait scaler pour lectures, mais le partitionnement permet de scaler aussi en \xe9criture.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cependant, pour que le scaling fonctionne bien, il faut que la charge soit \xe9quitablement r\xe9partie entre les nœuds. Pour ce faire, on peut par exemple r\xe9partir al\xe9atoirement les donn\xe9es dans les partitions (mais \xe7a n\xe9cessiterait de demander \xe0 tous les nœuds en parall\xe8le \xe0 chaque recherche)."}),"\n",(0,r.jsxs)(n.li,{children:["Quand la charge est mal r\xe9partie on appelle \xe7a des partitions ",(0,r.jsx)(n.strong,{children:"skewed"})," (biais\xe9es). Et quand un seul nœud se retrouve \xe0 tout g\xe9rer on l'appelle le ",(0,r.jsx)(n.strong,{children:"hot spot"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Parmi les types de partitions on a :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La partition par ",(0,r.jsx)(n.strong,{children:"key range"}),". On va attribuer un range de cl\xe9s \xe0 chaque nœud, et y stocker ces donn\xe9es-l\xe0. Si on conna\xeet ce range \xe0 l'avance, on pourra m\xeame directement demander au nœud concern\xe9 pour notre recherche.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On pourra par exemple avoir le 1er nœud qui a les cl\xe9s commen\xe7ant par A et B, et le dernier les cl\xe9s commen\xe7ant par W, X, Y et Z."}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Bigtable"})," et son \xe9quivalent open source ",(0,r.jsx)(l.U,{children:"HBase"}),", ainsi que ",(0,r.jsx)(l.U,{children:"RethinkDB"})," et ",(0,r.jsx)(l.U,{children:"MongoDB"})," jusqu'\xe0 la version 2.4 utilisent cette technique."]}),"\n",(0,r.jsx)(n.li,{children:"Dans chaque partition, on peut garder les entr\xe9es tri\xe9es de la m\xeame mani\xe8re que les LSM-Tree."}),"\n",(0,r.jsx)(n.li,{children:"On a un risque de hot spot, par exemple dans le cas o\xf9 on recherche par la cl\xe9 qui serait le timestamp, et que les partitions sont group\xe9es par journ\xe9e. La partition du jour courant risque de devenir un hot spot. Dans ce cas on peut pr\xe9fixer la cl\xe9 par un nom ou autre chose, pour constituer un index concat\xe9n\xe9 par exemple."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La partition par ",(0,r.jsx)(n.strong,{children:"hash of key"}),". On a la m\xeame mani\xe8re de stocker par cl\xe9 qu'avant, sauf qu'on va hasher la cl\xe9 avec une fonction de hash simple (mais qui ne donne pas de duplicata). Et on va assigner des ranges de hashs aux partitions. Ceci fait que les donn\xe9es seront al\xe9atoirement r\xe9parties.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"MongoDB"}),", ",(0,r.jsx)(l.U,{children:"Cassandra"})," et ",(0,r.jsx)(l.U,{children:"Voldemort"})," utilisent ce m\xe9canisme."]}),"\n",(0,r.jsxs)(n.li,{children:["Le d\xe9savantage de hasher la cl\xe9 c'est qu'on ne peut plus faire facilement de recherche par range.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Dans ",(0,r.jsx)(l.U,{children:"MongoDB"}),", si on a activ\xe9 les cl\xe9s hash\xe9es, il faut envoyer les queries de range \xe0 toutes les partitions."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Riak"}),", ",(0,r.jsx)(l.U,{children:"Couchbase"})," et ",(0,r.jsx)(l.U,{children:"Voldemort"})," ne supportent pas du tout les queries de range."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Cassandra"})," utilise un compromis entre les deux strat\xe9gies (hash et cl\xe9 normale) : on a une cl\xe9 compos\xe9e avec une premi\xe8re partie hash\xe9e d\xe9terminant la partition, et ensuite une 2\xe8me partie permettant de faire une recherche, y compris de range, dans la SSTable. On doit donc d'abord fixer la partition et ensuite on peut chercher ce qu'on veut efficacement."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Hasher la cl\xe9 peut parfois ne pas suffire \xe0 \xe9liminer les hot spot : dans le cas sp\xe9cifique o\xf9 on a une donn\xe9e qui est acc\xe9d\xe9e / \xe9crite de mani\xe8re massive (par exemple une c\xe9l\xe9brit\xe9 qui est fortement suivie qui s'exprime), il faut diviser cette entr\xe9e-l\xe0 en plusieurs entr\xe9es sur plusieurs machines. On peut par exemple pr\xe9fixer le hash d'un nombre et le r\xe9partir sur 100 machines diff\xe9rentes. Mais alors les lectures devront \xe0 chaque fois faire appel \xe0 toutes ces partitions et reconstruire la bonne donn\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour le moment les BDD ne g\xe8rent pas automatiquement ce genre de fonctionnalit\xe9, donc il faut le faire \xe0 la main."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il existe un concept appel\xe9 ",(0,r.jsx)(n.strong,{children:"consistent hashing"}),", mais il est surtout utilis\xe9 pour les caches distribu\xe9s \xe0 travers le monde (type CDN) pour \xe9viter le besoin d'entit\xe9 centrale, et n'est pas efficace avec les BDD. Certaines docs de BDD l'invoquent par erreur, mais pour \xe9viter la confusion il vaut mieux qu'on parle de ",(0,r.jsx)(n.em,{children:"hash partitioning"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les indexes secondaires sont extr\xeamement pratiques pour faire des recherches dans la BDD, mais elles introduisent une complexit\xe9 suppl\xe9mentaire.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Par rapport \xe0 leur support :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"HBase"})," et ",(0,r.jsx)(l.U,{children:"Voldemort"})," ont \xe9vit\xe9 de les supporter pour \xe9viter la complexit\xe9 de l'impl\xe9mentation."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Riak"})," a commenc\xe9 leur support."]}),"\n",(0,r.jsxs)(n.li,{children:["Pour ",(0,r.jsx)(l.U,{children:"Elasticsearch"})," et ",(0,r.jsx)(l.U,{children:"Solr"}),", ils sont leur raison d'\xeatre."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On a 2 mani\xe8res de les impl\xe9menter avec le partitionnement :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Document-based partitioning"})," : on va cr\xe9er un index local \xe0 la partition. Toutes les entr\xe9es de la partition seront index\xe9es pour la colonne choisie, mais l'index n'aura aucune id\xe9e de ce qui est index\xe9 sur une autre partition.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le probl\xe8me c'est que quand on veut faire une recherche par index secondaire, on va alors devoir faire une requ\xeate aupr\xe8s de toutes les partitions, puisque les partitions sont s\xe9par\xe9es par cl\xe9 primaire, pas par l'index secondaire. On appelle \xe7a le ",(0,r.jsx)(n.em,{children:"scatter / gather"}),". Ceci fait que la requ\xeate va co\xfbter cher, et devoir attendre que tous les nœuds r\xe9pondent (donc on est soumis au probl\xe8me des hauts percentiles qui nous ralentissent potentiellement beaucoup)."]}),"\n",(0,r.jsxs)(n.li,{children:["Cette approche est utilis\xe9e quand m\xeame dans ",(0,r.jsx)(l.U,{children:"MongoDB"}),", ",(0,r.jsx)(l.U,{children:"Riak"}),", ",(0,r.jsx)(l.U,{children:"Cassandra"}),", ",(0,r.jsx)(l.U,{children:"Elasticsearch"}),", ",(0,r.jsx)(l.U,{children:"SolrCloud"})," et ",(0,r.jsx)(l.U,{children:"VoltDB"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Term-based partitioning"})," : on cr\xe9e un index global. Mais bien entendu il est hors de question de le mettre sur un seul nœud, au risque que \xe7a devienne un bottleneck. On va le partitionner de m\xeame qu'on a partitionn\xe9 l'index primaire : les premi\xe8res cl\xe9s de l'index secondaires seront dans la partition 1, celles juste apr\xe8s dans la partition 2 etc.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cette technique rend la recherche rapide : puisqu'on sait quel nœud contient l'index qu'on veut, on lui envoie la requ\xeate directement. Par contre l'\xe9criture est plus lente puisqu'elle va impliquer des modifications dans plusieurs partitions (celle de la donn\xe9e et de l'index primaire, et celle de l'index secondaire pour le mettre \xe0 jour)."}),"\n",(0,r.jsx)(n.li,{children:"En pratique, la mise \xe0 jour de l'index secondaire avec le term-partitioning se fait de mani\xe8re asynchrone, et tant pis si une recherche avec l'index secondaire imm\xe9diatement apr\xe8s une \xe9criture ne fonctionne pas."}),"\n",(0,r.jsxs)(n.li,{children:["Parmi les impl\xe9mentations :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Amazon DynamoDB"})," met \xe0 jour son index term-partitioned de mani\xe8re asynchrone."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Riak"})," et ",(0,r.jsx)(l.U,{children:"Oracle data warehouse"})," permettent de choisir la technique de partitionnement de l'index secondaire."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["R\xe9guli\xe8rement, pour augmenter les capacit\xe9s ou remplacer une machine malade, on doit rediriger les requ\xeates et d\xe9placer les donn\xe9es d'une machine \xe0 l'autre. On appelle \xe7a le ",(0,r.jsx)(n.strong,{children:"rebalancing"})," entre partitions. Il y a plusieurs strat\xe9gies pour l'impl\xe9menter :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Une strat\xe9gie \xe0 ne pas faire : ",(0,r.jsx)(n.strong,{children:"hash mod N"}),". Si on d\xe9cidait de faire le modulo du hash de nos transactions pour les r\xe9partir dans les noeuds (par exemple le hash % 12 si on a 12 noeuds), alors \xe0 chaque fois que le nombre de noeuds changerait, on devrait faire du rebalancing, ce qui est beaucoup trop co\xfbteux."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Fixed number of partitions"}),". On va choisir un grand nombre de partitions, plus grand que le nombre de nœuds qu'on imagine qu'on va avoir, et on va attribuer plusieurs partitions par nœud (par exemple 100 par nœud). De cette mani\xe8re, d\xe8s qu'on ajoute ou supprime un nœud, on peut d\xe9placer quelques partitions ici et l\xe0 pour \xe9quilibrer le tout.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il faut bien choisir le bon nombre de partitions, s'il y en a trop \xe7a cr\xe9e un manque de performance du fait de chercher dans trop de partitions, s'il n'y en a pas assez on va d\xe9placer de trop gros blocs au moment du rebalancing. \xc7a peut \xeatre difficile \xe0 trouver si notre charge varie beaucoup."}),"\n",(0,r.jsxs)(n.li,{children:["Cette approche est utilis\xe9e par ",(0,r.jsx)(l.U,{children:"Riak"}),", ",(0,r.jsx)(l.U,{children:"Elasticsearch"}),", ",(0,r.jsx)(l.U,{children:"Couchbase"})," et ",(0,r.jsx)(l.U,{children:"Voldemort"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dynamic partitioning"}),". Pour les BDD utilisant le partitionnement de type key range (et pas hash range), avoir un nombre de partitions fixe peut \xeatre probl\xe9matique par rapport au skewing, et choisir \xe0 la main combien en mettre par nœud est fastidieux. On va donc vouloir un syst\xe8me qui r\xe9partir dynamiquement les partitions, par rapport \xe0 la quantit\xe9 de donn\xe9es pr\xe9sente dans chaque partition.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Quand une partition est jug\xe9e dynamiquement trop grosse, elle est coup\xe9e en 2 et une moiti\xe9 est \xe9ventuellement d\xe9plac\xe9e sur un autre nœud."}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"HBase"})," et ",(0,r.jsx)(l.U,{children:"RethinkDB"})," par exemple utilisent le partitionnement dynamique (puisqu'ils utilisent aussi le key range partitioning)."]}),"\n",(0,r.jsxs)(n.li,{children:["Pour le key range c'est obligatoire, mais le dynamic partitioning peut aussi \xeatre utilis\xe9 avec le hash range partitioning. ",(0,r.jsx)(l.U,{children:"MongoDB"})," par exemple donne le choix de key range ou hash range, et dans les deux cas fait le rebalancing de mani\xe8re dynamique."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Partitioning proportionally to nodes"}),". Le nombre fixe de partitions et le nombre dynamique de partitions est bas\xe9 sur la taille des partitions. On peut choisir plut\xf4t de se baser sur le nombre de partitions par nœud ind\xe9pendamment de leur taille. On fixe un nombre de partitions par nœud et on r\xe9partit les donn\xe9es dedans. Si on ajoute un nœud, les partitions existantes maigrissent pour transf\xe9rer une partie de leur donn\xe9es dans les partitions du nouveau nœud.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Cassandra"})," et ",(0,r.jsx)(l.U,{children:"Ketama"})," utilisent cette m\xe9thode."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On a un peu \xe9voqu\xe9 l'aspect manuel / automatique, mais plus concr\xe8tement :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Couchbase"}),", ",(0,r.jsx)(l.U,{children:"Voldemort"})," et ",(0,r.jsx)(l.U,{children:"Riak"})," cr\xe9ent des suggestions de rebalancing automatiquement, mais demandent la validation d'un administrateur humain pour op\xe9rer le rebalancing."]}),"\n",(0,r.jsx)(n.li,{children:"Le rebalancing compl\xe8tement automatique peut \xeatre tentant, mais il faut bien voir que c'est une op\xe9ration longue et co\xfbteuse, et que faire un mauvais rebalancing dans certaines conditions peut cr\xe9er une cascade d'\xe9chec, le syst\xe8me croyant \xe0 tort que certains noeuds surcharg\xe9s sont morts ou ce genre de chose. Globalement avoir un humain dans la boucle du rebalancing est une bonne id\xe9e."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos de la question du ",(0,r.jsx)(n.strong,{children:"routing"})," de la requ\xeate, comment le client va savoir \xe0 quel nœud envoyer sa requ\xeate ?","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il existe plusieurs solutions open source. Globalement 3 possibilit\xe9s se d\xe9gagent :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le client envoie \xe0 un nœud en mode round robin (chacun son tour), et ce nœud qui conna\xeet le bon nœud va faire lui-m\xeame la demande, va r\xe9ceptionner la r\xe9ponse, et la retransf\xe9rer au client."}),"\n",(0,r.jsxs)(n.li,{children:["Le client envoie la requ\xeate \xe0 un ",(0,r.jsx)(n.strong,{children:"routing tier"})," qui conna\xeet le partitionnement actuel, et va pouvoir envoyer la requ\xeate au bon nœud."]}),"\n",(0,r.jsx)(n.li,{children:"Le client conna\xeet d\xe9j\xe0 le bon nœud, et va directement lui envoyer la requ\xeate."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Dans tous les cas, il y a le probl\xe8me de savoir comment l'entit\xe9 qui conna\xeet le partitionnement actuel reste \xe0 jour malgr\xe9 les rebalancing ? C'est un probl\xe8me difficile.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il y a des protocoles pour atteindre un consensus dans les syst\xe8mes distribu\xe9s, mais ils sont compliqu\xe9s. On en parlera au chapitre 9."}),"\n",(0,r.jsxs)(n.li,{children:["De nombreux syst\xe8mes utilisent un service d\xe9di\xe9 au mapping entre partition / nœud et adresse ip.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"ZooKeeper"})," est l'un d'entre eux : tous les nœuds s'enregistrent aupr\xe8s de ZooKeeper et lui notifient les rebalancings. C'est lui qui fait autorit\xe9 en mati\xe8re de routing. Et il notifie les entit\xe9s qui en ont besoin (par exemple le routing tier) de l'\xe9tat du r\xe9seau de nœuds / partitions."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Espresso de Linkedin"})," utilise ",(0,r.jsx)(n.strong,{children:"Helix"}),", qui lui-m\xeame utilise ZooKeeper."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"HBase"}),", ",(0,r.jsx)(l.U,{children:"SolrCloud"})," et ",(0,r.jsx)(l.U,{children:"Kafka"})," utilisent aussi ZooKeeper."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"MongoDB"})," utilise son outil maison et ",(0,r.jsx)(n.strong,{children:"mongos daemons"})," comme routing tier."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Cassandra"})," et ",(0,r.jsx)(l.U,{children:"Riak"})," utilisent un ",(0,r.jsx)(n.strong,{children:"gossip protocol"})," pour que les nodes s'\xe9changent leurs changements de topologie. La requ\xeate peut alors arriver sur n'importe quel nœud qui la redirigera correctement vers le bon. \xc7a met plus de complexit\xe9 sur les nœuds, mais \xe7a \xe9vite la d\xe9pendance \xe0 un outil externe comme ZooKeeper."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Couchbase"})," ne fait pas de rebalancing automatique. Et il est coupl\xe9 en g\xe9n\xe9ral avec ",(0,r.jsx)(n.strong,{children:"moxi"}),", qui est un routing tier \xe9coutant les changements venant des nœuds."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Enfin concernant l'acc\xe8s au routing tier par le client, son adresse ip en changeant que rarement, une configuration de nom via DNS est suffisante pour y acc\xe9der."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"7---transactions",children:"7 - Transactions"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les transactions sont des unit\xe9s logiques regroupant plusieurs lectures / \xe9critures. Soit elles r\xe9ussissent, soit elles \xe9chouent et alors le client peut r\xe9essayer en toute s\xe9curit\xe9. Il s'agit d'abstraire tout un pan d'\xe9checs partiels qu'il faut g\xe9rer sinon \xe0 la main."}),"\n",(0,r.jsx)(n.li,{children:"Presque toutes les BDD relationnelles, et certaines non relationnelles utilisent les transactions pour encapsuler les requ\xeates. Cependant avec la hype r\xe9cente du NoSQL, on a un certain nombre de BDD qui arrivent avec l'id\xe9e que pour la scalabilit\xe9 et la high availability, les transactions doivent \xeatre abandonn\xe9es ou donner des garanties beaucoup plus faibles."}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ACID"})," signifie Atomicity, Consistency, Isolation and Durability. Malheureusement il y a de l'ambigu\xeft\xe9 sur chacun des termes, surtout sur l'isolation.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Atomicity"})," aurait pu \xeatre appel\xe9 ",(0,r.jsx)(n.em,{children:"abortability"}),", parce qu'il s'agit d'annuler une partie des requ\xeates d'une m\xeame transaction si la partie suivante \xe9choue. Comme \xe7a on peut recommencer la transaction enti\xe8re sans soucis."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Consistency"})," est ici entendu comme \xe9tant la coh\xe9rence des donn\xe9es du point de vue applicatif. Contrairement aux 3 autres termes, la consistency rel\xe8ve bien de la responsabilit\xe9 du code applicatif. Il s'agit de r\xe8gles li\xe9es au domaine en question, par exemple les d\xe9bits et les cr\xe9dits doivent s'annuler."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isolation"})," consiste \xe0 g\xe9rer les transactions concurrentes : chaque transaction doit pouvoir s'ex\xe9cuter sans \xeatre parasit\xe9e par d'autres transactions en plein milieu. On parle aussi de ",(0,r.jsx)(n.em,{children:"serializability"}),", pour dire qu'il faut la m\xeame garantie que si les transactions \xe9taient ex\xe9cut\xe9es en s\xe9rie les unes \xe0 la suite des autres. La plupart des BDD ne fournissent cependant pas ce niveau de garantie."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Durability"})," veut dire qu'une fois la transaction commit\xe9e, elle ne peut pas dispara\xeetre toute seule mais reste dans la BDD. Ca implique par exemple la technique du log write-ahead pour les B-Tree ou LSM-Tree, pour ne pas perdre les donn\xe9es. Cela implique aussi la r\xe9plication dans le cas de syst\xe8mes distribu\xe9s."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'atomicit\xe9 et l'isolation concernent les transactions avec plusieurs \xe9critures (plusieurs objets), mais aussi les “transactions” avec une seule \xe9criture. Si un probl\xe8me survient en plein milieu de l'\xe9criture, il faut s'assurer que la base de donn\xe9es ne se retrouve pas dans un \xe9tat inconsistant.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On dit parfois qu'on supporte les transaction (et m\xeame qu'on est ACID) quand on assure l'int\xe9grit\xe9 pour une seule \xe9criture, mais c'est une erreur, la transaction d\xe9signe principalement le groupe de plusieurs \xe9critures."}),"\n",(0,r.jsxs)(n.li,{children:["La garantie pour les \xe9critures sur un seul objet est parfois suffisante, mais dans pas mal de cas il faut une garantie sur plusieurs objets :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dans les BDD relationnelles (ou de graphe), les cl\xe9s \xe9trang\xe8res (ou les edges) doivent \xeatre mises \xe0 jour en m\xeame temps que l'objet change."}),"\n",(0,r.jsx)(n.li,{children:"Dans les BDD de document, les donn\xe9es \xe0 mettre \xe0 jour sont en g\xe9n\xe9ral dans le m\xeame document, donc pas de besoin de multi-object transaction de ce c\xf4t\xe9. Cependant les BDD de document encouragent aussi la d\xe9normalisation \xe0 la place des jointures, et dans ce cas les donn\xe9es doivent \xeatre mises \xe0 jour conjointement dans plusieurs endroits pour ne pas que la BDD devienne inconsistante."}),"\n",(0,r.jsx)(n.li,{children:"Quand on a des index secondaires, alors il faut mettre \xe0 jour aussi cet index, et ces index sont des objets diff\xe9rents du point de vue de la BDD, donc on doit bien avoir des transaction multi-objets."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Concernant l'annulation des transactions, c'est dans cette philosophie qu'est construite la notion d'ACID : si \xe7a \xe9choue on recommence la transaction.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Certaines BDD ne sont pas du tout dans cette philosophie : les BDD r\xe9pliqu\xe9es en mode leaderless sont plut\xf4t sur du “best effort”. La BDD ex\xe9cute ce qu'elle peut, et si on est dans un \xe9tat inconsistant, c'est \xe0 l'application de g\xe9rer les erreurs."}),"\n",(0,r.jsxs)(n.li,{children:["Certains ORM comme celui de Rails et Django ne r\xe9essayent pas les transactions automatiquement, alors que c'est l\xe0 le but m\xeame de l'ACIDit\xe9 de celles-ci.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Certains probl\xe8mes peuvent quand m\xeame survenir quand une transaction est abandonn\xe9e :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il se peut qu'elle ait fonctionn\xe9 mais qu'on ne re\xe7oive pas la r\xe9ponse."}),"\n",(0,r.jsx)(n.li,{children:"Si l'erreur est due \xe0 une surcharge de requ\xeates, r\xe9essayer la transaction n'arrangera pas les choses, au contraire."}),"\n",(0,r.jsx)(n.li,{children:"Il ne faut pas r\xe9essayer si l'erreur est de nature permanente (par exemple une violation de contraintes, ie. une transaction qui fait quelque chose d'interdit), mais seulement si l'erreur est de nature temporaire (r\xe9seau, crash d'un node, etc.)."}),"\n",(0,r.jsx)(n.li,{children:"Si la transaction a d'autres side-effects que sur la BDD (par exemple l'envoi d'un email), alors r\xe9essayer juste apr\xe8s peut refaire les side-effects. On parlera des Atomic commit et Two-phase commit plus tard."}),"\n",(0,r.jsx)(n.li,{children:"Si en r\xe9essayant \xe0 nouveau on \xe9choue quand m\xeame, la requ\xeate pourrait \xeatre compl\xe8tement perdue."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L'isolation au sens strict de transactions s\xe9rialisables est quelque chose de co\xfbteux que les BDD ne veulent souvent pas impl\xe9menter. On a donc seulement des ",(0,r.jsx)(n.strong,{children:"weak isolation levels"})," qui ne r\xe9pondent pas \xe0 tous les probl\xe8mes pos\xe9s par les transactions concurrentes. Il faut bien comprendre chaque probl\xe8me et chaque solution propos\xe9e pour choisir ceux qu'on a besoin pour notre application.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Read commited"})," est le niveau d'isolation le plus basique.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ca garantit :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Qu'il n'y aura pas de ",(0,r.jsx)(n.strong,{children:"dirty reads"})," : si au cours d'une transaction non termin\xe9e une \xe9criture a \xe9t\xe9 faite, une autre transaction au cours de la lecture ne doit pas pouvoir lire ce qui a \xe9t\xe9 \xe9crit."]}),"\n",(0,r.jsxs)(n.li,{children:["Qu'il n'y aura pas de ",(0,r.jsx)(n.strong,{children:"dirty writes"})," : si au cours d'une transaction non termin\xe9e une \xe9criture a \xe9t\xe9 faite mais pas encore commit\xe9e, et au cours d'une autre transaction l'\xe9criture est \xe9cras\xe9e, alors il on peut se retrouver avec des donn\xe9es inconsistantes."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Read commited est l'isolation par d\xe9faut dans de nombreuses bases de donn\xe9es, parmi elles : ",(0,r.jsx)(l.U,{children:"Oracle 11g"}),", ",(0,r.jsx)(l.U,{children:"PostgreSQL"}),", ",(0,r.jsx)(l.U,{children:"SQL Server 2012"}),", ",(0,r.jsx)(l.U,{children:"MemSQL"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["C\xf4t\xe9 impl\xe9mentation :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour les dirty reads, l'objet tout entier est bloqu\xe9 avec un lock par la transaction, jusqu'\xe0 ce qu'elle soit commit\xe9e ou abandonn\xe9e."}),"\n",(0,r.jsx)(n.li,{children:"Pour les dirty rights, on pourrait aussi mettre un lock, mais c'est perdre beaucoup en efficacit\xe9 parce que certaines requ\xeates lentes vont emp\xeacher de simples lectures. Alors la plupart du temps 2 valeurs sont conserv\xe9es : l'ancienne valeur de l'objet qu'on donne aux nouveaux lecteurs, et la nouvelle valeur qui sera la valeur finale quand la transaction en cours sera termin\xe9e."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Snapshot isolation and repeatable read"}),". Le read committed garantit que sur une m\xeame donn\xe9e il n'y aura pas des lectures / \xe9critures de transactions diff\xe9rentes, mais \xe7a ne garantit pas que diff\xe9rents objets de la base de donn\xe9es resteront coh\xe9rents entre eux au cours d'une m\xeame transaction.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Probl\xe8mes :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut par exemple lire une donn\xe9e, puis le temps qu'on lise la suivante celle-ci a \xe9t\xe9 modifi\xe9e, et la combinaison des deux lectures donne quelque chose d'incoh\xe9rent. En g\xe9n\xe9ral il suffit de refaire la 1\xe8re lecture et on a quelque chose de coh\xe9rent \xe0 nouveau."}),"\n",(0,r.jsx)(n.li,{children:"Plus grave : une copie de BDD peut prendre plusieurs heures, et le temps de la copie des changements peuvent \xeatre faits, de mani\xe8re \xe0 ce qu'au final on ait copi\xe9 au fur et \xe0 mesure quelque chose d'incoh\xe9rent. M\xeame chose avec une requ\xeate d'analyse \xe9norme qui met beaucoup de temps \xe0 lire un grand nombre de donn\xe9es : si elles sont modifi\xe9es en cours de route."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La snapshot isolation est support\xe9e par ",(0,r.jsx)(l.U,{children:"PostgreSQL"}),", ",(0,r.jsx)(l.U,{children:"MySQL"})," avec ",(0,r.jsx)(n.strong,{children:"InnoDB"}),", ",(0,r.jsx)(l.U,{children:"Oracle"}),", ",(0,r.jsx)(l.U,{children:"SQL Server"})," et d'autres."]}),"\n",(0,r.jsxs)(n.li,{children:["C\xf4t\xe9 impl\xe9mentation :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"En g\xe9n\xe9ral pour les writes on a un write lock qui bloque les autres writes sur un m\xeame objet."}),"\n",(0,r.jsx)(n.li,{children:"En revanche les reads n'utilisent pas de locks, et le principe c'est que les writes ne bloquent pas les reads et les reads ne bloquent pas les writes."}),"\n",(0,r.jsx)(n.li,{children:"Chaque transaction va avoir son snapshot de donn\xe9es en fonction des donn\xe9es sur lesquelles il op\xe8re, et ces donn\xe9es ne seront pas chang\xe9es de toute la transaction. On appelle \xe7a le multi-version concurrency control (MVVC)."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La snapshot isolation est appel\xe9e de diff\xe9rentes mani\xe8res en fonction des BDD :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Dans ",(0,r.jsx)(l.U,{children:"Oracle"})," elle est appel\xe9e ",(0,r.jsx)(n.em,{children:"serializable"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Dans ",(0,r.jsx)(l.U,{children:"MySQL"})," et ",(0,r.jsx)(l.U,{children:"PostgreSQL"})," c'est appel\xe9 ",(0,r.jsx)(n.em,{children:"repeatable read"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ce terme ",(0,r.jsx)(n.em,{children:"repeatable read"})," vient du standard SQL qui ne contient pas la notion de ",(0,r.jsx)(n.em,{children:"snapshot isolation"}),", vu qu'elle n'existait pas \xe0 l'\xe9poque de System R (sur lequel est bas\xe9e la norme SQL)."]}),"\n",(0,r.jsxs)(n.li,{children:["Et pour compliquer le tout, IBM DB2 utilise le terme de ",(0,r.jsx)(n.em,{children:"repeatable read"})," pour d\xe9signer la serializability, ce qui fait qu'il n'a plus vraiment de sens."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Preventing lost updates"}),". Jusqu'ici on s'est int\xe9ress\xe9 aux probl\xe8mes de lecture dans un contexte d'\xe9critures dans d'autres transactions. Mais il y a \xe9galement des probl\xe8mes survenant lors d'\xe9critures concurrentes entre-elles. Les dirty writes en sont un exemple, et les lost updates un autre.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Si deux transactions modifient une m\xeame valeur de mani\xe8re concurrente, la derni\xe8re transaction \xe9crasera la valeur \xe9crite dans la premi\xe8re. On dit aussi qu'elle va la ",(0,r.jsx)(n.em,{children:"clobber"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Exemples : un compteur incr\xe9ment\xe9 deux fois mais qui se retrouve finalement incr\xe9ment\xe9 de 1, ou encore deux utilisateurs modifiant la m\xeame page wiki en envoyant la page enti\xe8re, le dernier \xe9crasant les modifications de l'autre."}),"\n",(0,r.jsxs)(n.li,{children:["Ce probl\xe8me courant a de nombreuses solutions :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Atomic write operations"})," : vu que le probl\xe8me des lost updates vient du fait qu'on lit d'abord la valeur avant de la mettre \xe0 jour, certaines BDD donnent la possibilit\xe9 de faire une lecture suivie d'un update avec une atomicit\xe9 garantie.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"MongoDB"})," fournit aussi la possibilit\xe9 de faire des modifications locales \xe0 un document JSON de mani\xe8re atomique."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Redis"})," permet de modifier par exemple des priority queues de mani\xe8re atomique."]}),"\n",(0,r.jsx)(n.li,{children:"En g\xe9n\xe9ral les BDD le font en donnant un lock sur l'objet concern\xe9 par l'\xe9criture."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Explicit locking"})," : on peut, en pleine requ\xeate SQL, indiquer qu'on prend un lock manuellement sur le r\xe9sultat d'une partie de la requ\xeate, pour le r\xe9utiliser dans une \xe9criture juste apr\xe8s.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut facilement oublier de le faire ou mal prendre en compte la logique applicative."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Automatically detect lost updates"})," : de nombreuses BDD permettent de v\xe9rifier la pr\xe9sence de lost updates, et en cas de d\xe9tection d'annuler la requ\xeate et de la retenter juste apr\xe8s.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["L'avantage aussi c'est qu'on peut le faire avec la m\xeame fonctionnalit\xe9 que le snapshot isolation. ",(0,r.jsx)(l.U,{children:"PostgreSQL"}),", ",(0,r.jsx)(l.U,{children:"Oracle"})," et ",(0,r.jsx)(l.U,{children:"SQL Server"})," le font de cette mani\xe8re. ",(0,r.jsx)(l.U,{children:"MySQL"})," / ",(0,r.jsx)(l.U,{children:"InnoDB"})," en revanche ne supportent pas cette fonctionnalit\xe9."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Compare-and-set"})," : certaines bases de donn\xe9es qui ne fournissent pas de transactions permettent des op\xe9rations compare-and-set qui consistent \xe0 ex\xe9cuter un changement seulement si la donn\xe9e n'a pas \xe9t\xe9 modifi\xe9e depuis la derni\xe8re fois qu'on l'a lue, ce qui permet normalement d'\xe9viter les lost updates."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dans le cas des BDD avec r\xe9plication"})," : quand on a de la r\xe9plication les locks ne servent \xe0 rien, et le compare-and-set non plus. La meilleure solution est d'ex\xe9cuter les deux requ\xeates et de garder une copie des deux r\xe9sultats, puis de faire appel \xe0 du code applicatif ou d'utiliser des structures sp\xe9ciales de fusion pour r\xe9soudre le conflit.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Riak"})," 2.0 fournit des structures qui permettent d'\xe9viter les lost updates \xe0 travers les r\xe9plicas."]}),"\n",(0,r.jsx)(n.li,{children:"Malheureusement la plupart des BDD ont par d\xe9faut une strat\xe9gie last write wins (LWW) qui est provoque des lost updates."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Write skews and phantoms"})," : on g\xe9n\xe9ralise ici le cas des dirty writes et des lost updates dans la mesure o\xf9 on va \xe9crire sur des objets diff\xe9rents. Chaque requ\xeate concurrente lit les donn\xe9es, puis \xe9crit dans un objet diff\xe9rent, mais comme ils le font ind\xe9pendamment, le code applicatif ne se rend pas compte qu'ils cassent une contrainte applicative qui devait \xeatre garantie par le code applicatif. On appelle \xe7a des ",(0,r.jsx)(n.strong,{children:"write skew"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Exemple : il faut au moins un docteur on-call, il en reste deux et les deux d\xe9cident de cliquer sur le bouton pour se d\xe9sister. Les deux transactions se font en parall\xe8le et modifient des objets diff\xe9rents li\xe9s au profil de chaque docteur."}),"\n",(0,r.jsxs)(n.li,{children:["Les solutions sont moins nombreuses :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les BDD ne fournissent pas de moyen de mettre des contraintes sur des objets diff\xe9rents. On peut en revanche utiliser du code custom avec les triggers ou les materialized views si c'est support\xe9."}),"\n",(0,r.jsxs)(n.li,{children:["On peut locker les objets concern\xe9s par notre logique m\xe9tier \xe0 la main au moment de faire la requ\xeate.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Cette solution marche si on a d\xe9j\xe0 les objets dont on veut que la valeur ne change pas. Mais si dans notre cas la condition c'est qu'une entr\xe9e avec une certaine caract\xe9ristique n'existe pas pour pouvoir faire quelque chose (par ex ins\xe9rer un nom d'utilisateur s'il n'est pas d\xe9j\xe0 pris), alors on ne peut pas locker \xe0 la main une absence d'objet.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Dans ce cas o\xf9 le write skew est caus\xe9 par une \xe9criture dans une transaction, qui change le r\xe9sultat d'une recherche dans une autre transaction, le ph\xe9nom\xe8ne est appel\xe9 un ",(0,r.jsx)(n.strong,{children:"phantom"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Une solution (peu \xe9l\xe9gante) peut consister \xe0 mat\xe9rialiser les phantoms en cr\xe9ant une table sp\xe9ciale avec un champ pour chaque \xe9l\xe9ment possible, et demander au code applicatif de faire un lock manuel sur l'\xe9l\xe9ment mat\xe9rialis\xe9 correspondant \xe0 chaque write. Dans la plupart des cas, il vaut cependant mieux privil\xe9gier la serializability."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Malheureusement la snapshot isolation ne suffit pas, il faut une vraie serializability dont on va parler un peu plus loin."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Serializability"})," : il y a un niveau au-dessus de tous les autres, qui permet de garantir que les transactions vont s'ex\xe9cuter avec le m\xeame niveau de garantie vis-\xe0-vis des race conditions que s'ils \xe9taient ex\xe9cut\xe9s les uns \xe0 la suite des autres, sans parall\xe9lisme du tout. Il y a 3 techniques pour l'impl\xe9menter dans un contexte non distribu\xe9 :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Actual serial execution"})," : on va ex\xe9cuter les transactions vraiment les uns \xe0 la suite des autres, sur un seul thread.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cette option est envisag\xe9e maintenant alors qu'elle \xe9tait rejet\xe9e auparavant parce que la RAM est peu ch\xe8re et on peut mettre l'essentiel de la BDD dedans, ce qui permet de rendre les transactions tr\xe8s rapides. Et aussi parce que les transactions OLTP sont courtes et impliquent peu de requ\xeates, alors que les OLAP sont certes longues mais sont read-only donc peuvent se faire hors de l'execution loop."}),"\n",(0,r.jsxs)(n.li,{children:["Cette approche est utilis\xe9e dans ",(0,r.jsx)(l.U,{children:"VoltDB"})," / ",(0,r.jsx)(l.U,{children:"H-Store"}),", ",(0,r.jsx)(l.U,{children:"Redis"})," et ",(0,r.jsx)(l.U,{children:"Datomic"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Pour que ce soit possible sur un seul thread, il faut qu'il ne soit pas bloqu\xe9 pendant qu'on demande \xe0 l'utilisateur la suite en plein milieu de la transaction. Il faut donc collecter les donn\xe9es qu'il faut pour toute la transaction, et faire la transaction enti\xe8re en une fois. Pour ce faire, on utilise les ",(0,r.jsx)(n.strong,{children:"stored procedures"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ces proc\xe9dures permettent d'ex\xe9cuter du code \xe9crit dans un langage sp\xe9cifique : pour ",(0,r.jsx)(l.U,{children:"Oracle"})," PL/SQL, pour ",(0,r.jsx)(l.U,{children:"SQL Server"})," T-SQL, pour ",(0,r.jsx)(l.U,{children:"PostgreSQL"})," PL/pgSQL, mais ces langages sont vieux, peu testables, et n'ont pas beaucoup de fonctionnalit\xe9s."]}),"\n",(0,r.jsxs)(n.li,{children:["Des BDD modernes permettent cependant d'utiliser des langages modernes pour les stored procedures : ",(0,r.jsx)(l.U,{children:"VoltDB"})," utilise Java et Groovy, ",(0,r.jsx)(l.U,{children:"Datomic"})," utilise Java et Clojure, ",(0,r.jsx)(l.U,{children:"Redis"})," utilise Lua."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour la r\xe9plication, ",(0,r.jsx)(l.U,{children:"VoltDB"})," permet d'ex\xe9cuter les stored procedures sur chaque machine. Il faut alors que ces proc\xe9dures soient d\xe9terministes."]}),"\n",(0,r.jsxs)(n.li,{children:["Dans le cas o\xf9 on veut scaler en \xe9criture on a besoin de partitionnement. On peut alors cr\xe9er autant de partitions que de coeurs de processeur sur la machine, et assigner un thread par partition. Chaque partition ex\xe9cutera bien les transactions de mani\xe8re s\xe9quentielle.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Attention par contre aux requ\xeates qui ont besoin d'effectuer des op\xe9rations \xe0 travers plusieurs partitions (\xe0 peu pr\xe8s tout sauf les donn\xe9es key/value), \xe7a provoque des ralentissement de plusieurs ordres de grandeur."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Donc les contraintes pour utiliser l'ex\xe9cution en s\xe9rie :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Chaque transaction doit \xeatre petite et rapide."}),"\n",(0,r.jsx)(n.li,{children:"La BDD doit entrer en RAM. Une partie peu utilis\xe9e de la BDD peut rester sur disque, mais si on doit aller la chercher dans le thread unique c'est chaud au niveau perf. Une solution pourrait \xeatre d'abandonner la transaction, mettre la donn\xe9e dont on a besoin en RAM, et la retenter."}),"\n",(0,r.jsx)(n.li,{children:"La charge en \xe9criture doit \xeatre assez faible pour \xeatre trait\xe9e par une machine, ou alors il faut un partitionnement sans requ\xeates qui s'ex\xe9cutent sur plusieurs partitions."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Two-Phase Locking (2PL)"})," : c'est l'algorithme qui a \xe9t\xe9 utilis\xe9 pendant 30 ans. Il s'agit de mettre un lock sur la donn\xe9e d\xe8s lors qu'on est en pr\xe9sence d'une transaction qui fait un write, m\xeame vis-\xe0-vis de transactions qui ne font que des reads. En revanche s'il n'y a que des transactions qui font des reads, pas besoin de lock.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Compar\xe9 au snapshot isolation o\xf9 les writes ne bloquaient pas les reads, et les reads ne bloquaient pas les writes, ici les writes bloquent aussi les reads."}),"\n",(0,r.jsxs)(n.li,{children:["2PL est utilis\xe9 dans ",(0,r.jsx)(l.U,{children:"MySQL"})," (InnoDB), ",(0,r.jsx)(l.U,{children:"SQL Server"})," et ",(0,r.jsx)(l.U,{children:"DB2"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Fonctionnement : il y a les shared locks et les exclusive locks. A chaque fois qu'un read est fait sur un objet, la transaction prend un shared lock, qui permet de la faire attendre au cas o\xf9 l'exclusive lock serait pris. Si une transaction veut faire un write, alors elle prend l'exclusive lock d\xe8s qu'elle peut, et tout le monde doit attendre pour acc\xe9der \xe0 cet objet que sa transaction enti\xe8re soit termin\xe9e (d'o\xf9 le 2-phase : on prend le lock, puis on termine le reste de la transaction de mani\xe8re exclusive).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour \xeatre vraiment comme des transactions s\xe9rialis\xe9es, il faut aussi r\xe9soudre le probl\xe8me des phantoms (un write qui modifie le r\xe9sultat d'une recherche). On le fait en cr\xe9ant des locks sur des pr\xe9dicats : si une transaction a besoin de faire une query pour chercher quelque chose, alors elle d\xe9clare un shared lock sur un pr\xe9dicat, et si un write modifie le r\xe9sultat correspondant \xe0 ce pr\xe9dicat, alors ils se bloqueront mutuellement.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le lock sur des pr\xe9dicats \xe9tant tr\xe8s mauvais d'un point de vue performance, on approxime souvent les pr\xe9dicats sous forme de lock d'index, en s'assurant qu'on lock \xe9ventuellement plus d'objets, et pas moins pour respecter la s\xe9rialisabilit\xe9."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le souci de cette m\xe9thode c'est la performance, en partie du fait de nombreux locks, mais surtout du fait que n'importe quelle transaction peut faire attendre toutes les autres. Donc on a un flow assez impr\xe9dictible, et des high percentiles mauvais.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les deadlocks sont d\xe9tect\xe9s et r\xe9solus en annulant l'une des transactions, mais s'ils sont nombreux, \xe7a fait d'autant moins de performance."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Serializable Snapshot Isolation (SSI)"})," : il s'agit d'un algorithme tr\xe8s prometteur qui fournit la s\xe9rialisabilit\xe9, et en m\xeame temps n'a que tr\xe8s peu de diff\xe9rence de performance avec la snapshot isolation.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La SSI est \xe0 la fois utilis\xe9e par les BDD single node (",(0,r.jsx)(l.U,{children:"PostgreSQL"})," depuis la version 9.1) et distribu\xe9es (",(0,r.jsx)(l.U,{children:"FoundationDB"}),")."]}),"\n",(0,r.jsxs)(n.li,{children:["Fonctionnement : contrairement \xe0 l'id\xe9e de faire des locks pour prot\xe9ger la transaction d'un conflit \xe9ventuel, qui est une approche dite pessimiste, ici on adopte une approche optimiste et on r\xe9alise toutes les transactions dans un snapshot \xe0 part. Au moment du commit on v\xe9rifie qu'il n'y a pas eu de conflits. S'ils ont eu lieu, on annule la transaction et on laisse l'application recommencer.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il y a une difficult\xe9 vis-\xe0-vis du fait de d\xe9tecter si une transaction avec lecture initiale suivie d'une \xe9criture devient invalide parce que la donn\xe9e lue est modifi\xe9e par une autre transaction. Il y a 2 solutions pour r\xe9gler \xe7a :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"D\xe9tecter les lectures faites sur le MVCC (multi version concurrency control) qui ne sont plus \xe0 jour au moment o\xf9 la transaction veut \xeatre commit\xe9e. Si on d\xe9tecte, on annule la transaction."}),"\n",(0,r.jsx)(n.li,{children:"D\xe9tecter les writes qui affectent les reads d'une autre transaction en pla\xe7ant une balise sur l'index concern\xe9 pour indiquer que plusieurs transactions utilisent la donn\xe9e. Au moment de commiter, la BDD v\xe9rifie qu'il n'y a pas de conflit par rapport au write fait par la transaction qui avait \xe9t\xe9 marqu\xe9e. Si oui on annule la derni\xe8re qui veut commiter. Le marquage peut \xeatre enlev\xe9 quand la situation de concurrence est r\xe9solue."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Au niveau de la performance, plus la BDD est pr\xe9cise sur quelle transaction doit \xeatre annul\xe9e, et plus \xe7a lui prend du temps. D'un autre c\xf4t\xe9 si elle en annule trop \xe7a fait plus de transactions annul\xe9es."}),"\n",(0,r.jsx)(n.li,{children:"Compar\xe9 au 2PL on a quelque chose de plus performant mais aussi de plus pr\xe9dictible, vu que les requ\xeates n'ont pas \xe0 attendre qu'une longue requ\xeate ait termin\xe9. Et si on a une forte charge de lectures c'est parfait aussi puisqu'elles ne sont jamais bloqu\xe9es."}),"\n",(0,r.jsxs)(n.li,{children:["Compar\xe9 \xe0 l'ex\xe9cution vraiment en s\xe9rie, on n'est pas limit\xe9 au CPU d'une seule machine, ",(0,r.jsx)(l.U,{children:"FoundationDB"})," distribue la d\xe9tection des conflits sur plusieurs machines."]}),"\n",(0,r.jsx)(n.li,{children:"Globalement, vu qu'une transaction peut vite voir ses pr\xe9misses invalid\xe9es par d'autres, pour qu'on n'ait pas beaucoup d'annulation de transactions, il faut que celles-ci soient assez courtes et rapides. Mais d'un autre c\xf4t\xe9, 2PL et l'ex\xe9cution s\xe9riale ne font pas mieux avec les transactions longues."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"8---the-trouble-with-distributed-systems",children:"8 - The trouble with distributed systems"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les fautes partielles :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le souci avec les syst\xe8mes distribu\xe9s c'est qu'ils peuvent agir de mani\xe8re non d\xe9terministe, et qu'une partie du syst\xe8me peut \xeatre en \xe9chec alors que le reste fonctionne. C'est une chose dont on n'a pas l'habitude dans un seul ordinateur."}),"\n",(0,r.jsxs)(n.li,{children:["Les superordinateurs choisissent en g\xe9n\xe9ral d'\xe9crire des checkpoints en DD, et d'arr\xeater tout le syst\xe8me pour r\xe9parer le composant probl\xe9matique en cas de panne, pour ensuite reprendre l\xe0 o\xf9 \xe7a en \xe9tait \xe0 partir du checkpoint.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les syst\xe8mes distribu\xe9s de type “cloud” ou “web” sont \xe0 l'oppos\xe9 :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"ils sont trop gros pour tol\xe9rer d'\xe9teindre \xe0 chaque panne, et ils ne peuvent de toute fa\xe7on pas tol\xe9rer d'arr\xeater le service"}),"\n",(0,r.jsx)(n.li,{children:"ils utilisent du mat\xe9riel bon march\xe9 pour scaler"}),"\n",(0,r.jsx)(n.li,{children:"ils sont r\xe9partis \xe0 travers le globe, utilisant le r\xe9seau internet qui est tr\xe8s peu fiable compar\xe9 \xe0 un r\xe9seau local."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Il faut que la gestion des probl\xe8mes mat\xe9riels fasse partie du design de notre syst\xe8me."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le r\xe9seau :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le r\xe9seau internet (IP) est construit de mani\xe8re \xe0 \xeatre peu fiable de par sa nature asynchrone. Un paquet peut \xe0 tout moment \xeatre perdu, corrompu, mettre beaucoup plus de temps \xe0 arriver etc. pour diverses raisons, parce qu'il passe par des dizaines de nœuds divers et vari\xe9s qui peuvent \xeatre surcharg\xe9s, d\xe9branch\xe9s, mal configur\xe9s etc.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On a des protocoles comme TCP construits par dessus pour corriger \xe7a et renvoyer les paquets perdus ou corrompus."}),"\n",(0,r.jsx)(n.li,{children:"Quand on envoie un paquet, on ne sait pas s'il a \xe9t\xe9 re\xe7u ou pas. Au mieux on peut demander au destinataire de r\xe9pondre, mais s'il ne r\xe9pond pas on ne sait pas ce qu'il s'est pass\xe9. Tout ce qu'on peut faire c'est avoir un timeout, et consid\xe9rer l'\xe9chec apr\xe8s le timeout."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["C'est le cas d'internet qui est peu fiable, mais le r\xe9seau ethernet local est \xe9galement asynchrone. Donc les messages \xe9chang\xe9s entre les ordinateurs d'un m\xeame datacenter sont aussi prompts aux corruptions et pertes.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Une \xe9tude a trouv\xe9 qu'il y a 12 fautes r\xe9seau par mois dans un datacenter moyen."}),"\n",(0,r.jsx)(n.li,{children:"Ajouter de la redondance ne r\xe8gle pas autant de probl\xe8mes qu'on le croit puisqu'il y a aussi les erreurs humaines des ops qui sont nombreuses"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La d\xe9tection des machines en \xe9tat de faute est difficile, mais il y a des moyens :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si le processus applicatif est mort mais que l'OS tourne, la machine r\xe9pondra peut-\xeatre par un message TCP indiquant qu'elle refuse les connexions."}),"\n",(0,r.jsxs)(n.li,{children:["Dans le m\xeame cas, la machine peut aussi avertir les autres nœuds que son processus applicatif est mort. ",(0,r.jsx)(l.U,{children:"HBase"})," fait \xe7a."]}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas sp\xe9cifique d'un datacenter, on peut avoir acc\xe8s aux switches r\xe9seaux pour avoir certaines informations sur l'\xe9tat connu de certaines machines qui ne r\xe9pondent plus depuis un certain temps."}),"\n",(0,r.jsx)(n.li,{children:"De m\xeame avec les routeurs qui peuvent imm\xe9diatement r\xe9pondre que telle ou telle machine est injoignable si on les interroge."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La question de la valeur du timeout est une question particuli\xe8rement \xe9pineuse et pas simple. Une des mani\xe8res est de tester en environnement r\xe9el et d'ajuster en fonction des performances.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Cet ajustement peut \xeatre automatique, ",(0,r.jsx)(l.U,{children:"Akka"})," et ",(0,r.jsx)(l.U,{children:"Cassandra"})," font \xe7a."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La congestion du r\xe9seau est souvent caus\xe9e par des probl\xe8mes de queuing diverses :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"au niveau des switchs"}),"\n",(0,r.jsx)(n.li,{children:"au niveau des machines si tous les CPU sont occup\xe9s"}),"\n",(0,r.jsx)(n.li,{children:"TCP qui fait du queuing pour \xe9viter la corruption de paquets, et qui retente l'envoie du paquet de mani\xe8re transparente (ce qui prend du temps)"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Ne pourrait-on pas rendre la communication fiable du point de vue mat\xe9riel ?","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour ce faire, il faudrait qu'elle soit synchrone. C'est le cas du r\xe9seau t\xe9l\xe9phonique \xe0 commutation de circuit, qui alloue une ligne permettant d'envoyer une quantit\xe9 fixe de donn\xe9es de mani\xe8re r\xe9guli\xe8re. Les divers switch et autres \xe9l\xe9ments r\xe9seaux qui \xe9tablissent cette communication allouent cette quantit\xe9 pour que le transfert puisse se faire."}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas des communications autres que stream audio / vid\xe9o, on ne sait pas \xe0 l'avance quelle quantit\xe9 de donn\xe9es on voudra, ni quand on voudra faire le transfert. La commutation par paquets permet de ne rien envoyer quand il n'y a pas besoin, et d'envoyer des paquets de taille variable quand c'est n\xe9cessaire. Le prix c'est que le r\xe9seau n'est pas en train de nous allouer de la place en permanence, et qu'il y a du queuing."}),"\n",(0,r.jsx)(n.li,{children:"C'est donc bien un choix d'allocation dynamique et non pas de r\xe9servation statique des ressources r\xe9seaux qui fait qu'on utilise toutes nos ressources disponibles mais avec des d\xe9lais variables. On fait ce genre de choix aussi pour l'allocation dynamique des CPU vis \xe0 vis des threads."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les clocks : les clocks des ordinateurs sont globalement peu fiables, et d'autant moins dans un contexte d'ordinateurs distribu\xe9s.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il y a 2 types de clocks sur un ordinateur :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"time-of-the-day clocks"})," : ils renvoient le temps courant, en g\xe9n\xe9ral sous forme d'entier depuis l'",(0,r.jsx)(n.em,{children:"epoch"})," (1er janvier 1970).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Vu qu'ils sont synchronis\xe9s par NTP (network time protocol), on peut r\xe9guli\xe8rement avoir des sauts dans le temps, et donc pour mesurer des dur\xe9es c'est pas le top."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"monotonic clocks"})," : ils renvoient une valeur arbitraire, mais garantissent qu'apr\xe8s un certain temps, la valeur renvoy\xe9e sera l'ancienne + le temps \xe9coul\xe9"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos de la pr\xe9cision :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Google suppose que les clocks de ses machines se d\xe9calent de l'\xe9quivalent de 17 secondes pour un clock resynchronis\xe9 une fois par jour."}),"\n",(0,r.jsx)(n.li,{children:"Le protocole de mise \xe0 jour des clocks NTP ne peut pas \xeatre plus pr\xe9cis que le temps de latence d'envoi/r\xe9ception des messages (une exp\xe9rimentation a montr\xe9 un minimum de 35 ms pour une synchronisation via internet).. Et en cas de congestion du r\xe9seau c'est pire."}),"\n",(0,r.jsx)(n.li,{children:"Dans les machines virtuelles le CPU est partag\xe9, donc on peut se retrouver avec des sauts bizarres dans le clock \xe0 cause de \xe7a."}),"\n",(0,r.jsx)(n.li,{children:"En cas de besoin, on peut mettre en place des infrastructures de haute pr\xe9cision qui se mettent \xe0 jour par GPS, mais c'est co\xfbteux. C'est ce qui est fait sur les machines de trading \xe0 haute fr\xe9quence."}),"\n",(0,r.jsxs)(n.li,{children:["En fait, il faudrait voir le clock plut\xf4t comme un intervalle que comme un temps. Malheureusement la plupart des API ne le pr\xe9sentent pas comme \xe7a.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Une exception est constitu\xe9e par l'API ",(0,r.jsx)(n.strong,{children:"TrueTime"})," de ",(0,r.jsx)(l.U,{children:"Google Spanner"}),", qui renvoie un groupe de 2 valeurs : ",(0,r.jsx)(n.em,{children:"[earliest, latest]"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dans le cas particulier de Google, en partant du principe que les intervalles de confiance sont fiables, si deux intervalles pour deux requ\xeates ne se chevauchent pas, alors on est s\xfbrs que la requ\xeate avec l'intervalle plus r\xe9cent a eu lieu apr\xe8s l'autre. Google utilise \xe7a pour faire de la snapshot isolation dans un environnement distribu\xe9, mais pour \xe7a il \xe9quipe chaque datacenter d'une r\xe9ception GPS ou d'une horloge atomique, sans quoi les intervalles seraient trop grands. En dehors de Google cette solution bas\xe9e sur le temps n'est pour le moment pas viable."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Contrairement \xe0 un CPU ou une carte r\xe9seau, quand un clock est d\xe9fectueux la machine peut quand m\xeame donner l'impression que tout va bien, et faire des erreurs qui se voient beaucoup plus difficilement.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est en particulier probl\xe9matique si on se sert des clocks pour faire des timestamps pour v\xe9rifier quelle transaction a eu lieu la 1\xe8re dans un syst\xe8me distribu\xe9. Et c'est encore plus probl\xe9matique avec du LWW (last write wins) : si on noeud a son clock qui retarde, tous ses messages finiront par \xeatre rejet\xe9s en faveur de ceux des autres nœuds parce que consid\xe9r\xe9s comme anciens."}),"\n",(0,r.jsx)(n.li,{children:"Plut\xf4t que les clocks physiques, il faut utiliser des clocks logiques, c'est-\xe0-dire des techniques pour d\xe9tecter l'ordre des choses plut\xf4t que le moment o\xf9 elles ont eu lieu."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Un thread peut se mettre en pause pendant un temps ind\xe9termin\xe9 pour des raisons tr\xe8s vari\xe9es : le garbage collector du langage, la machine virtuelle, l'OS qui a besoin de le mettre en pause pour faire autre chose etc. Dans un syst\xe8me distribu\xe9 “shared nothing” il n'y a pas de m\xe9moire partag\xe9e, donc il faut partir du principe qu'un nœud peut se retrouver arr\xeat\xe9 pendant que le monde autour de lui aura continu\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il existe des syst\xe8mes appel\xe9s temps r\xe9el (real time, ou hard real time pour bien insister sur l'aspect contrainte de temps \xe0 respecter absolument). Ces syst\xe8mes sont pens\xe9s et test\xe9s sous tous les angles pour respecter un certain nombre de contraintes de temps de r\xe9ponse. On les utilise principalement dans les machines o\xf9 le temps est crucial (par exemple le d\xe9clenchement d'un airbag)."}),"\n",(0,r.jsx)(n.li,{children:"Pour le probl\xe8me sp\xe9cifique du garbage collector, certains syst\xe8mes demandent \xe0 leur nœud de pr\xe9venir quand il y a un besoin de garbage collection, et au besoin redirigent le trafic vers d'autres nœuds en attendant que ce soit fait. \xc7a permet de r\xe9duire pas mal les probl\xe8mes de pause non voulue de l'application."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Savoir, v\xe9rit\xe9 et mensonge :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dans des conditions aussi difficiles que les syst\xe8mes distribu\xe9s o\xf9 on ne peut rien savoir de certain sauf \xe0 travers les messages qu'on re\xe7oit ou ne re\xe7oit pas, on peut quand m\xeame cr\xe9er des syst\xe8mes qui fonctionnent : il est possible d'avoir quelque chose de fiable construit sur des bases offrant peu de garanties, \xe0 conditions que le mod\xe8le de syst\xe8me qu'on a choisi convienne."}),"\n",(0,r.jsxs)(n.li,{children:["La v\xe9rit\xe9 dans un contexte distribu\xe9 est d\xe9termin\xe9e par la majorit\xe9. Pour \xe9viter la d\xe9pendance \xe0 un noeud particulier, et \xe9tant donn\xe9 qu'un noeud, quel qu'il soit, ne peut pas faire confiance \xe0 sa propre horloge vu qu'il peut entrer en pause \xe0 tout moment sans le savoir, on d\xe9cide de mettre en place des ",(0,r.jsx)(n.strong,{children:"quorums"})," pour qu'une majorit\xe9 de noeuds d\xe9cident par exemple si un noeud est mort ou non.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il faut bien s'assurer que and on noeud pense \xeatre dot\xe9 d'une responsabilit\xe9 (il est le leader, il a le lock sur un objet etc.), il se fie quand m\xeame \xe0 ce que disent la majorit\xe9 des noeuds : s' ils lui disent qu'il n'a plus la responsabilit\xe9 en question, alors il faut qu'il accepte de se comporter comme tel, sous peine d'inconsistances dans le syst\xe8me."}),"\n",(0,r.jsxs)(n.li,{children:["Pour garantir qu'un lock soit bien respect\xe9, on peut utiliser un lock service qui fournit un token incr\xe9mental \xe0 chaque lock. Si le nœud a son temps allou\xe9 qui a expir\xe9, et qu'il essaye d'\xe9crire alors qu'un autre a d\xe9j\xe0 \xe9crit \xe0 sa place, son token sera rejet\xe9 par le lock service. On parle de ",(0,r.jsx)(n.strong,{children:"fencing token"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"ZooKeeper"})," permet de fournir ce genre de fencing token s'il est utilis\xe9 comme lock service."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Jusqu'ici on est parti du principe que les noeuds peuvent de plus r\xe9pondre, ne pas savoir qu'ils n'ont plus une certaine responsabilit\xe9, ou \xe9chouer. Mais qu'ils restent “honn\xeates” au sens o\xf9 ils ne vont pas dire qu'ils ont re\xe7u un message alors qu'ils ne l'ont pas re\xe7u, ou encore falsifier un fencing token. De tels cas de corruption s'appellent une ",(0,r.jsx)(n.strong,{children:"Byzantine fault"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\xc7a vient du Byzantine Generals Problem o\xf9 on imagine dans la ville antique de Byzance, des g\xe9n\xe9raux de guerre essayent de se mettre d'accord, et communiquant par messager, mais o\xf9 certains g\xe9n\xe9raux mentent sans se faire d\xe9couvrir."}),"\n",(0,r.jsx)(n.li,{children:"On imagine donc que certains nœuds peuvent \xeatre compl\xe8tement corrompus jusqu'\xe0 ne plus suivre le protocole attendu du tout, par exemple dans le cas d'un logiciel dans un contexte a\xe9rospatial soumis \xe0 des radiations."}),"\n",(0,r.jsxs)(n.li,{children:["Ou alors se mettent carr\xe9ment \xe0 tricher intentionnellement, soit \xe0 cause d'un piratage, soit plus classiquement un contexte de communication inter-organisations, o\xf9 les organisations ne se font pas confiance.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est le cas par exemple pour la blockchain o\xf9 les participants ne se font pas confiance puisque n'importe lequel pourrait essayer de tricher."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Dans notre cas habituel de serveurs web, on part du principe que le client final derri\xe8re son navigateur pourrait \xeatre malicieux, mais sinon les serveurs de l'organisation sont fiables. Et on ne met pas en place de m\xe9canismes contre les probl\xe8mes de fautes byzantines, parce que c'est trop compliqu\xe9."}),"\n",(0,r.jsx)(n.li,{children:"La plupart des algorithmes contre les fautes byzantines comptent sur le fait que la majorit\xe9 des nœuds ne vont pas \xeatre infect\xe9s par le probl\xe8me, et donc pourront garder le contr\xf4le contre la minorit\xe9 du r\xe9seau corrompue. Donc \xe7a peut \xeatre utile dans un contexte d'application peer-to-peer, mais si on charge notre version du logiciel dans tous les nœuds, \xe7a ne nous prot\xe9gera pas des bugs. Et de m\xeame si un hacker prend le contr\xf4le d'un nœud, on imagine qu'il pourra aussi prendre le contr\xf4le des autres nœuds."}),"\n",(0,r.jsxs)(n.li,{children:["On peut n\xe9anmoins se pr\xe9munir contre des formes mod\xe9r\xe9es de mensonges avec quelques astuces :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Faire un checksum des paquets pour v\xe9rifier qu'ils n'aient pas \xe9t\xe9 corrompus. TCP/UDP le font mais parfois laissent passer."}),"\n",(0,r.jsx)(n.li,{children:"V\xe9rifier la validit\xe9 de toutes les donn\xe9es entr\xe9es par l'utilisateur."}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas de la mise \xe0 jour depuis des serveurs NTP, faire des requ\xeates aupr\xe8s de plusieurs serveurs, pour que ceux qui n'ont pas une bonne valeur soient rejet\xe9s."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Notre syst\xe8me doit prendre en compte les probl\xe8mes mat\xe9riels qu'on a d\xe9crits, mais il ne doit pas non plus \xeatre compl\xe8tement d\xe9pendant du mat\xe9riel exact sur lequel il tourne pour pouvoir changer le mat\xe9riel. On va donc cr\xe9er une abstraction qui est le ",(0,r.jsx)(n.strong,{children:"system model"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Concernant les consid\xe9rations li\xe9es au temps, on en a 3 :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Synchronous model"})," : on part du principe que les erreurs r\xe9seau, de clock ou les pauses de processus sont limit\xe9s \xe0 certaines valeurs d\xe9finies; En pratique la r\xe9alit\xe9 ne colle pas \xe0 de mod\xe8le."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Partially synchronous model"})," : on part du principe que le syst\xe8me se comporte de mani\xe8re synchrone la plupart du temps, sauf parfois o\xf9 il d\xe9borde. Ce mod\xe8le correspond beaucoup mieux \xe0 nos syst\xe8mes web distribu\xe9s."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Asynchronous model"})," : on est beaucoup plus restrictif puisqu'on consid\xe8re qu'aucune notion de temps ne peut \xeatre fiable. Et donc on ne peut pas utiliser de timeouts non plus."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Concernant les consid\xe9rations li\xe9es aux \xe9checs de noeuds, il y en a aussi 3 :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Crash-stop faults"})," : on consid\xe8re que si un nœud fait une faute, on l'arr\xeate et c'en est fini de lui."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Crash-recovery faults"})," : les nœuds peuvent \xeatre en faute, puis revenir en \xe9tat correct un peu plus tard. C'est ce mod\xe8le qui nous est en g\xe9n\xe9ral le plus utile pour nos syst\xe8mes web."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Byzantine (arbitrary) faults"})," : les nœuds peuvent faire absolument n'importe quoi."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour d\xe9finir qu'un algorithme d'un system model distribu\xe9 est correct, il peut avoir deux types de propri\xe9t\xe9s :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"safety"})," : il s'agit d'une propri\xe9t\xe9 qui dit que rien de mal ne doit se passer. Par exemple, la uniqueness de quelque chose. Si une telle propri\xe9t\xe9 est rompue, c'est parce que chose a \xe9t\xe9 viol\xe9e et qu'il y a eu un dommage non r\xe9parable."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"liveness"})," : il s'agit d'une propri\xe9t\xe9 qui dit qu'une chose attendue doit arriver. Par exemple l'availability, le fait de recevoir une r\xe9ponse. Si une telle propri\xe9t\xe9 est rompue, c'est que ce qui \xe9tait attendu n'a pas eu lieu, mais pourrait avoir lieu plus tard"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Il est courant de demander \xe0 ce que les caract\xe9ristiques de safety soient respect\xe9es dans tous les cas, m\xeame si tous les nœuds crashent, un mauvais r\xe9sultat ne doit pas \xeatre retourn\xe9. Pour les caract\xe9ristiques de liveness, on peut demander \xe0 ce qu'elles soient respect\xe9es seulement dans certains cas, par exemple si un nombre suffisant de nœuds est encore en vie."}),"\n",(0,r.jsxs)(n.li,{children:["Enfin, il faut bien garder en t\xeate qu'un system model n'est qu'un mod\xe8le. Dans la r\xe9alit\xe9, on sera amen\xe9 \xe0 rencontrer des erreurs non pr\xe9vues. Et \xe0 l'inverse, sans raisonnement th\xe9orique, on pourrait avoir des erreurs dans nos syst\xe8mes pendant longtemps sans s'en rendre compte. Les deux sont aussi importants l'un que l'autre.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est la diff\xe9rence entre le computer science (th\xe9orique), et le software engineering (pratique)."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"9---consistency-and-consensus",children:"9 - Consistency and Consensus"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour rendre un syst\xe8me tol\xe9rant aux fautes, il faut introduire des abstractions. C'est ce qu'on a fait avec les transactions par exemple en partant du principe qu'une transaction est atomique. Une autre abstraction int\xe9ressante est le ",(0,r.jsx)(n.strong,{children:"consensus"})," : faire en sorte que les nœuds se mettent d'accord."]}),"\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"consistency"})," est une question importante \xe0 laquelle on peut apporter diff\xe9rents niveaux de garantie. Comme avec l'isolation o\xf9 il s'agissait de traiter la concurrence entre deux transactions, avec la consistance il s'agit de coordonner l'\xe9tat des r\xe9plicas vis-\xe0-vis des d\xe9lais (replication lag) et des fautes."]}),"\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"linearizability"})," consiste en une abstraction qui donne l'illusion que le replication lag n'existe pas, qu'il n'y a en fait qu'une seule copie des donn\xe9es : d\xe8s qu'une copie a \xe9t\xe9 faite, le syst\xe8me doit se comporter comme si cette donn\xe9e la plus r\xe9cente \xe9tait lisible depuis partout.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Une des cons\xe9quences c'est qu'il faut que quand une lecture a \xe9t\xe9 faite avec une valeur, ce soit cette valeur qui soit retourn\xe9e par tous les r\xe9plicas \xe0 partir de ce moment. Si une \xe9criture a lieu entre temps \xe7a peut \xeatre cette nouvelle valeur \xe9crite, mais certainement pas une valeur plus ancienne.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On doit pouvoir \xe9viter le cas o\xf9 une personne recharge la page et voit que le match a \xe9t\xe9 gagn\xe9 par telle \xe9quipe, et juste apr\xe8s une autre personne affiche la page, et voit que le match est toujours en cours."}),"\n",(0,r.jsx)(n.li,{children:"En revanche, il n'y a pas de contraintes de d\xe9lais : si l'\xe9criture prend du temps c'est pas grave. Et si deux transactions sont concurrentes et que l'une arrive avant l'autre c'est pas grave non plus."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Linearizability vs serializability : la serializability est une notion d'isolation pour pouvoir garantir la manipulation de plusieurs objets au sein d'une m\xeame transaction, sans \xeatre g\xean\xe9 par les autres transactions. La linearizability consiste \xe0 renvoyer syst\xe9matiquement le r\xe9sultat le plus r\xe9cent \xe0 chaque lecture une fois que celui-ci a \xe9t\xe9 lu au moins une fois.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le 2-phase locking et l'actual serialization garantissent aussi la linearizability. En revanche la Serializable snapshot isolation ne la garantit pas puisqu'elle va cr\xe9er des snapshots pour les transactions, et ne pas inclure les writes r\xe9cents dans ces snapshots (ce qui peut facilement r\xe9sulter \xe0 ce que certaines transactions aient un write et d'autres pas)."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Parmi les applications de la linearizability :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["L'\xe9lection d'un nouveau leader est un probl\xe8me o\xf9 d\xe8s que le lock a \xe9t\xe9 pris, il faut que personne d'autre ne puisse le prendre.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Apache ZooKeeper"})," et ",(0,r.jsx)(l.U,{children:"etcd"})," sont souvent utilis\xe9s comme syst\xe8me de lock pour impl\xe9menter l'\xe9lection de leader.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Apache Curator"})," ajoute des choses par-dessus ZooKeeper."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Le fait de garantir qu'un nom d'utilisateur ne sera pas pris deux fois, ou encore qu'un compte en banque ne va pas en dessous de 0."}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas o\xf9 on a 2 canaux de communication, l'un des canaux peut \xeatre plus rapide que l'autre : par exemple si on \xe9crit une image, et qu'on enqueue un message pour qu'une version thumbnail de l'image soit g\xe9n\xe9r\xe9e. Si le traitement du message dans la queue est plus rapide que le temps qu'on met \xe0 \xe9crire l'image enti\xe8re, la thumbnail risque d'\xeatre faite \xe0 partir d'un fichier partiel. Il faut donc s'assurer de l'ordre de ce qui est fait dans ces 2 canaux."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La linearizability parmi les syst\xe8mes de r\xe9plication connus :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Single-leader replication : \xe7a pourrait \xeatre linearizable si la BDD n'utilise pas de snapshot isolation. Mais il reste le probl\xe8me de savoir qui est le leader, et dans le cas de r\xe9plication asynchrone on peut perdre des donn\xe9es au failover."}),"\n",(0,r.jsxs)(n.li,{children:["Consensus algorithms : ces algorithmes permettent d'impl\xe9menter la linearizability en r\xe9pondant aux probl\xe8mes soulev\xe9s dans la single-based replication. On va y revenir.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["C'est comme \xe7a que fonctionnent ",(0,r.jsx)(l.U,{children:"ZooKeeper"})," et ",(0,r.jsx)(l.U,{children:"etcd"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Multi-leader replication : ces syst\xe8mes ne sont pas linearizable puisqu'il y a des \xe9critures concurrentes qui sont r\xe9solues apr\xe8s coup."}),"\n",(0,r.jsxs)(n.li,{children:["Leaderless replication : certains affirment qu'en respectant la r\xe8gle du quorum consistency, on peut obtenir une linearizability sur des BDD Dynamo-style. Mais ce n'est en g\xe9n\xe9ral pas vrai.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Riak"})," ne fait pas de read repair \xe0 cause du manque de performance de cette technique, et il la faudrait pour la linearizability."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Cassandra"})," fait le read repair, mais il perd la linearizability \xe0 cause de son algo last write wins qui cause des pertes de donn\xe9es."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Si on part de l'exemple de la multi-leader replication, on constate que c'est pratique parce que si la connexion est rompue entre deux datacenters, les deux peuvent continuer ind\xe9pendamment, et se resynchroniser d\xe8s que la connexion est r\xe9tablie. On a alors une grande availability du syst\xe8me, mais on ne respectera pas la linearizability. A l'inverse si on reste en single-leader, le datacenter d\xe9connect\xe9 du datacenter leader se verra inop\xe9rant jusqu'\xe0 r\xe9tablissement du r\xe9seau. Mais on garde la linearizability.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le CAP theorem d\xe9crit cette probl\xe9matique et a permis en son temps d'ouvrir la discussion, mais il est fondamentalement inutile de nos jours."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Dans la pratique, de nombreuses BDD n'impl\xe9mentent pas la linearizability parce que \xe7a co\xfbte trop cher en performance. Il n'y a malheureusement pas d'algorithme qui permette d'avoir de la linearizability sans ce probl\xe8me de performance qui est d'autant plus grand qu'il y a beaucoup de d\xe9lais dans le r\xe9seau."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Garanties d'ordre d'ex\xe9cution :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"causal consistency"})," (causalit\xe9) est au cœur des probl\xe9matiques des syst\xe8mes distribu\xe9s faisant fonctionner des applications qui ont du sens.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Respecter la causalit\xe9 n'implique pas forc\xe9ment un ",(0,r.jsx)(n.strong,{children:"total order"})," (ordonnancement total) de tous les \xe9l\xe9ments, mais uniquement de ceux li\xe9s entre eux par une relation cause / cons\xe9quence.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La linearizability quant \xe0 elle, implique un total order. Elle est donc une contrainte plus forte que la causal consistency."}),"\n",(0,r.jsx)(n.li,{children:"C'est trop r\xe9cent \xe0 l'\xe9poque du livre pour \xeatre dans des syst\xe8mes en production, mais il y a de la recherche sur des techniques permettant de d\xe9tecter la causalit\xe9 sans total order. Par exemple une g\xe9n\xe9ralisation des version vectors."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La causal consistency co\xfbte quand m\xeame cher s'il faut traquer toutes les transactions et leurs relations. On peut sinon utiliser des ",(0,r.jsx)(n.strong,{children:"sequence numbers"})," pour cr\xe9er un clock logique permettant de d\xe9finir un ordre total.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Sur une configuration single-leader, il suffit d'incr\xe9menter un compteur \xe0 chaque op\xe9ration au niveau du leader."}),"\n",(0,r.jsxs)(n.li,{children:["Dans le cas o\xf9 il y a plusieurs leaders, on a d'autres solutions:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"G\xe9n\xe9rer des sequence numbers diff\xe9rents pour chaque nœud (par exemple pair pour l'un, impairs pour l'autre)."}),"\n",(0,r.jsx)(n.li,{children:"Utiliser un clock physique."}),"\n",(0,r.jsx)(n.li,{children:"Allouer des plages \xe0 chaque nœud, par exemple 0 \xe0 1000 pour l'un, 1000 \xe0 2000 pour l'autre etc."}),"\n",(0,r.jsx)(n.li,{children:"Malheureusement certains nœuds peuvent aller plus vite que d'autres, et ces techniques ne garantissent pas la causalit\xe9 dans le syst\xe8me."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La causalit\xe9 peut \xeatre assur\xe9e dans un environnement multi-leader gr\xe2ce aux ",(0,r.jsx)(n.strong,{children:"Lamport timestamps"}),". Il s'agit d'une id\xe9e de Leslie Lamport dans un des papiers les plus cit\xe9s des syst\xe8mes distribu\xe9s.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le principe est d'avoir un compteur normal par nœud, et pour le rendre unique on l'associe \xe0 un chiffre repr\xe9sentant le nœud lui-m\xeame. Et l'astuce de la technique consiste \xe0 ce que chaque nœud et chaque client garde en m\xe9moire la valeur la plus \xe9lev\xe9e de compteur qu'il connaisse. Et quand il a connaissance de la valeur d'un autre compteur plus \xe9lev\xe9 que celui qu'il connaissait au d\xe9tour d'une op\xe9ration, il met imm\xe9diatement \xe0 jour le compteur du nœud sur lequel il fera la prochaine op\xe9ration avec cette valeur-l\xe0."}),"\n",(0,r.jsx)(n.li,{children:"Cette technique permet de respecter la causalit\xe9, mais aussi un total ordering."}),"\n",(0,r.jsxs)(n.li,{children:["Malheureusement \xe7a ne r\xe8gle pas tous nos probl\xe8mes : m\xeame avec un total order, on ne peut pas savoir sur le moment si un nom d'utilisateur unique est en passe d'\xeatre pris par un autre nœud ou non pour savoir sur le moment s'il faut l'autoriser soi-m\xeame ou non. Avec le temps et les op\xe9rations, on finira par avoir un ordonnancement total, mais pour le moment non.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est l'objet du total order broadcast."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"total order broadcast"})," n\xe9cessite qu'aucun message ne soit perdu, et que tous les messages soient d\xe9livr\xe9s \xe0 tous les nœuds dans le m\xeame ordre.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La connexion peut \xeatre interrompue, mais les algorithmes de total order broadcast doivent r\xe9essayer et r\xe9tablir l'ordre des messages dans tous les nœuds quand le r\xe9seau est r\xe9tabli."}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"ZooKeeper"})," et ",(0,r.jsx)(l.U,{children:"etcd"})," impl\xe9mentent le total order broadcast."]}),"\n",(0,r.jsx)(n.li,{children:"A noter aussi que le total order broadcast maintient l'ordre tel qu'il est au moment de l'\xe9mission des messages, donc c'est plus fort que le timestamp ordering."}),"\n",(0,r.jsx)(n.li,{children:"On peut voir \xe7a comme un log de messages transmis \xe0 tous les nœuds dans le bon ordre."}),"\n",(0,r.jsxs)(n.li,{children:["On peut ainsi impl\xe9menter la linearizability \xe0 partir d'un syst\xe8me respectant le total order broadcast.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour l'\xe9criture :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On ajoute un message au log disant qu'on voudrait \xe9crire"}),"\n",(0,r.jsx)(n.li,{children:"On lit le log et on attend que notre message nous parvienne"}),"\n",(0,r.jsx)(n.li,{children:"Si le premier message concernant ce sur quoi on voulait \xe9crire est le n\xf4tre, alors on peut valider l'\xe9criture dans le log."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour la lecture :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut faire pareil qu'avec l'\xe9criture : ajouter un message indiquant qu'on veut lire, attendre de le recevoir, puis faire la lecture en fonction de l'ordre indiqu\xe9 dans le log.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["C'est comme \xe7a que \xe7a marche dans les ",(0,r.jsx)(n.em,{children:"quorum reads"}),", dans ",(0,r.jsx)(l.U,{children:"etcd"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut demander \xe0 avoir tous les messages de log li\xe9s \xe0 une lecture puis faire la lecture \xe0 partir de l\xe0.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["C'est comme \xe7a que fonctionne la fonction ",(0,r.jsx)(n.em,{children:"sync()"})," de ",(0,r.jsx)(l.U,{children:"ZooKeeper"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"On peut lire \xe0 partir d'un r\xe9plica synchrone avec le leader (en cas de single-leader), dont on est s\xfbr qu'il a les donn\xe9es les plus r\xe9centes."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"A l'inverse, on peut aussi impl\xe9menter un syst\xe8me total order broadcast \xe0 partir d'un syst\xe8me lin\xe9arisable : il suffit d'avoir un compteur lin\xe9arisable qu'on attache \xe0 chaque message envoy\xe9 via total order broadcast."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"On peut enfin noter qu'\xe0 la fois la linearizability et le total order broadcast sont tous deux \xe9quivalents au consensus."})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"consensus"})," consiste en la possibilit\xe9 pour les nœuds de se mettre d'accord sur quelque chose (on pense par exemple \xe0 l'\xe9lection de leader, ou \xe0 l'",(0,r.jsx)(n.em,{children:"atomic commit problem"})," o\xf9 il faut choisir entre garder ou non une transaction pr\xe9sente sur certains nœuds), alors m\xeame que des noeuds peuvent \xeatre en faute \xe0 tout moment.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est un sujet tr\xe8s subtil et complexe."}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"Le FLP result"})," est un r\xe9sultat th\xe9orique montrant que le consensus est impossible dans un system model asynchrone. Dans la pratique, \xe0 l'aide de timeouts (m\xeame s'ils peuvent \xeatre parfois faussement positifs), on arrive \xe0 atteindre le consensus."]}),"\n",(0,r.jsx)(n.li,{children:"Quand une transaction est \xe9crite en BDD, il est hors de question de la retirer par la suite parce qu'elle a pu \xeatre prise en compte par d'autres transactions. Il faut donc bien r\xe9fl\xe9chir avant d'entrer d\xe9finitivement l'\xe9criture en BDD."}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"two-phase commit (2PC)"})," est un algorithme de consensus impl\xe9ment\xe9 dans certaines BDD.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["2PC n'est pas tr\xe8s bon, des algorithmes plus modernes existent chez ",(0,r.jsx)(l.U,{children:"ZooKeeper"})," (",(0,r.jsx)(n.strong,{children:"Zab"}),") et ",(0,r.jsx)(l.U,{children:"etcd"})," (",(0,r.jsx)(n.strong,{children:"Raft"}),")."]}),"\n",(0,r.jsx)(n.li,{children:"Attention \xe0 ne pas confondre 2PC avec 2PL (2 phase lock) qui permet l'isolation pour la s\xe9rialisation, le mieux est d'ignorer le rapprochement de leur nom."}),"\n",(0,r.jsxs)(n.li,{children:["Fonctionnement :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["on a besoin d'un nouveau composant : le ",(0,r.jsx)(n.strong,{children:"coordinator"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Lors d'une transaction, apr\xe8s les lectures / \xe9critures, quand on veut inscrire vraiment tout \xe7a en BDD, le coordinator va proc\xe9der en 2 \xe9tapes :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"demander successivement \xe0 chaque nœud si il est pr\xeat \xe0 faire un commit et attendre leur r\xe9ponse."}),"\n",(0,r.jsx)(n.li,{children:"si oui, faire le commit, sinon annuler la transaction."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"L'id\xe9e c'est que lors de la 1\xe8re phase, quand le coordinator demande si les nœuds sont pr\xeats, en fait il leur demande aussi de tout pr\xe9parer pour que m\xeame en cas de crash rien ne soit perdu de leur c\xf4t\xe9. La seule chose qui leur resterait \xe0 faire alors serait de valider les donn\xe9es d\xe9j\xe0 mises en forme pour aller dans la BDD."}),"\n",(0,r.jsx)(n.li,{children:"Lorsque le coordinator prend sa d\xe9cision finale de faire s'ex\xe9cuter ou d'annuler la transaction en phase 2, alors il l'\xe9crit localement et passe un point de non-retour. A partir de l\xe0 il r\xe9essayera en permanence de faire finaliser la transaction aupr\xe8s de tout nœud qui deviendrait indisponible \xe0 partir de ce moment-l\xe0."}),"\n",(0,r.jsxs)(n.li,{children:["Dans le cas o\xf9 le coordinator crash juste apr\xe8s avoir demand\xe9 aux noeuds de se pr\xe9parer fait que les noeuds doivent rester en attente. Ils ne peuvent pas unilat\xe9ralement prendre de d\xe9cision de valider ou annuler une transaction chacun de leur c\xf4t\xe9. La solution est d'attendre que le coordinator revienne, lise ce qu'il avait d\xe9cid\xe9 sur son fichier de log, et envoie les messages qui conviennent.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il existe un autre algorithme appel\xe9 3-phase commit (3PC) qui r\xe9sout le probl\xe8me de l'aspect bloquant li\xe9 \xe0 l'attente du commit du coordinator, mais il implique des temps de r\xe9seaux born\xe9s. Or nos r\xe9seaux habituels sont impr\xe9visibles. Pour cette raison, c'est le 2PC qui continue d'\xeatre utilis\xe9."}),"\n",(0,r.jsx)(n.li,{children:"Le souci de ce cas c'est surtout le lock au niveau de la BDD, souvient sur les entr\xe9es concern\xe9es par la transaction. Si le coordinator ne revient jamais ou que les logs sont perdus, alors on peut se retrouver face \xe0 des locks orphelins, et un administrateur humain devra manuellement r\xe9soudre ces conflits, puisque les locks sont cens\xe9s survivre m\xeame \xe0 un red\xe9marrage de la BDD."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["En pratique, les transactions distribu\xe9es sont souvent d\xe9cri\xe9es parce qu'elles co\xfbteraient trop par rapport \xe0 ce qu'elles apporteraient.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les transactions distribu\xe9es utilisant MySQL sont connues pour \xeatre 10 fois plus lentes que les m\xeames transactions sur un seul nœud."}),"\n",(0,r.jsx)(n.li,{children:"Il y a deux types de transactions distribu\xe9es : celles qui sont impl\xe9ment\xe9es par une m\xeame BDD qui tourne sur plusieurs nœuds, et celles qui consistent \xe0 faire communiquer des technologies h\xe9t\xe9rog\xe8nes d'un nœud \xe0 un autre. Les derni\xe8res sont bien plus compliqu\xe9es."}),"\n",(0,r.jsxs)(n.li,{children:["Les transactions h\xe9t\xe9rog\xe8nes peuvent faire communiquer par exemple une BDD et un message broker, et ne commiter que si tout a march\xe9, et annuler tout sinon.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"XA (eXtended Architecture)"})," est justement un protocole qui permet d'impl\xe9menter le 2PC dans des technologies h\xe9t\xe9rog\xe8nes. Il s'agit d'une API en C qui se connecte aux programmes qui s'ex\xe9cutent sur une machine.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il est support\xe9 par de nombreuses BDD : ",(0,r.jsx)(l.U,{children:"PostgreSQL"}),", ",(0,r.jsx)(l.U,{children:"MySQL"}),", ",(0,r.jsx)(l.U,{children:"DB2"}),", ",(0,r.jsx)(l.U,{children:"SQL Server"}),", ",(0,r.jsx)(l.U,{children:"Oracle"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Et par plein de message brokers : ",(0,r.jsx)(l.U,{children:"ActiveMQ"}),", ",(0,r.jsx)(l.U,{children:"HornetQ"}),", ",(0,r.jsx)(l.U,{children:"MSMQ"}),", ",(0,r.jsx)(l.U,{children:"IBM MQ"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"XA a cependant des limitations, par exemple il ne permet pas de d\xe9tecter les deadlocks, et ne supporte pas le SSI (serializable snapshot isolation)."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Il faut noter quand m\xeame que le coordinateur est souvent un single point of failure vu qu'il contient lui-m\xeame des donn\xe9es persistantes cruciales pour le fonctionnement du syst\xe8me. Mais \xe9tonnamment les possibilit\xe9s de le rendre r\xe9plicable sont en g\xe9n\xe9ral rudimentaires."}),"\n",(0,r.jsx)(n.li,{children:"2PC a quand m\xeame un point probl\xe9matique aussi, c'est qu'il a tendance \xe0 amplifier les failures, puisque d\xe8s qu'un nœud ne r\xe9pond pas on va annuler la transaction. C'est pas tr\xe8s “fault tolerant” tout \xe7a."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le consensus tol\xe9rant les fautes :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut citer 4 propri\xe9t\xe9s d\xe9finissant le consensus :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["3 de safety :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Uniform agreement : tous les nœuds doivent arriver au m\xeame choix."}),"\n",(0,r.jsx)(n.li,{children:"Integrity : aucun nœud ne d\xe9cide deux fois."}),"\n",(0,r.jsx)(n.li,{children:"Validity : le choix d\xe9cid\xe9 est valide."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Et une de liveness :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Termination : les nœuds ne se retrouvent pas bloqu\xe9s, m\xeame en cas de crash de certains d'entre eux. Ils \xe9voluent vers la terminaison du processus de choix.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"2PC ne remplit pas cette condition puisque le coordinator peut bloquer le syst\xe8me en cas de faute."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les algorithmes de consensus tol\xe9rants aux fautes sont difficiles \xe0 impl\xe9menter (donc on ne va pas les impl\xe9menter nous-m\xeames mais utiliser des outils qui les impl\xe9mentent).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ce sont les suivants :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Viewstamped replication (VSR)"}),"\n",(0,r.jsx)(n.li,{children:"Paxos"}),"\n",(0,r.jsx)(n.li,{children:"Raft"}),"\n",(0,r.jsx)(n.li,{children:"Zab"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Ces algorithmes sont de type total order broadcast."}),"\n",(0,r.jsx)(n.li,{children:"A chaque tour les nœuds d\xe9cident du prochain message \xe0 traiter, et d\xe9cident par consensus."}),"\n",(0,r.jsx)(n.li,{children:"Pour le remplacement des leaders les nœuds utilisent des timeouts, et lancent une \xe9lection avec un quorum. Et c'est seulement quand le nœud a bien re\xe7u le message de la majorit\xe9 qu'il sait qu'il est bien le leader."}),"\n",(0,r.jsx)(n.li,{children:"Ces algorithmes sont encore un sujet de recherche, et ont parfois des edge cases probl\xe9matiques qui basculent le leader entre 2 nœuds, ou qui forcent en permanence le leader \xe0 renoncer."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Services de coordination :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les services comme ",(0,r.jsx)(l.U,{children:"ZooKeeper"})," sont rarement utilis\xe9s directement par les d\xe9veloppeurs. On va plut\xf4t les utiliser \xe0 travers d'autres services comme ",(0,r.jsx)(l.U,{children:"HBase"}),", ",(0,r.jsx)(l.U,{children:"Hadoop YARN"}),", ",(0,r.jsx)(l.U,{children:"OpenStack Nova"})," et ",(0,r.jsx)(l.U,{children:"Kafka"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Ce sont en gros des stores de cl\xe9-valeur qui tiennent en RAM."}),"\n",(0,r.jsxs)(n.li,{children:["ZooKeeper a notamment ces caract\xe9ristiques :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Linearizable atomic operations"})," : \xe0 l'aide d'un lock, une seule op\xe9ration parmi les op\xe9rations concurrentes peut r\xe9ussir."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Total ordering of operations"})," : les fencing tokens permettent de pr\xe9server l'ordre des transactions."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Failure detection"})," : les nœuds ZooKeeper et les autres nœuds s'envoient des messages r\xe9guli\xe8rement, et en cas de timeout d\xe9clarent le nœud \xe9chou\xe9."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Change notifications"})," : les clients (les autres nœuds) peuvent s'abonner \xe0 des changements sp\xe9cifiques des autres nœuds \xe0 travers ZooKeeper, ce qui \xe9vite de faire des requ\xeates pour voir o\xf9 \xe7a en est."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"ZooKeeper"})," est pratique pour des informations qui changent toutes les minutes ou heures comme l'association d'une adresse ip \xe0 un leader.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Si on veut r\xe9pliquer l'\xe9tat d'une application qui peut n\xe9cessiter des milliers ou millions de changements par seconde, on peut utiliser des outils comme ",(0,r.jsx)(l.U,{children:"Apache BookKeeper"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"ZooKeeper"})," fait partie des membership services, issu d'une longue recherche depuis les ann\xe9es 80. En couplant le consensus avec la d\xe9tection de fautes, ils permettent d'arriver \xe0 une certaine connaissance de qui composent les membres du r\xe9seau."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Int\xe9grer des syst\xe8mes disparates ensemble est l'une des choses les plus importantes \xe0 faire dans une application non triviale."}),"\n",(0,r.jsxs)(n.li,{children:["Les donn\xe9es sont souvent class\xe9es en 2 cat\xe9gories qu'il est de bon ton d'expliciter :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"systems of record"})," qui sont les donn\xe9es de r\xe9f\xe9rence."]}),"\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"derived data systems"})," qui sont en g\xe9n\xe9ral des donn\xe9es d\xe9normalis\xe9es, par exemple stock\xe9es dans un cache."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"10---batch-processing",children:"10 - Batch Processing"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il existe 3 types de syst\xe8mes :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Services (online systems)"})," : un client envoie un message et re\xe7oit une r\xe9ponse. En g\xe9n\xe9ral, le temps de r\xe9ponse et la disponibilit\xe9 (availability) sont tr\xe8s importants."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Batch processing systems (offline systems)"})," : des t\xe2ches de fond, souvent ex\xe9cut\xe9es p\xe9riodiquement, durant plusieurs minutes voire plusieurs jours. La performance se mesure par la quantit\xe9 de donn\xe9es trait\xe9es."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Stream processing systems (near-real-time systems)"})," : il s'agit d'une forme particuli\xe8re de batch processing. On ne r\xe9pond pas \xe0 une requ\xeate d'un client humain, mais on r\xe9agit \xe0 un \xe9v\xe9nement assez rapidement apr\xe8s qu'il ait eu lieu."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le batch processing avec les outils Unix :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["L'outil ",(0,r.jsx)(n.em,{children:"sort"})," d'Unix va automatiquement prendre en charge des donn\xe9es plus grandes qu'il n'y a de m\xe9moire vive, mettre \xe7a en disque pour faire les op\xe9rations, et parall\xe9liser au niveau CPU."]}),"\n",(0,r.jsx)(n.li,{children:"La philosophie unix est tr\xe8s proche de l'agile et du devops. On casse les gros probl\xe8mes en petits, on fait de petits programmes qui font une chose et la font bien. On fait des it\xe9rations courtes."}),"\n",(0,r.jsx)(n.li,{children:"Une des cl\xe9s de la puissance des outils unix est l'interface uniforme, permettant de les composer ensemble. De nos jours c'est plut\xf4t l'exception que la norme parmi les programmes."}),"\n",(0,r.jsx)(n.li,{children:"On a \xe9galement une s\xe9paration entre la logique et le c\xe2blage des donn\xe9es gr\xe2ce \xe0 stdin et stdout."}),"\n",(0,r.jsxs)(n.li,{children:["Les outils unix sont tr\xe8s pratiques pour l'exp\xe9rimentation : les entr\xe9es sont immuables, et on peut envoyer la sortie vers un ",(0,r.jsx)(n.em,{children:"less"})," par exemple."]}),"\n",(0,r.jsx)(n.li,{children:"Mais le plus souci c'est que les outils unix ne marchent que sur une machine, pas sur des architectures distribu\xe9es."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["MapReduce est un mod\xe8le assez bas niveau de batch processing, connu pour \xeatre l'algorithme qui permet \xe0 Google d'\xeatre aussi scalable.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il ressemble aux outils unix mais sur des architectures distribu\xe9es."}),"\n",(0,r.jsx)(n.li,{children:"Il prend des inputs, et envoie le r\xe9sultat dans des outputs."}),"\n",(0,r.jsx)(n.li,{children:"Les inputs ne sont normalement pas modifi\xe9s et il n'y a pas de side-effects autre que les outputs."}),"\n",(0,r.jsx)(n.li,{children:"Les fichiers d'output sont \xe9crits de mani\xe8re s\xe9quentielle."}),"\n",(0,r.jsxs)(n.li,{children:["Alors que les outils unix \xe9crivent dans stdout, MapReduce \xe9crit dans un syst\xe8me de fichiers distribu\xe9s.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Hadoop"})," utilise ",(0,r.jsx)(n.strong,{children:"HDFS (Hadoop distributed File System)"}),", qui est une impl\xe9mentation open source de Google File System."]}),"\n",(0,r.jsx)(n.li,{children:"Il en existe d'autres comme GlusterFS, Quantcast File System (QFS)."}),"\n",(0,r.jsx)(n.li,{children:"D'autres services sont similaires : Amazon S3, Azure Blob Storage, OpenStack Shift."}),"\n",(0,r.jsxs)(n.li,{children:["Fonctionnement de HDFS :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"HDFS est bas\xe9 sur une approche shared-nothing, c'est-\xe0-dire qu'il lui suffit d'ordinateurs connect\xe9s par un r\xe9seau ip classique."}),"\n",(0,r.jsx)(n.li,{children:"Un d\xe9mon tourne sur chaque nœud et expose les fichiers qui sont sur ce nœud. Et un serveur central appel\xe9 NameNode contient des r\xe9f\xe9rences vers ces fichiers."}),"\n",(0,r.jsx)(n.li,{children:"Il y a de la r\xe9plication entre les nœuds."}),"\n",(0,r.jsx)(n.li,{children:"De cette mani\xe8re HDFS est capable de faire fonctionner des dizaines de milliers de machines et des petabytes de donn\xe9es."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le fonctionnement se fait en 4 \xe9tapes :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["1- On lit des fichiers et on les structure sous forme d'entr\xe9es.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est le parser qui s'en charge."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["2- on appelle la fonction ",(0,r.jsx)(n.em,{children:"mapper"})," pour extraire des cl\xe9s-valeurs","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il s'agit ici d'une fonction o\xf9 on peut ajouter du code \xe0 nous. La fonction est appel\xe9e une fois par entr\xe9e et permet d'extraire de la mani\xe8re souhait\xe9e les cl\xe9s-valeurs."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["3- on trie les cl\xe9s-valeurs par cl\xe9s","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est fait automatiquement."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["4- on appelle la fonction ",(0,r.jsx)(n.em,{children:"reducer"})," pour faire notre action sur les cl\xe9s-valeurs","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L\xe0 encore on peut ajouter du code \xe0 nous. On a en param\xe8tre toutes les valeurs associ\xe9es \xe0 une cl\xe9 et on peut en faire ce qu'on veut en sortie."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"On peut aussi encha\xeener plusieurs MapReduce, l'un pr\xe9parant les donn\xe9es en entr\xe9e pour l'autre."}),"\n",(0,r.jsx)(n.li,{children:"MapReduce permet aussi de parall\xe9liser les op\xe9rations de mani\xe8re transparente pour le code. Comme il y a de nombreuses entr\xe9es \xe0 traiter, chacune peut s'ex\xe9cuter localement sur la machine du r\xe9plica o\xf9 elle est. Cela permet aussi d'\xe9viter les transferts r\xe9seau en localisant les calculs."}),"\n",(0,r.jsxs)(n.li,{children:["Concernant le code custom des fonctions mapper et reducer, dans ",(0,r.jsx)(l.U,{children:"Hadoop"})," elles sont \xe9crites en Java, alors que dans ",(0,r.jsx)(l.U,{children:"MongoDB"})," et ",(0,r.jsx)(l.U,{children:"CouchDB"})," elles sont \xe9crites en Javascript."]}),"\n",(0,r.jsxs)(n.li,{children:["Contrairement aux outils Unix, MapReduce ne permet pas de cha\xeener directement ses jobs. Il faut plut\xf4t \xe9crire le r\xe9sultat d'un job dans un dossier, puis donner ce dossier comme entr\xe9e au MapReduce suivant. C'est du moins comme \xe7a que \xe7a se passe dans ",(0,r.jsx)(l.U,{children:"Hadoop"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Du coup tout un tas d'outils permettent de coordonner les jobs MapReduce dans Hadoop : ",(0,r.jsx)(l.U,{children:"Oozie"}),", ",(0,r.jsx)(l.U,{children:"Azkaban"}),", ",(0,r.jsx)(l.U,{children:"Luigi"}),", ",(0,r.jsx)(l.U,{children:"Airflow"}),", ",(0,r.jsx)(l.U,{children:"Pinball"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["D'autres outils haut niveau autour de Hadoop permettent \xe9galement de g\xe9rer ce genre de choses : ",(0,r.jsx)(l.U,{children:"Pig"}),", ",(0,r.jsx)(l.U,{children:"Hive"}),", ",(0,r.jsx)(l.U,{children:"Cascading"}),", ",(0,r.jsx)(l.U,{children:"Crunch"}),", ",(0,r.jsx)(l.U,{children:"FlumeJava"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos des ",(0,r.jsx)(n.strong,{children:"reduce-side joins"})," avec MapReduce :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On ne va envisager les jointures que sur des tables enti\xe8res pour notre cas qui concerne les batchs, typiquement quand on traite des BDD destin\xe9es \xe0 l'analyse des donn\xe9es."}),"\n",(0,r.jsx)(n.li,{children:"Par exemple : si on a d'un c\xf4t\xe9 des \xe9v\xe9nements avec un user id, et de l'autre c\xf4t\xe9 la table des users avec certaines de leurs caract\xe9ristiques. On va vouloir corr\xe9ler les deux pour ne s\xe9lectionner que les faits d'un certain type d'utilisateurs."}),"\n",(0,r.jsx)(n.li,{children:"Pour des raisons de performance, on va opter pour le plus de localit\xe9 possible, et donc on ne va pas faire des acc\xe8s random en traitant chaque entr\xe9e une par une l\xe0 o\xf9 elle est. On va plut\xf4t copier la table des users dans le m\xeame filesystem HDFS que la table des faits, puis on va lire les deux conjointement."}),"\n",(0,r.jsxs)(n.li,{children:["La technique des ",(0,r.jsx)(n.strong,{children:"sort-merge joins"})," permet \xe0 plusieurs mappers de trier des donn\xe9es par la m\xeame cl\xe9 (par exemple l'id de l'utilisateur pour des \xe9v\xe9nements dont il est l'objet, et pour des donn\xe9es personnelles sur l'utilisateur), puis \xe0 un reducer de r\xe9cup\xe9rer ces donn\xe9es et de les merger ensemble pour faire l'action qu'on voulait avec cette jointure.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Une fois que les mappers ont fait leur travail, chaque cl\xe9 agit comme une adresse au sens o\xf9 les valeurs d'une m\xeame cl\xe9 vont \xeatre envoy\xe9es au m\xeame nœud pour que le reducer soit ex\xe9cut\xe9 avec ces valeurs-l\xe0. Il y a bien une localit\xe9 des donn\xe9es pour l'ex\xe9cution du traitement."}),"\n",(0,r.jsx)(n.li,{children:"D'une certaine mani\xe8re on a s\xe9par\xe9 l'obtention des donn\xe9es du traitement des donn\xe9es, ce qui contraste avec la plupart des applications o\xf9 on fait des requ\xeates en BDD en plein milieu du code."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Dans certains cas on peut se retrouver avec des ",(0,r.jsx)(n.em,{children:"hot keys"})," par exemple des donn\xe9es li\xe9es aux followers de c\xe9l\xe9brit\xe9s. Ceci peut donner trop de charge \xe0 un nœud de reducer, et les autres devront alors l'attendre pour que l'op\xe9ration de MapReduce soit termin\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour \xe9viter \xe7a on va d\xe9tecter les hot keys et les traiter diff\xe9remment des autres cl\xe9s. On va les s\xe9parer dans plusieurs reducers diff\xe9rents sur plusieurs nœuds, et ensuite on fusionnera le r\xe9sultat final.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Pig"})," fait d'abord une op\xe9ration pour d\xe9terminer les hot keys, et ensuite fait le traitement de la mani\xe8re d\xe9crite."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Crunch"})," a besoin qu'on lui dise explicitement les hot keys."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Hive"})," a aussi besoin que les hot keys soient sp\xe9cifi\xe9s explicitement dans une table de metadata s\xe9par\xe9e."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos des ",(0,r.jsx)(n.strong,{children:"map-side joins"})," :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les reduce-side joins sont pratiques parce que les mappers lisent les donn\xe9es quelles qu'elles soient, pr\xe9parent, trient et donnent \xe7a aux reducers. Mais tout ceci co\xfbte en terme de copies au niveau du DD.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si nous avons des informations sur la structure des donn\xe9es, nous pouvons faire des map-side joins, o\xf9 il s'agit simplement de tout faire dans les mappers et se d\xe9barrasser des reducers."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Un cas o\xf9 c'est utile est quand on doit faire une jointure entre un grand dataset et un petit dataset, suffisamment petit pour que \xe7a puisse \xeatre charg\xe9 dans la RAM de chaque mapper. Chaque mapper aura alors \xe0 disposition l'ensemble du petit dataset pour chercher les entr\xe9es qui l'int\xe9ressent.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On appelle cet algorithme le ",(0,r.jsx)(n.strong,{children:"broadcast hash join"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Cette m\xe9thode est support\xe9e par ",(0,r.jsx)(l.U,{children:"Pig"}),", ",(0,r.jsx)(l.U,{children:"Hive"}),", ",(0,r.jsx)(l.U,{children:"Cascading"})," et ",(0,r.jsx)(l.U,{children:"Crunch"}),", ainsi que la data warehouse ",(0,r.jsx)(l.U,{children:"Impala"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas o\xf9 on a deux tables partitionn\xe9es de la m\xeame mani\xe8re et qu'on veut faire une jointure dessus, on peut faire le map-side join sur chacune des partitions, ce qui permet de ne charger en m\xe9moire qu'une faible quantit\xe9 de donn\xe9es."}),"\n",(0,r.jsx)(n.li,{children:"Si les deux datasets sont en plus tri\xe9s selon la m\xeame cl\xe9, alors on n'a pas besoin que l'une des deux entre en m\xe9moire. Les mappers pourront chercher les donn\xe9es qui les int\xe9ressent du fait qu'elles sont tri\xe9es de la m\xeame mani\xe8re."}),"\n",(0,r.jsx)(n.li,{children:"Le choix d'un map-side join ou d'un reduce-side join a un impact sur les donn\xe9es r\xe9sultant du MapReduce : avec le map-side les donn\xe9es seront partitionn\xe9es de la m\xeame mani\xe8re qu'elles l'\xe9taient \xe0 l'input, alors qu'avec le reduce-side, les donn\xe9es seront partitionn\xe9es selon la cl\xe9 de la jointure."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le batch se rapprocherait plus des OLAP que des OLTP dans la mesure o\xf9 il scanne une grande quantit\xe9 de donn\xe9es, mais le r\xe9sultat d'un batch sera une forme de structure et non pas un rapport \xe0 destination de data analysts.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Un exemple de batch est l'utilisation initiale de MapReduce par Google pour faire des indexes pour son moteur de recherche. Encore aujourd'hui MapReduce est un bon moyen de cr\xe9er des indexes pour ",(0,r.jsx)(l.U,{children:"Lucene"})," / ",(0,r.jsx)(l.U,{children:"Solr"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Un autre exemple est de construire des BDD key-value pour du machine learning, ou pour des syst\xe8mes de recommandation.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On pourrait penser que la bonne solution serait d'orienter la sortie du MapReduce vers notre BDD, entr\xe9e par entr\xe9e, mais c'est une mauvaise id\xe9e, \xe0 la fois pour des raisons de performance (localit\xe9 des donn\xe9es, pas d'utilisation r\xe9seau, parall\xe9lisation des t\xe2ches) et d'atomicit\xe9 du batch job."}),"\n",(0,r.jsxs)(n.li,{children:["La bonne solution consiste plut\xf4t \xe0 cr\xe9er une toute nouvelle BDD sur le filesystem distribu\xe9, de la m\xeame mani\xe8re qu'on cr\xe9e le fichier d'index.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Plusieurs syst\xe8mes de BDD supportent le fait de cr\xe9er des fichiers de BDD \xe0 partir d'op\xe9rations MapReduce : ",(0,r.jsx)(l.U,{children:"Voldemort"}),", ",(0,r.jsx)(l.U,{children:"Terrapin"}),", ",(0,r.jsx)(l.U,{children:"ElephantDB"}),", ",(0,r.jsx)(l.U,{children:"HBase"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Ces fichiers sont \xe9crits une fois et demeurent ensuite read-only."}),"\n",(0,r.jsx)(n.li,{children:"Les syst\xe8mes de BDD qui les supportent vont servir les anciennes donn\xe9es, commencer \xe0 copier ce fichier depuis le filesystem distribu\xe9 vers le disque local, et d\xe8s que c'est fait switcher vers le fait de servir ces donn\xe9es-l\xe0."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["MapReduce suit la philosophie Unix :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut rejouer une op\xe9ration MapReduce autant de fois qu'on veut sans dommages pour les donn\xe9es d'entr\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si les donn\xe9es sont corrompues pour une raison \xe9ph\xe9m\xe8re, on retente l'op\xe9ration."}),"\n",(0,r.jsx)(n.li,{children:"Si c'est un bug logiciel, on le r\xe9sout, et on refait la m\xeame op\xe9ration encore."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"On a une s\xe9paration de la logique, et du c\xe2blage pour d\xe9cider o\xf9 vont les donn\xe9es."}),"\n",(0,r.jsxs)(n.li,{children:["Par contre l\xe0 o\xf9 les outils unix font beaucoup de parsing parce que le format est le texte, ",(0,r.jsx)(l.U,{children:"Hadoop"})," et compagnie peuvent utiliser ",(0,r.jsx)(l.U,{children:"Avro"})," et ",(0,r.jsx)(l.U,{children:"Parquet"})," pour permettre une \xe9volutivit\xe9 des sch\xe9mas."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Comparaison entre Hadoop et les BDD distribu\xe9es :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les BDD distribu\xe9es impl\xe9mentant le ",(0,r.jsx)(n.em,{children:"massively parallel processing (MPP)"})," avaient d\xe9j\xe0 la capacit\xe9 de faire des jointures distribu\xe9es en parall\xe8le depuis 10 ans quand MapReduce est sorti. La diff\xe9rence c'est qu'elles obligent les donn\xe9es \xe0 respecter un sch\xe9ma pr\xe9d\xe9fini."]}),"\n",(0,r.jsxs)(n.li,{children:["Par contraste, le mod\xe8le MapReduce a permis de collecter n'importe quelles donn\xe9es, y compris du texte, des images etc. et de les mettre tels quels, transf\xe9rant alors le probl\xe8me de l'interpr\xe9tation de ces donn\xe9es au consommateur.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\xc7a s'appelle le ",(0,r.jsx)(n.em,{children:"sushi principle"})," : raw data is better. Et \xe7a permet par exemple de consommer la m\xeame donn\xe9e diff\xe9remment selon les contextes."]}),"\n",(0,r.jsx)(n.li,{children:"On peut par exemple collecter les donn\xe9es, et dans une \xe9tape s\xe9par\xe9e utiliser un MapReduce pour r\xe9organiser ces donn\xe9es de mani\xe8re \xe0 les transformer en data warehouse."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les BDD MPP sont efficaces pour le cas d'utilisation qu'elles pr\xe9voient : la manipulation des donn\xe9es via des requ\xeates SQL. En outre, \xe7a fournit un bon niveau d'abstraction pour ne pas avoir \xe0 \xe9crire de code.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"D'un autre c\xf4t\xe9, tout ne peut pas \xeatre trait\xe9 avec des requ\xeates SQL. Si on a des utilisations particuli\xe8res comme du machine learning, des syst\xe8mes de recommandation, de recherche dans du texte etc. alors on a probablement besoin d'ex\xe9cuter du code custom sur ces donn\xe9es. C'est ce que permet MapReduce."}),"\n",(0,r.jsxs)(n.li,{children:["Si on a MapReduce, on peut construire un mod\xe8le SQL par dessus. C'est ce qu'a fait ",(0,r.jsx)(l.U,{children:"Hive"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La versatilit\xe9 permise par les raw data dans du ",(0,r.jsx)(l.U,{children:"Hadoop"})," permettent d'impl\xe9menter du SQL, du MapReduce, mais aussi d'autres mod\xe8les encore.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On a des BDD OLTP comme ",(0,r.jsx)(l.U,{children:"HBase"})]}),"\n",(0,r.jsxs)(n.li,{children:["On a des BDD analytiques comme ",(0,r.jsx)(l.U,{children:"Impala"})]}),"\n",(0,r.jsx)(n.li,{children:"Les deux utilisent HDFS mais pas MapReduce."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Deux autres diff\xe9rences :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La mani\xe8re de g\xe9rer les fautes n'est pas la m\xeame : les syst\xe8mes MPP annulent la requ\xeate en cas de faute, alors que MapReduce va annuler une partie du job, peut \xeatre le mapper ou le reducer, et r\xe9essayer pour le terminer."}),"\n",(0,r.jsx)(n.li,{children:"La gestion de la m\xe9moire n'est pas la m\xeame : les syst\xe8mes MPP vont avoir tendance \xe0 stocker beaucoup en m\xe9moire vive, alors que MapReduce va plut\xf4t \xe9crire sur disque d\xe8s que possible."}),"\n",(0,r.jsxs)(n.li,{children:["Ceci est en partie d\xfb au fait que MapReduce a \xe9t\xe9 fait par Google dans un contexte o\xf9 les jobs de grande priorit\xe9 et de faible priorit\xe9 tournent sur les m\xeames machines. En moyenne un job batch a 5% de chances d'\xeatre arr\xeat\xe9 parce que ses ressources sont pr\xe9empt\xe9es par un processus plus prioritaire. C'est aussi pour cette raison qu'on \xe9crit sur disque d\xe8s que possible et qu'on tol\xe8re beaucoup les fautes.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Sans ce genre de contraintes de pr\xe9emption, MapReduce pourrait se r\xe9v\xe9ler moins pertinent dans sa mani\xe8re de fonctionner."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Malgr\xe9 le succ\xe8s de MapReduce dans les ann\xe9es 2000, il y a d'autres mod\xe8les int\xe9ressants.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"MapReduce, bien que simple \xe0 comprendre, n'est pas simple \xe0 mettre en œuvre. Par exemple, le moindre algorithme de jointure a besoin d'\xeatre refait from scratch."}),"\n",(0,r.jsxs)(n.li,{children:["Il existe un ensemble d'outils construits par-dessus MapReduce, et qui fournissent d'autres abstractions (",(0,r.jsx)(l.U,{children:"Pig"}),", ",(0,r.jsx)(l.U,{children:"Hive"}),", ",(0,r.jsx)(l.U,{children:"Cascading"}),", ",(0,r.jsx)(l.U,{children:"Crunch"}),")."]}),"\n",(0,r.jsx)(n.li,{children:"Il existe aussi des mod\xe8les compl\xe8tement diff\xe9rents de MapReduce, et qui permettent d'obtenir de bien meilleures performances pour certaines t\xe2ches."}),"\n",(0,r.jsxs)(n.li,{children:["Contrairement aux programmes Unix, MapReduce fait de la ",(0,r.jsx)(n.strong,{children:"mat\xe9rialisation des \xe9tats interm\xe9diaires"}),", c'est-\xe0-dire que la sortie d'un MapReduce doit \xeatre compl\xe8tement \xe9crite avant de pouvoir \xeatre consomm\xe9e par un autre processus. A contrario les programmes Unix mettent en place un buffer sous le forme du pipe qui permet au programme suivant de d\xe9marrer en consommant la sortie du pr\xe9c\xe9dent bout par bout au fur et \xe0 mesure.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ceci a plusieurs d\xe9savantages :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le fait de devoir attendre qu'un job MapReduce soit compl\xe8tement termin\xe9 avant d'entamer le suivant est source de lenteur."}),"\n",(0,r.jsx)(n.li,{children:"Souvent, le mapper ne sert qu'\xe0 lire le code d\xe9j\xe0 format\xe9 correctement et est donc inutile. On pourrait alors cha\xeener plusieurs reducers."}),"\n",(0,r.jsx)(n.li,{children:"Le fait que les \xe9tats interm\xe9diaires mat\xe9rialis\xe9s soient sur le filesytem distribu\xe9 veut dire qu'ils sont aussi r\xe9pliqu\xe9s, ce qui est plut\xf4t overkill pour l'usage qu'on en fait;"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour r\xe9pondre \xe0 ces probl\xe8mes, des ",(0,r.jsx)(n.strong,{children:"dataflow engines"})," ont \xe9t\xe9 d\xe9velopp\xe9s.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Parmi les plus connus il y a ",(0,r.jsx)(l.U,{children:"Spark"}),", ",(0,r.jsx)(l.U,{children:"Tez"})," et ",(0,r.jsx)(l.U,{children:"Flink"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Tez est relativement petit, alors que Spark et Flink sont des frameworks plus gros, avec leurs propres couches r\xe9seau, scheduler, API."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Ils permettent :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"de ne pas n\xe9cessairement faire l'\xe9tape de tri, ce qui permet de faire des \xe9conomies quand l'ordre des entr\xe9es n'importe pas."}),"\n",(0,r.jsx)(n.li,{children:"de cha\xeener les operators (qui remplacent les mappers et reducers) dans l'ordre souhait\xe9, ce qui permet aussi d'\xe9viter les mappers inutiles."}),"\n",(0,r.jsx)(n.li,{children:"des optimisations locales, sans faire appel au r\xe9seau, et sans \xe9crire dans le filesystem distribu\xe9 HDFS quand ce n'est pas n\xe9cessaire. On ne mat\xe9rialise donc pas forc\xe9ment les \xe9tats interm\xe9diaires."}),"\n",(0,r.jsx)(n.li,{children:"de commencer la prochaine op\xe9ration d\xe8s que des donn\xe9es sont disponibles, et sans attendre que la pr\xe9c\xe9dente soit termin\xe9e."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut les utiliser pour faire les m\xeames op\xe9rations qu'avec MapReduce, et comme les operators sont une g\xe9n\xe9ralisation des mappers et reducers, on peut switcher de ",(0,r.jsx)(l.U,{children:"MapReduce"})," vers ",(0,r.jsx)(l.U,{children:"Spark"})," ou ",(0,r.jsx)(l.U,{children:"Tez"})," dans ",(0,r.jsx)(l.U,{children:"Pig"}),", ",(0,r.jsx)(l.U,{children:"Hive"})," ou ",(0,r.jsx)(l.U,{children:"Cascading"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Alors qu'avec MapReduce on avait une bonne tol\xe9rance aux fautes, avec Spark, Flink et Tez on doit trouver d'autres astuces :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si la machine qui faisait le calcul est perdue, on trouve d'autres donn\xe9es qui permettent de reconstruire la donn\xe9e perdue : la liste des op\xe9rations appliqu\xe9es, et un \xe9tat pr\xe9c\xe9dent, ou au pire la donn\xe9e originale qui est sur HDFS."}),"\n",(0,r.jsx)(n.li,{children:"Concernant le probl\xe8me du d\xe9terminisme, si une op\xe9ration \xe9tait non d\xe9terministe et que la donn\xe9e a \xe9t\xe9 transmise \xe0 un autre acteur alors qu'on a une faute, alors il faut tuer l'acteur en question. Et de mani\xe8re g\xe9n\xe9rale il faut \xe9viter les op\xe9rations non d\xe9terministes."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut \xe9galement utiliser les batch pour des donn\xe9es sous forme de graphs.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"PageRank est un exemple connu de syst\xe8me sous forme de graph."}),"\n",(0,r.jsx)(n.li,{children:"Pour les parcourir et y faire des op\xe9rations, un MapReduce ne suffit pas puisqu'il ne peut faire qu'une lecture/\xe9criture. Mais on peut r\xe9p\xe9ter ce genre d'op\xe9rations sous forme it\xe9rative, tant qu'on n'a pas atteint le but recherch\xe9."}),"\n",(0,r.jsxs)(n.li,{children:["Cependant MapReduce n'est pas tr\xe8s efficace pour it\xe9rer plusieurs fois avec de petits changements.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On a alors un mod\xe8le appel\xe9 ",(0,r.jsx)(n.strong,{children:"bulk synchronous parallel (BSP)"}),", aussi connu sous le nom de ",(0,r.jsx)(n.strong,{children:"Pregel model"}),", popularis\xe9 par un papier de Google.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il est impl\xe9ment\xe9 par ",(0,r.jsx)(l.U,{children:"Apache Giraph"}),", ",(0,r.jsx)(l.U,{children:"Spark GraphX API"}),", ",(0,r.jsx)(l.U,{children:"Flink Gelly API"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"C'est la m\xeame chose qu'avec MapReduce sauf que les donn\xe9es sont conserv\xe9es en m\xe9moire, et en cas de faible changement, il n'y a que peu de choses \xe0 recr\xe9er."}),"\n",(0,r.jsx)(n.li,{children:"Il est r\xe9sistant aux fautes, en v\xe9rifiant l'\xe9tat de tous les vertices r\xe9guli\xe8rement, et en l'\xe9crivant sur disque dur."}),"\n",(0,r.jsx)(n.li,{children:"Le calcul est parall\xe9lis\xe9, et \xe7a cause beaucoup de communication r\xe9seau. Dans la mesure du possible, si les donn\xe9es peuvent tenir en RAM sur un seul nœud, ou m\xeame sur son DD, il vaut mieux tenter l'approche non distribu\xe9e qui sera plus rapide, sinon le Pregel model est in\xe9vitable."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A mesure que le temps passe, des couches sont construites par dessus MapReduce, permettant d'avoir des abstractions.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les jointures peuvent ainsi \xeatre faites par des op\xe9rateurs relationnels, permettant \xe0 l'outil de d\xe9cider de la mani\xe8re de l'impl\xe9menter. C'est support\xe9 par Hive, Spark et Flink."}),"\n",(0,r.jsx)(n.li,{children:"Gr\xe2ce \xe0 ces diverses abstractions, les batch processings se rapprochent des BDD distribu\xe9es d'un point de vue performance, tout en permettant quand c'est n\xe9cessaire, d'ex\xe9cuter du code arbitrairement pour plus de flexibilit\xe9."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"11---stream-processing",children:"11 - Stream Processing"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'id\xe9e derri\xe8re les streams c'est de faire la m\xeame chose que les batchs, mais de mani\xe8re beaucoup plus r\xe9currente, et jusqu'\xe0 la plus petite unit\xe9 possible : plut\xf4t que de faire le traitement une fois par jour on fait le traitement d\xe8s qu'on a des donn\xe9es nouvelles."}),"\n",(0,r.jsxs)(n.li,{children:["Les donn\xe9es dans le stream processing sont des ",(0,r.jsx)(n.strong,{children:"events"}),". Ils sont mis \xe0 disposition par un ",(0,r.jsx)(n.strong,{children:"producer"}),", \xe0 destination de ",(0,r.jsx)(n.strong,{children:"consumers"}),". Ils sont group\xe9s dans un ",(0,r.jsx)(n.strong,{children:"stream"})," d'events."]}),"\n",(0,r.jsxs)(n.li,{children:["Comment transmettre les event streams :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut imaginer un m\xe9canisme de polling o\xf9 le producer met \xe0 disposition et les consumers v\xe9rifient r\xe9guli\xe8rement s'il n'y a pas de nouveaux events. Mais \xe7a fait beaucoup de messages \xe0 envoyer si on veut \xeatre r\xe9actif. Il vaut mieux que les consumers soient notifi\xe9s \xe0 chaque event.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"En g\xe9n\xe9ral les BDD supportent mal cette technique. On a bien les triggers qui permettent d'ex\xe9cuter du code \xe0 chaque requ\xeate, mais \xe7a reste assez limit\xe9. Les BDD ne sont pas con\xe7ues pour \xe7a."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La bonne solution est d'utiliser un ",(0,r.jsx)(n.strong,{children:"messaging system"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour diff\xe9rencier ces syst\xe8mes, il faut regarder deux points :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Que se passe-t-il si le producer cr\xe9e plus d'events que les consumers ne peuvent consommer ?","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Soit les consumers sautent ces messages."}),"\n",(0,r.jsx)(n.li,{children:"Soit les messages sont mis dans un buffer qui grossit, et dans ce cas que se passe-t-il si \xe7a continue de grossir jusqu'\xe0 d\xe9passer la RAM ?"}),"\n",(0,r.jsx)(n.li,{children:"Soit les consumers emp\xeachent le producer de produire tant qu'ils n'ont pas fini les events d\xe9j\xe0 produits."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Que se passe-t-il si le syst\xe8me est down ou que des nœuds crashent ? est-ce qu'on perd des events, ou est-ce qu'ils sont persist\xe9s / dupliqu\xe9s ?"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Une premi\xe8re possibilit\xe9 est la communication directe entre producer et consumers :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Des librairies de messaging brokerless comme ",(0,r.jsx)(l.U,{children:"ZeroMQ"})," et ",(0,r.jsx)(l.U,{children:"nanomsg"})," utilisent TCP/IP pour communiquer."]}),"\n",(0,r.jsx)(n.li,{children:"UDP multicast est un protocole qui permet d'envoyer des events sans garantie de r\xe9ception."}),"\n",(0,r.jsx)(n.li,{children:"StatsD et Brubeck utilisent UDP pour envoyer des m\xe9triques en tol\xe9rant des pertes."}),"\n",(0,r.jsx)(n.li,{children:"Le consumer peut exposer une API REST ou RPC appel\xe9e par le producer. C'est l'id\xe9e des webhooks. Dans le cas o\xf9 les consumers sont HS, il se peut simplement qu'ils ratent l'event."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Une autre solution est l'utilisation de ",(0,r.jsx)(n.strong,{children:"message brokers"})," (ou message queues).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ce sont en fait des BDD, soit in memory, soit avec une forme de persistance, qui mettent en relation les producers et consumers en g\xe9n\xe9ral de mani\xe8re asynchrone.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ils tol\xe8rent donc les crashs c\xf4t\xe9 consumer, puisque le message pourra \xeatre trait\xe9 plus tard."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Par rapport aux BDD :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ils ont des similarit\xe9s, et peuvent m\xeame participer \xe0 des protocoles 2PC utilisant XA."}),"\n",(0,r.jsxs)(n.li,{children:["Mais il y a des diff\xe9rences :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les BDD gardent les donn\xe9es, alors que les brokers les effacent quand \xe7a a \xe9t\xe9 trait\xe9."}),"\n",(0,r.jsx)(n.li,{children:"Les brokers partent du principe que le nombre de messages \xe0 avoir en m\xe9moire est faible. S'il grossit les performances peuvent se d\xe9grader."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Lorsqu'il y a plusieurs consumers, on peut trouver deux strat\xe9gies pour leur envoyer les events :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Load balancing"})," : si les messages co\xfbtent cher \xe0 traiter, on donne chaque message \xe0 un consommateur.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les protocoles d'encapsulation AMQP et JMS supportent tous deux cette pratique."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Fan-out"})," : Chaque consumer re\xe7oit le message et peut le traiter ind\xe9pendamment des autres.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L\xe0 encore AMQP et JMS supportent cette pratique."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour que le broker sache quand il faut enlever le message de la queue et \xe9viter de l'enlever en cas de crash du consumer, le consumer qui a trait\xe9 le message doit faire un ",(0,r.jsx)(n.strong,{children:"acknowledgement"}),". Sinon le message reste et devra \xeatre trait\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ces crashs peuvent causer un traitement des messages dans un ordre diff\xe9rent de celui d'arriv\xe9e. Si on veut \xe9viter \xe7a, on peut faire une queue par consumer."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les brokers traditionnels se distinguent des BDD ou des batches par le fait que les donn\xe9es sont d\xe9truites une fois trait\xe9es. Mais on peut tr\xe8s bien combiner la faible latence de traitement des messages (streaming) avec de la persistance durable : on a alors les ",(0,r.jsx)(n.strong,{children:"log-based message brokers"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il s'agit d'\xe9crire les events dans un fichier de log, comme on le ferait pour les LSM-Tree, ou les write-ahead logs. Les consumers peuvent alors traiter le fichier s\xe9quentiellement, et une fois \xe0 la fin \xeatre notifi\xe9s \xe0 chaque nouveau message."}),"\n",(0,r.jsxs)(n.li,{children:["Pour pouvoir scaler avec ce mod\xe8le au-del\xe0 de ce que peut supporter la lecture d'un seul disque, on peut utiliser le partitionnement : les messages sont partitionn\xe9s sur diff\xe9rentes machines repr\xe9sentant des producers, et des consumers viennent traiter les messages sur chaque partition.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Au sein de chaque partition, on peut avoir un identifiant s\xe9quentiel indiquant l'ordre. Par contre, \xe7a ne marche pas \xe0 travers les partitions."}),"\n",(0,r.jsx)(n.li,{children:"Gr\xe2ce au partitionnement, ce type de log-based brokers, malgr\xe9 le fait d'\xe9crire sur disque, arrivent \xe0 traiter plusieurs millions de messages par seconde."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Ce type de broker est impl\xe9ment\xe9 par ",(0,r.jsx)(l.U,{children:"Apache Kafka"}),", ",(0,r.jsx)(l.U,{children:"Amazon Kinesis Streams"})," et ",(0,r.jsx)(l.U,{children:"Twitter's Distributed Log"}),". ",(0,r.jsx)(l.U,{children:"Google Cloud Pub/Sub"})," est architectur\xe9 de cette fa\xe7on, mais expose une JMS-style API."]}),"\n",(0,r.jsx)(n.li,{children:"Les log-based brokers supportent le fan-out messaging puisque les logs sont conserv\xe9s et peuvent \xeatre lus un grand nombre de fois."}),"\n",(0,r.jsxs)(n.li,{children:["Pour ce qui est du load-balancing messaging, c'est mis en place \xe0 l'aide des partitions, qui sont assign\xe9s \xe0 des consumers sp\xe9cifiques.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il y a des d\xe9savantages :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On n'a qu'un consumer par partition."}),"\n",(0,r.jsx)(n.li,{children:"Les messages lents d'une m\xeame partition vont ralentir les autres messages de cette partition."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Quand utiliser les brokers classiques vs log-based :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Quand le processing des messages peut \xeatre co\xfbteux, et qu'on a envie de parall\xe9liser message par message (et quand l'ordre des messages n'est pas tr\xe8s important), on peut utiliser les brokers de type JMS / AMQP."}),"\n",(0,r.jsxs)(n.li,{children:["Quand en revanche les messages sont rapides \xe0 traiter, et que l'ordre importe, alors les log-based brokers sont pertinents.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Vu que l'ordre est respect\xe9 seulement au sein des partitions, on peut tr\xe8s bien choisir comme cl\xe9 de partitionnement la chose dont on veut que les \xe9v\xe9nement li\xe9s gardent le bon ordre. Par exemple l'id d'un utilisateur."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\xc9tant donn\xe9 que l'ordre est respect\xe9 au sein de chaque partition, on n'a plus besoin d'acknowledgement quand le traitement est fait pour chaque event. On sait que ce sera fait dans l'ordre et on peut regarder r\xe9guli\xe8rement le ",(0,r.jsx)(n.strong,{children:"log offset"})," de chaque consumer.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si un consumer \xe9choue, un autre reprendra au dernier log offset connu. Et si des messages avaient \xe9t\xe9 trait\xe9s mais dont le log offset n'\xe9tait pas connu, ils seront trait\xe9s deux fois (il va falloir r\xe9gler ce probl\xe8me)."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos de l'espace disque :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"A force d'\xe9crire des logs sur le DD, il finit par \xeatre plein, et il faut alors supprimer des donn\xe9es ou les bouger vers un espace d'archivage."}),"\n",(0,r.jsxs)(n.li,{children:["Cela veut donc dire que si on consumer est vraiment trop lent, il pourrait finir par ne plus avoir acc\xe8s aux messages non lus qui ont \xe9t\xe9 d\xe9plac\xe9s.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il faut quand m\xeame relativiser \xe7a : un DD typique fait 6To, et en \xe9crivant s\xe9quentiellement \xe0 la vitesse max on \xe9crit en moyenne \xe0 150 Mo/s. Ce qui fait 11 heures pour remplir le disque dur. Et sachant qu'on n'\xe9crit pas en permanence \xe0 la vitesse max, en g\xe9n\xe9ral des events de plusieurs jours vont pouvoir \xeatre stock\xe9s sur une m\xeame machine productrice."}),"\n",(0,r.jsx)(n.li,{children:"Si un consumer est trop en retard, on peut aussi lever une alerte pour qu'un \xeatre humain g\xe8re. Vu les d\xe9lais, il aura normalement le temps de r\xe9gler la situation."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"On peut noter aussi que pour les log-based brokers, vu qu'ils \xe9crivent toujours sur DD, le temps de traitement reste \xe0 peu pr\xe8s constant, alors que pour les brokers plus classiques, si on d\xe9passe la RAM et qu'on doit \xe9crire sur DD, les performances se d\xe9gradent."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"On peut remarquer que les log-based brokers sont plus proches des batches que les brokers classiques. Les donn\xe9es anciennes \xe9tant conserv\xe9es, on peut les rejouer \xe0 loisir pour faire des t\xe2ches dessus."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les streams et les bases de donn\xe9es :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les principes des streams peuvent aussi \xeatre utiles pour les BDD.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Par exemple, le replication log envoy\xe9 par le leader n'est rien d'autre qu'un stream."}),"\n",(0,r.jsx)(n.li,{children:"On peut aussi consid\xe9rer que chaque op\xe9ration d'\xe9criture en BDD est un \xe9v\xe9nement, et qu'on peut reconstruire la BDD \xe0 partir du log d'events d\xe9terministes."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On se retrouve souvent avec des copies des donn\xe9es sous diff\xe9rents formats pour diff\xe9rents usages (cache, data warehouse etc.). Mais comment garder ces donn\xe9es synchronis\xe9es ?","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Une solution est d'utiliser les batches. Mais c'est lent, et on n'aura pas de donn\xe9es \xe0 jour rapidement."}),"\n",(0,r.jsxs)(n.li,{children:["Une autre solution serait d'\xe9crire en m\xeame temps dans la BDD principale et dans ces autres copies. Mais dans des syst\xe8mes distribu\xe9s il peut survenir des inconsistances entre ces copies.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour r\xe9gler ce probl\xe8me, on pourrait transformer les copies en suiveuses de la BDD principales comme avec le mod\xe8le leader / follower."}),"\n",(0,r.jsxs)(n.li,{children:["Malheureusement pendant longtemps les logs des messages allant dans la BDD ont \xe9t\xe9 consid\xe9r\xe9s comme des API priv\xe9es. R\xe9cemment on a un int\xe9r\xeat vers le fait de les exploiter comme des streams qu'on appelle ",(0,r.jsx)(n.strong,{children:"change data capture (CDC)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["La solution est d'utiliser un log-based broker pour transporter les events d'\xe9criture de la BDD (leader) vers les datasets qui sont des followers (search index, data warehouse etc.).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["C'est utilis\xe9 par ",(0,r.jsx)(l.U,{children:"Databus"})," de LinkedIn, ",(0,r.jsx)(l.U,{children:"Wormhole"})," de Facebook et ",(0,r.jsx)(l.U,{children:"Sherpa"})," de Yahoo."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Bottled Water"})," le fait pour ",(0,r.jsx)(l.U,{children:"PostgreSQL"})," en lisant son write-ahead log."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Maxwell"})," et ",(0,r.jsx)(l.U,{children:"Debezium"})," le font pour ",(0,r.jsx)(l.U,{children:"MySQL"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Mongodriver"})," le fait pour ",(0,r.jsx)(l.U,{children:"MongoDB"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"GoldenGate"})," le fait pour ",(0,r.jsx)(l.U,{children:"Oracle"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Kafka Connect Framework"})," offre des connecteurs CDC pour divers BDD."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"RethinkDB"}),", ",(0,r.jsx)(l.U,{children:"Firebase"}),", ",(0,r.jsx)(l.U,{children:"CouchDB"}),", ",(0,r.jsx)(l.U,{children:"MongoDB"})," et ",(0,r.jsx)(l.U,{children:"VoltDB"})," permettent aussi d'avoir un m\xe9canisme pour exporter le stream des donn\xe9es hors de la BDD."]}),"\n",(0,r.jsx)(n.li,{children:"En g\xe9n\xe9ral, cette solution est utilis\xe9e dans un mode de r\xe9plication asynchrone."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Certains outils permettent de commencer un dataset suiveur avec un snapshot initial des donn\xe9es, plut\xf4t que de r\xe9cup\xe9rer la totalit\xe9 des logs pour reconstruire la BDD."}),"\n",(0,r.jsxs)(n.li,{children:["Certains outils comme ",(0,r.jsx)(l.U,{children:"Apache Kafka"})," permettent aussi de r\xe9cup\xe9rer les logs compact\xe9s, au sens de la compaction des LSM-Tree : seules les logs repr\xe9sentant la derni\xe8re version des entr\xe9es sont gard\xe9es. Si une entr\xe9e est supprim\xe9e \xe0 un moment, toutes les logs pr\xe9c\xe9dentes de cette entr\xe9e peuvent \xeatre supprim\xe9es aussi par la compaction par exemple."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Event sourcing"})," : c'est une id\xe9e d\xe9velopp\xe9e par la communaut\xe9 domain-driven design (DDD).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cela consiste \xe0 stocker tous les changements d'\xe9tat d'une application sous forme de logs de change events"}),"\n",(0,r.jsxs)(n.li,{children:["La diff\xe9rence entre le change data capture de la BDD et l'event sourcing c'est que le change data capture permet d'ajouter / enlever / modifier des choses dans la BDD et d'en faire un log, alors que l'event sourcing d\xe9courage ou interdit la modification, mais consiste plut\xf4t \xe0 accumuler des events qui repr\xe9sentent des choses qui se produisent plut\xf4t que de simples changements d'\xe9tat qui s'annuleraient entre eux.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La cons\xe9quence est qu'on ne peut pas vraiment faire de compaction pour les events de l'event sourcing, parce qu'ils ne s'annulent pas entre eux \xe0 proprement parler. Il faut garder ces events immuables."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"L'event sourcing est un mod\xe8le tr\xe8s puissant pour repr\xe9senter clairement ce qui se passe dans l'application, et permet aussi d'avoir des facilit\xe9s pour d\xe9bugger."}),"\n",(0,r.jsxs)(n.li,{children:["Il existe des BDD sp\xe9ciales pour l'event sourcing comme ",(0,r.jsx)(l.U,{children:"Event Store"}),", mais en r\xe9alit\xe9 n'importe quelle BDD ou message broker serait adapt\xe9."]}),"\n",(0,r.jsxs)(n.li,{children:["L'event sourcing s\xe9pare bien les ",(0,r.jsx)(n.strong,{children:"events"})," des ",(0,r.jsx)(n.strong,{children:"commands"}),". Quand une requ\xeate arrive de l'utilisateur c'est d'abord une command. Elle doit \xeatre trait\xe9e et valid\xe9e, et c'est seulement quand on est s\xfbr qu'elle l'est qu'elle devient un event immuable. Elle est alors transmise \xe0 divers syst\xe8mes consommateurs et ne peut pas \xeatre supprim\xe9e, mais seulement chang\xe9e par un autre event d'annulation par exemple."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les streams et les \xe9tats vis \xe0 vis de l'immuabilit\xe9 :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut voir la BDD comme \xe9tant un sous ensemble, ou une version cache la plus r\xe9cente des donn\xe9es que sont les logs d'events. Avec le m\xe9canisme de compaction des SSTables c'est encore plus \xe9vident puisqu'on a les logs, et on vient enlever ce qui est “inutile” pour obtenir la BDD qui est l'\xe9tat le plus actuel des donn\xe9es."}),"\n",(0,r.jsx)(n.li,{children:"Un des avantages \xe0 avoir les logs des changements immuables comme source de v\xe9rit\xe9 principale \xe0 partir de laquelle on peut construire diverses formes de dataset est que m\xeame si on fait une op\xe9ration malheureuse qui corrompt les donn\xe9es, si c'est juste sous forme de log il suffira de revenir en arri\xe8re dans les logs et c'est r\xe9gl\xe9. Avec une vraie BDD si on a corrompu les donn\xe9es on risque de ne pas pouvoir d\xe9faire."}),"\n",(0,r.jsxs)(n.li,{children:["On peut d\xe9river diverses formes de donn\xe9es \xe0 partir des logs :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Par exemple, ",(0,r.jsx)(l.U,{children:"Druid"})," ing\xe8re les donn\xe9es de ",(0,r.jsx)(l.U,{children:"Kafka"}),", de m\xeame pour ",(0,r.jsx)(l.U,{children:"Pistachio"})," qui utilise ",(0,r.jsx)(l.U,{children:"Kafka"})," comme un commit log, et ",(0,r.jsx)(l.U,{children:"Kafka Connect"})," peut exporter les donn\xe9es de ",(0,r.jsx)(l.U,{children:"Kafka"})," vers diverses BDD ou indexes."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Stocker les donn\xe9es est facile si on n'a pas \xe0 se pr\xe9occuper de le faire dans un format qui permettra une lecture optimis\xe9e en fonction de notre contexte. On peut donc s\xe9parer l'\xe9criture de la lecture, en cr\xe9ant de nouveaux dataset d\xe9riv\xe9s quand on a besoin des donn\xe9es pour faire quelque chose de sp\xe9cifique.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Cette id\xe9e de s\xe9parer les donn\xe9es d'\xe9criture et de lecture est connue sous le nom ",(0,r.jsx)(n.strong,{children:"CQRS (Command Query Responsibility Segregation)"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Dans cette approche la question de “faut-il vraiment d\xe9normaliser ?” ne se pose plus vraiment : il est logique de d\xe9normaliser pour optimiser en lecture, vu que de toute fa\xe7on les donn\xe9es seront pr\xe9sentes sous une forme plus canonique dans la version \xe9crite."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Avantages et inconv\xe9nients de l'",(0,r.jsx)(n.em,{children:"event sourcing"})," et du ",(0,r.jsx)(n.em,{children:"change data capture"})," :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Un des inconv\xe9nients est que si l'\xe9criture se fait de mani\xe8re asynchrone pour gagner du temps (ce qui est souvent le cas), on risque de ne pas avoir la garantie de ",(0,r.jsx)(n.em,{children:"read after your writes"})," par exemple. Pour rem\xe9dier \xe0 \xe7a on pourrait rendre la copie synchrone, ou utiliser des transactions distribu\xe9es, ou un ",(0,r.jsx)(n.em,{children:"total order broadcast"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Un des avantages est que \xe7a peut faciliter la ",(0,r.jsx)(n.strong,{children:"concurrency control"})," : \xe0 chaque fois qu'une requ\xeate a besoin de modifier plusieurs objets, on peut tr\xe8s bien \xe9crire un event dans le log qui implique l'ensemble de ces objets. Et donc on aurait des op\xe9rations atomiques \xe9crites en une fois."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos de l'immuabilit\xe9 :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Elle est utile si les donn\xe9es ne changent pas tant que \xe7a, mais si elles changent beaucoup on risque de se retrouver avec des logs \xe9normes pour pas beaucoup de donn\xe9es."}),"\n",(0,r.jsx)(n.li,{children:"On a aussi des contraintes l\xe9gales qui imposent parfois de supprimer certaines donn\xe9es."}),"\n",(0,r.jsxs)(n.li,{children:["On peut alors r\xe9\xe9crire l'historique pour enlever certaines donn\xe9es. ",(0,r.jsx)(l.U,{children:"Datomic"})," appelle \xe7a l'excision.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il faut savoir aussi qu'\xe9tant donn\xe9 les diverses copies de dataset, backups et autres, c'est assez difficile de compl\xe8tement supprimer les donn\xe9es."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Traitement des streams.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut faire 3 choses avec un stream :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'\xe9crire en BDD ou autre forme de persistance."}),"\n",(0,r.jsx)(n.li,{children:"Le donner directement \xe0 l'utilisateur en lui affichant."}),"\n",(0,r.jsxs)(n.li,{children:["Le modifier pour fabriquer un nouveau stream \xe0 travers un ",(0,r.jsx)(n.strong,{children:"operator"})," comme avec les batchs, dont le r\xe9sultat ira \xe0 nouveau dans une persistance ou chez l'utilisateur."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Tout ceci est assez similaire \xe0 ce qui se passe avec les batchs.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La diff\xe9rence c'est que le stream ne se finit pas, et donc on ne peut pas faire de sort ou de jointures sort-merge comme avec les batchs."}),"\n",(0,r.jsx)(n.li,{children:"La tol\xe9rance aux erreurs aussi n'est pas la m\xeame : on peut difficilement rejouer un stream qui tourne depuis des ann\xe9es comme on rejouerait un batch qui vient d'\xe9chouer."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos des usages du streaming :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On l'utilise pour du monitoring quand on veut \xeatre averti de choses particuli\xe8res, par exemple avec la d\xe9tection de fraudes, le statut des machines d'une usine etc."}),"\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"complex event processing (CEP)"})," permettent de d\xe9clarer des patterns \xe0 trouver (souvent avec du SQL), et cr\xe9ent des ",(0,r.jsx)(n.em,{children:"complex events"})," \xe0 chaque fois que \xe7a match, il s'agit de trouver une combinaison d'events.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["C'est impl\xe9ment\xe9 dans ",(0,r.jsx)(l.U,{children:"Esper"}),", ",(0,r.jsx)(l.U,{children:"IBM InfoSphere Streams"}),", ",(0,r.jsx)(l.U,{children:"Apama"}),", ",(0,r.jsx)(l.U,{children:"TIBCO StreamBase"}),", ",(0,r.jsx)(l.U,{children:"SQLstream"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les stream analytics qui ressemblent aux CEP mais sont plus orient\xe9s vers le fait de trouver des r\xe9sultats agr\xe9g\xe9s \xe0 partir des donn\xe9es stream\xe9es. Par exemple calculer une moyenne, une statistique.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On utilise souvent des fen\xeatres de donn\xe9es pour faire les calculs dessus."}),"\n",(0,r.jsx)(n.li,{children:"On utilise parfois des algorithmes probabilistes comme les Bloom Filters pour savoir si un \xe9l\xe9ment est dans un set et d'autres. Ces algorithmes produisent des r\xe9sultats approximatifs mais utilisent moins de m\xe9moire."}),"\n",(0,r.jsxs)(n.li,{children:["Parmi les outils on a ",(0,r.jsx)(l.U,{children:"Apache Storm"}),", ",(0,r.jsx)(l.U,{children:"Spark Streaming"}),", ",(0,r.jsx)(l.U,{children:"Flink"}),", ",(0,r.jsx)(l.U,{children:"Concord"}),", ",(0,r.jsx)(l.U,{children:"Samza"})," et ",(0,r.jsx)(l.U,{children:"Kafka Streams"}),". Et parmi les outils host\xe9s on a ",(0,r.jsx)(l.U,{children:"Google Cloud Dataflow"})," et ",(0,r.jsx)(l.U,{children:"Azure Stream Analytics"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les dataset d\xe9riv\xe9es des logs comme dans l'event sourcing peuvent \xeatre vus comme des materialized views, dans ce cas il faut prendre en compte l'ensemble des logs et pas juste une fen\xeatre.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Samza"})," et ",(0,r.jsx)(l.U,{children:"Kafka Streams"})," font \xe7a."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut faire aussi un peu pareil que les CEP mais en recherchant un seul event qui match un crit\xe8re de recherche. Alors que d'habitude on doit indexer avant de faire une recherche, l\xe0 il s'agit de rechercher en plein streaming.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La feature ",(0,r.jsx)(n.em,{children:"percolator"})," d'",(0,r.jsx)(l.U,{children:"Elasticsearch"})," permet de faire \xe7a."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La notion de temps dans la gestion des stream processing :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Alors que dans les batch processing ce qui compte c'est \xe9ventuellement le timestamp des events analys\xe9s, et pas le temps pendant le quel le batch s'ex\xe9cute (ce qui rend la r\xe9ex\xe9cution du batch transparente d'ailleurs), dans le cadre du stream processing le temps pendant lequel le processing s'ex\xe9cute peut \xeatre pris en compte, par exemple pour faire des fen\xeatres.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Attention cependant aux lags : il est possible que lors du stream processing un event soit process\xe9 bien apr\xe8s avoir \xe9t\xe9 \xe9mis. Et dans ce cas on peut se retrouver avec des events trait\xe9s dans un ordre qui n'est pas le bon vis-\xe0-vis de leur \xe9mission."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Quand on stream avec des fen\xeatres de temps contenant des events pour y faire des op\xe9rations, on ne peut jamais \xeatre s\xfbr que tous les events de la fen\xeatre sont arriv\xe9s : ils ont peut \xeatre \xe9t\xe9 retard\xe9s (qu'on appelle ",(0,r.jsx)(n.strong,{children:"straggler"}),")","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dans ce cas, soit on dit tant pis et on annule les events retardataires, en levant \xe9ventuellement une alerte s'il y en a trop."}),"\n",(0,r.jsx)(n.li,{children:"Soit on publie plus tard un correctif avec les events retardataires."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Quand on veut prendre en compte le temps, le temps de la cr\xe9ation de l'event est souvent plus pr\xe9cis (par exemple un event peut \xeatre cr\xe9\xe9 offline par un mobile, et envoy\xe9 seulement quand il est connect\xe9), mais aussi moins fiable vu que la machine n'est pas sous notre contr\xf4le contrairement au serveur.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Une des solutions est de relever (1) le temps de l'event indiqu\xe9 par le client, (2) le temps de l'envoi de l'event indiqu\xe9 par le client, et (3) le temps de la r\xe9ception de l'event par le serveur. De cette mani\xe8re on peut comparer les horloges du client et du serveur vu que le (2) et le (3) doivent \xeatre tr\xe8s proches."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il y a plusieurs types de fen\xeatres temporelles :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Tumbling window"})," : Les fen\xeatres sont fixes, et chaque event appartient \xe0 une fen\xeatre."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Hopping window"})," : Les fen\xeatres font la m\xeame taille mais se chevauchent, certains events qui sont entre les deux sont dans les deux fen\xeatres."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sliding window"})," : Les fen\xeatres font la m\xeame taille mais se d\xe9placent dans le temps, et donc les events les plus anciens sont exclus au fur et \xe0 mesure, remplac\xe9s par des events plus r\xe9cents."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Session window"})," : Les fen\xeatres n'ont pas la m\xeame taille, elles regroupent des events proches dans le temps o\xf9 un m\xeame utilisateur a \xe9t\xe9 actif."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les streams \xe9tant une g\xe9n\xe9ralisation des batchs, on a ici le m\xeame besoin des jointures.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut d\xe9nombrer 3 types :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"stream-stream join (window join)"})," consiste \xe0 joindre deux ensemble streams d'events ensemble. Par exemple dans le cadre d'une recherche, joindre les events de recherches faites aux events clics qui s'en sont suivis (ou \xe0 l'absence de clics apr\xe8s timeout)."]}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"stream-table join (stream enrichement)"})," consiste \xe0 “enrichir” les events issus d'un stream avec le contenu d'une BDD. Par exemple les actions d'un utilisateur enrichis (compl\xe9t\xe9s ou tri\xe9s) avec des infos issus de son profil.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour ce faire il nous faut une copie de la BDD sur le disque local de pr\xe9f\xe9rence, et si suffisamment petit on peut m\xeame la mettre en RAM. C'est tr\xe8s similaire aux Map-side joins des batchs."}),"\n",(0,r.jsxs)(n.li,{children:["Vu que les donn\xe9es de la table risquent d'\xeatre mises \xe0 jour, on peut utiliser le ",(0,r.jsx)(n.em,{children:"change data capture"})," pour r\xe9colter les mises \xe0 jour de la table r\xe9guli\xe8rement."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"table-table join (materialized view maintenance)"})," consiste \xe0 mat\xe9rialiser une requ\xeate de jointure entre deux tables, \xe0 chaque fois qu'il y a un changement dans ces deux tables qui risque d'affecter le r\xe9sultat de cette jointure.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut prendre l'exemple de twitter qui, en m\xeame temps qu'il stocke les tweets et followers, construit une timeline en cache au fur et \xe0 mesure."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On remarque que dans la plupart des cas, le temps est important, et que deux \xe9v\xe9nements, ou un \xe9v\xe9nement et une mise \xe0 jour en BDD pourraient arriver avant ou apr\xe8s l'autre (du fait du partitionnement). Ceci rend la jointure non d\xe9terministe (si on la refait on risque d'avoir un r\xe9sultat diff\xe9rent).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dans les data warehouses ce probl\xe8me s'appelle _slowly changing dimension (SCD) _et la solution \xe0 \xe7a peut \xeatre d'ajouter un identifiant qui est chang\xe9 \xe0 chaque event. Mais la cons\xe9quence c'est qu'on ne peut plus faire de compaction."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos des fautes dans le cadre des streams :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["L'avantage avec les batchs c'\xe9tait le fait de pouvoir r\xe9ex\xe9cuter en cas d'erreur, et d'avoir au final le job ex\xe9cut\xe9 comme s'il l'avait \xe9t\xe9 une seule fois.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Une des solutions est le ",(0,r.jsx)(n.strong,{children:"microbatching"})," : on fait des petites fen\xeatres de donn\xe9es (souvent d'1 seconde) et on les traite comme des batchs.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Spark Streaming"})," fait \xe7a."]}),"\n",(0,r.jsxs)(n.li,{children:["Une variante consiste \xe0 faire des checkpoints r\xe9guliers sur DD, et en cas de crash on recommence \xe0 partir du checkpoint.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Flink"})," fait \xe7a."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Attention cependant au moment o\xf9 on fait autre chose avec ces donn\xe9es, comme \xe9crire en BDD ou envoyer un email. Dans ce cas, il s'agit de side effects qui pourront \xeatre r\xe9ex\xe9cut\xe9s en cas de r\xe9ex\xe9cution du microbatch.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour r\xe9gler ce probl\xe8me, il faut tout pr\xe9parer, et ex\xe9cuter tout ce qui est validation des op\xe9rations, side-effects et autres en une seule fois et de mani\xe8re atomique.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C'est un peu de la m\xeame mani\xe8re que le 2PC (two phase commit) des transactions distribu\xe9es."}),"\n",(0,r.jsxs)(n.li,{children:["C'est utilis\xe9 par ",(0,r.jsx)(l.U,{children:"Google Cloud Dataflow"}),", ",(0,r.jsx)(l.U,{children:"VoltDB"})," et ",(0,r.jsx)(l.U,{children:"Apache Kafka"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Une autre solution pour ce probl\xe8me est de cr\xe9er de l'",(0,r.jsx)(n.strong,{children:"idempotence"}),", c'est-\xe0-dire faire en sorte qu'une chose faite plusieurs fois donne le m\xeame r\xe9sultat.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut le faire par exemple en retenant un offset qui fera en sorte de ne rien faire si on tente de refaire l'op\xe9ration."}),"\n",(0,r.jsx)(n.li,{children:"Attention au fait que cela implique qu'il faut rejouer les messages dans le m\xeame ordre (un broker log-based permet \xe7a), de mani\xe8re d\xe9terministe, et sans concurrence."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut aussi vouloir que des ",(0,r.jsx)(n.strong,{children:"states"})," (par exemple compteurs, moyennes etc.) soient reconstruites en cas de faute.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dans certains cas \xe7a peut \xeatre fait \xe0 partir des events, par exemple parce qu'il s'agit d'un \xe9tat qui porte sur peu d'entre eux."}),"\n",(0,r.jsxs)(n.li,{children:["Sinon une solution peut \xeatre de les sauvegarder r\xe9guli\xe8rement quelque part pour aller les chercher en cas de besoin.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Flink"})," capture r\xe9guli\xe8rement ces valeurs et les \xe9crit sur du HDFS."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"Samza"})," et ",(0,r.jsx)(l.U,{children:"Kafka Streams"})," r\xe9pliquent les changements des states vers un stockage persistant avec compaction."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"VoltDB"})," r\xe9plique les states en faisant le processing des messages sur plusieurs nœuds."]}),"\n",(0,r.jsx)(n.li,{children:"Il faut voir que la sauvegarde en local avec acc\xe8s au disque ou la sauvegarde via le r\xe9seau peuvent chacun \xeatre plus ou moins performants en fonction des cas."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"12---the-future-of-data-systems",children:"12 - The Future of Data Systems"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Chaque outil a ses avantages et inconv\xe9nients, et il n'y a pas d'outils parfaits.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Certaines personnes disent que tel ou tel type d'outil n'a aucune utilit\xe9, mais \xe7a refl\xe8te surtout le fait qu'eux ne l'utilisent pas, et qu'ils ne voient pas plus loin que le bout de leur nez."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il convient souvent de combiner plusieurs outils pour plusieurs usages :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Parmi ceux-ci on peut trouver :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Une BDD relationnelle pour la persistance de donn\xe9es structur\xe9es. (ex : ",(0,r.jsx)(l.U,{children:"PostgreSQL"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:["Un index de recherche pour une recherche performante, mais qui est moins bon sur la persistance des donn\xe9es (ex : ",(0,r.jsx)(l.U,{children:"Elasticsearch"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:["Un syst\xe8me d'analyse du type data warehouse ou batch / stream processing.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Parmi les batchs / streams on pourrait vouloir alimenter un syst\xe8me de machine learning, de classification, de ranking, de recommandations, de notification bas\xe9e sur le changement de donn\xe9es."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Un cache ou des donn\xe9es d\xe9normalis\xe9es issues des donn\xe9es initiales."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Par exemple, on peut avoir une BDD et un search index, avec les donn\xe9es \xe9crites d'abord dans la BDD, puis propag\xe9es dans le search index via ",(0,r.jsx)(n.em,{children:"change data capture (CDC)"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Si on d\xe9cide qu'on veut \xe9crire \xe0 la fois dans la BDD, et dans le search index, alors on risque d'avoir des latences qui causent des diff\xe9rences d'ordre d'\xe9criture entre les deux.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Une solution \xe0 \xe7a c'est d'utiliser un syst\xe8me d'entonnoir qui force l'ordre, dans l'id\xe9e d'un ",(0,r.jsx)(n.em,{children:"total order broadcast"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Que choisir entre les donn\xe9es d\xe9riv\xe9es (CDC, event sourcing) et les transactions distribu\xe9es (2PC) pour faire communiquer plusieurs outils entre eux ?","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Selon l'auteur, XA, le protocole qui permet de faire communiquer les outils via les transactions distribu\xe9es a une mauvaise tol\xe9rance aux fautes et une faible performance. Et en l'absence d'un autre protocole aussi r\xe9pandu (ce qui ne risque pas d'arriver rapidement), il est plus pertinent d'opter pour les datasets d\xe9riv\xe9s.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Cependant, les transactions distribu\xe9es supportent la linearizability et donc permettent par exemple le “",(0,r.jsx)(n.em,{children:"read your own writes"}),"”, alors que les donn\xe9es d\xe9riv\xe9es sont en g\xe9n\xe9ral asynchrones et donc n'apportent pas ces garanties. Cette ",(0,r.jsx)(n.em,{children:"eventual consistency"})," est \xe0 mettre dans la balance.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Plus tard on parlera d'un moyen de contourner ce probl\xe8me."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Attention au fait de vouloir du total ordering :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour avoir du total ordering il faut que les donn\xe9es passent par une seule machine (par exemple single leader). Sinon on peut cr\xe9er des partitions mais on aura des ambigu\xeft\xe9s entre partitions."}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas de plusieurs datacenters on a en g\xe9n\xe9ral besoin de 2 leaders => on n'aura donc pas de total ordering."}),"\n",(0,r.jsx)(n.li,{children:"Quand on fait du micro-service, il est courant de d\xe9ployer le code sur des machines avec chacune son stockage et sans que ce stockage soit donc partag\xe9 => on se retrouve l\xe0 aussi donc \xe0 ne pas respecter le total ordering."}),"\n",(0,r.jsx)(n.li,{children:"Pour \xeatre clair : le total ordering implique le total order broadcast, qui est \xe9quivalent au consensus. Et la plupart des algorithmes de consensus ne sont pas faits pour marcher si le throughput d\xe9passe les donn\xe9es que peut g\xe9rer un seul serveur. Le fait de pouvoir g\xe9rer un tel throughput avec des datacenters distribu\xe9s dans le monde est un sujet de recherche."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos de l'ordre causal :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour les \xe9v\xe9nements qui touchent le m\xeame objet, celui-ci \xe9tant sur la m\xeame partition on peut ordonner ces actions et respecter la causalit\xe9."}),"\n",(0,r.jsxs)(n.li,{children:["En revanche, pour les \xe9v\xe9nements qui portent sur plusieurs objets il n'y a pas de solution facile. Quelques pistes :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les clocks logiques peuvent aider."}),"\n",(0,r.jsx)(n.li,{children:"Si on log des events pendant pour les lectures, alors les autres \xe9vents peuvent les utiliser pour identifier le moment o\xf9 un \xe9v\xe9nement ne s'\xe9tait pas produit et cr\xe9er un ordre comme \xe7a."}),"\n",(0,r.jsx)(n.li,{children:"Les structures de r\xe9solution automatique de conflit (fusion des objets par exemple) peuvent aussi aider."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos des batches et streams :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Une des raisons pour lesquelles il est pratique d'avoir des dataset d\xe9riv\xe9s par batch/stream plut\xf4t que transactions distribu\xe9es est qu'on peut fauter quelque part et ne pas tout annuler, mais seulement retenter la construction du batch/stream."}),"\n",(0,r.jsxs)(n.li,{children:["Un des avantages des batchs/streams c'est qu'avec les datasets d\xe9riv\xe9s, on peut changer le sch\xe9ma de nos donn\xe9es pour un dataset, et reprocesser le tout, ou continuer pour le stream. On n'a pas \xe0 faire d'op\xe9rations destructives pour faire \xe9voluer notre code.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut d'ailleurs faire les changements graduellement, blocs de donn\xe9es par bloc de donn\xe9es."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"lambda architecture"})," consiste \xe0 avoir un batch et un stream qui vont processer la m\xeame chose pour avoir la donn\xe9e imm\xe9diatement, mais avoir un process mieux tol\xe9rant aux erreurs plus tard. Le stream fait une approximation, alors que le batch fait un calcul plus pr\xe9cis r\xe9guli\xe8rement.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il y a cependant plusieurs probl\xe8mes :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Maintenir la logique dans le batch et le stream est difficile."}),"\n",(0,r.jsx)(n.li,{children:"Il faut merger les deux r\xe9guli\xe8rement, et \xe7a peut \xeatre difficile si les op\xe9rations appliqu\xe9es sont difficiles."}),"\n",(0,r.jsx)(n.li,{children:"Reprocesser toutes les donn\xe9es avec le batch est tr\xe8s co\xfbteux, donc on peut \xe0 la place reprocesser une seule heure de donn\xe9es et y ajouter le stream. Cependant, rendre le batch incr\xe9mental le fragilise."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Mais plus r\xe9cemment on a d'autres solutions pour rendre la lambda architecture plus utilisable gr\xe2ce \xe0 certaines features qui sont de plus en plus support\xe9s par les outils."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos de BDD :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les BDD et les filesystem font la m\xeame t\xe2che."}),"\n",(0,r.jsxs)(n.li,{children:["Mais ils ont certaines diff\xe9rences : les filesystem Unix offrent une API bas niveau pour traiter avec les fichiers, alors que les BDD offrent une API plus haut niveau avec SQL.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"D'une certaine mani\xe8re certaines BDD NoSQL tentent d'ajouter la philosophie Unix aux BDD."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les BDD et les batchs / streams ont des choses en commun :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Par exemple, la construction de search indexs dans les batchs/streams sont un peu la m\xeame chose que la construction d'index secondaires."}),"\n",(0,r.jsx)(n.li,{children:"Et du coup on en arrive \xe0 la conclusion qu'en fait les batchs/streams ne sont que la continuation d'une m\xeame base de donn\xe9es transform\xe9e pour l'adapter aux besoins, distribu\xe9e sur d'autres machines et administr\xe9e \xe9ventuellement par d'autres \xe9quipes."}),"\n",(0,r.jsxs)(n.li,{children:["L'auteur sp\xe9cule que les donn\xe9es seront organis\xe9es en deux grands axes, qui sont en fait deux faces de la m\xeame pi\xe8ce :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Federated databases (unifying reads)"})," : il s'agit de fournir une API de lecture pour acc\xe9der \xe0 toutes les donn\xe9es existantes du syst\xe8me, tout en laissant les applications sp\xe9cialis\xe9es acc\xe9der directement aux datasets sp\xe9cifiques dont elles ont besoin. L'id\xe9e est donc de connecter toutes les donn\xe9es ensemble.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(l.U,{children:"PostgreSQL"})," et son ",(0,r.jsx)(n.em,{children:"foreign data wrapper"})," permet de faire \xe7a."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Unbundled databases (unifying writes)"})," : il s'agit de traiter les \xe9critures pour qu'on puisse \xe9crire dans n'importe quelle version des donn\xe9es, et qu'elles soient quand m\xeame synchronis\xe9es avec le reste. Alors que les BDD supportent les indexes secondaires, ici on a diff\xe9rents datasets interconnect\xe9s et donc on doit en quelque sorte maintenir nos indexes \xe0 la main.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On est en plein dans la tradition Unix o\xf9 des petits outils font une chose bien, et peuvent s'interconnecter."}),"\n",(0,r.jsxs)(n.li,{children:["Alors que la f\xe9d\xe9ration des donn\xe9es n'est pas trop difficile, maintenir les donn\xe9es synchronis\xe9es est plus compliqu\xe9 \xe0 faire.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour accomplir ces donn\xe9es synchronis\xe9es on recourt traditionnellement aux transactions distribu\xe9es, mais selon l'auteur c'est la mauvaise approche. L'approche sous forme de donn\xe9es d\xe9riv\xe9es depuis un event log asynchrone, et l'utilisation de l'idempotence est bien plus solide."}),"\n",(0,r.jsx)(n.li,{children:"Une des raisons d\xe9j\xe0 \xe9voqu\xe9e est que faire communiquer des syst\xe8mes de donn\xe9es h\xe9t\xe9rog\xe8nes via un mauvais protocole marche moins bien que via une meilleure abstraction avec des logs d'event et de l'idempotence."}),"\n",(0,r.jsxs)(n.li,{children:["Le gros plus de l'approche avec les event logs est le couplage faible entre les composants :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La nature asynchrone de cette approche permet de tol\xe9rer bien mieux les fautes (par exemple, un consommateur fautif va rattraper son retard plus tard via les messages accumul\xe9s) alors qu'avec les transactions distribu\xe9es synchrones par nature, les fautes ont tendance \xe0 \xeatre amplifi\xe9es."}),"\n",(0,r.jsx)(n.li,{children:"Au niveau des \xe9quipes, chacune peut se sp\xe9cialiser dans un type de dataset pour un usage, et le faire ind\xe9pendamment des autres."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Entre utiliser un syst\xe8me de BDD int\xe9gr\xe9 et un syst\xe8me compos\xe9 de datasets d\xe9riv\xe9s, le choix des datasets d\xe9riv\xe9s n'est pas forc\xe9ment syst\xe9matique. \xc7a peut \xeatre une forme d'optimisation pr\xe9matur\xe9e, et d'ailleurs si un syst\xe8me de BDD r\xe9pond \xe0 nos besoins, autant l'utiliser lui seul."}),"\n",(0,r.jsxs)(n.li,{children:["Ce qui manque dans l'histoire c'est une mani\xe8re simple et haut niveau d'interconnecter ces syst\xe8mes, par exemple “declare mysql | elasticsearch” comme \xe9quivalent de “CREATE INDEX” dans une BDD.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il y a des recherches \xe0 ce sujet mais pour le moment rien de tel, on doit faire beaucoup de choses \xe0 la main."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour continuer sur l'id\xe9e de l'",(0,r.jsx)(n.strong,{children:"unbundling databases"}),", et des applications autour du ",(0,r.jsx)(n.strong,{children:"dataflow"})," :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut trouver des ressemblances avec le concept d'unbundling des BDD et des langages de dataflow comme Oz, Juttle, les langages fonctionnels r\xe9actifs comme Erlang, et les langages de programmation logique comme Bloom."}),"\n",(0,r.jsx)(n.li,{children:"L'id\xe9e de l'unbundling est aussi pr\xe9sente dans les tableurs quand ils mettent \xe0 jour toute une colonne d\xe8s qu'une donn\xe9e est \xe9crite. Il faut juste faire la m\xeame chose mais dans un contexte distribu\xe9, et avec des technologies disparates."}),"\n",(0,r.jsx)(n.li,{children:"On a diff\xe9rentes formes de donn\xe9es d\xe9riv\xe9es, mais en gros d\xe8s que la d\xe9rivation est sp\xe9cifique \xe0 notre m\xe9tier, il faut \xe9crire du code applicatif pour g\xe9rer ce dataset-l\xe0. Et les BDD ont en g\xe9n\xe9ral du mal \xe0 permettre \xe7a. Il y a bien les triggers / stored procedures, mais \xe7a reste une feature secondaire."}),"\n",(0,r.jsxs)(n.li,{children:["Il est devenu un pattern courant et une bonne pratique de s\xe9parer le code applicatif du state (ie. la persistance), en ayant des serveurs stateless qui acc\xe8dent \xe0 une BDD commune.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les d\xe9veloppeurs fonctionnels disent qu'ils sont pour “la s\xe9paration de l'\xe9glise et de l'\xe9tat”."}),"\n",(0,r.jsx)(n.li,{children:"Cependant, de m\xeame que dans la plupart des langages il n'y a pas de syst\xe8me de souscription (sauf \xe0 le faire avec le pattern observer), dans les BDD il n'y en a pas non plus sauf r\xe9cemment avec les CDC par exemple."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Vu qu'on veut sortir la logique de mise \xe0 jour automatique par exemple d'un index dans la BDD hors de celle-ci, on peut partir du principe que la donn\xe9e n'est pas une chose passive utilis\xe9e par l'application, mais que les changements dans un dataset peuvent d\xe9clencher du code applicatif pour cr\xe9er un autre dataset.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["A cet effet, on peut utiliser des log message brokers (et non pas des message brokers traditionnels qui servent \xe0 ex\xe9cuter des jobs de mani\xe8re asynchrone).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'ordre des messages est souvent important pour maintenir des datasets d\xe9riv\xe9s."}),"\n",(0,r.jsx)(n.li,{children:"On doit \xeatre tol\xe9rant aux fautes et ne pas perdre de messages, sous peine d'inconsistance."}),"\n",(0,r.jsx)(n.li,{children:"Les message brokers permettent au code applicatif de s'ex\xe9cuter sous forme d'operators, ce qui est pratique."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le stream processing et les services :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'architecture sous forme de services est plut\xf4t \xe0 la mode, son avantage principal est de permettre une forme de scalabilit\xe9 dans l'entreprise, en permettant \xe0 plusieurs \xe9quipes de d\xe9ployer s\xe9par\xe9ment."}),"\n",(0,r.jsx)(n.li,{children:"Il y a cependant une diff\xe9rence entre les services qui vont envoyer un message pour recevoir une r\xe9ponse du service qui a les donn\xe9es, et le stream processing qui va construire et maintenir \xe0 jour un dataset local \xe0 la machine qui a le code applicatif, qui n'aura plus de requ\xeate r\xe9seau \xe0 faire => la m\xe9thode avec le stream processing est donc plus performante."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Lecture des donn\xe9es d\xe9riv\xe9es :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les donn\xe9es d\xe9riv\xe9es sont construites et mises \xe0 jour en observant la donn\xe9e initiale et la faisant passer \xe0 travers des operators, tout ceci pendant la phase d'\xe9criture. On a ensuite du code ex\xe9cut\xe9 qui lit ces donn\xe9es d\xe9riv\xe9es et qui r\xe9pond \xe0 une requ\xeate d'un client, pendant la phase de lecture donc.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ce point de rencontre repr\xe9sente en quelque sorte le point d'\xe9quilibre entre la quantit\xe9 de travail qu'on souhaite faire \xe0 l'\xe9criture, et la quantit\xe9 de travail qu'on souhaite faire \xe0 la lecture."}),"\n",(0,r.jsxs)(n.li,{children:["On peut d\xe9placer ce point de rencontre pour faire plus de travail \xe0 l'\xe9criture, ou plus \xe0 la lecture.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Par exemple pour la recherche, on peut tr\xe8s bien ne pas cr\xe9er de search index, et tout faire \xe0 la lecture."}),"\n",(0,r.jsxs)(n.li,{children:["Ou alors on peut non seulement cr\xe9er un search index \xe0 l'\xe9criture, mais aussi cr\xe9er tous les r\xe9sultats de recherche possibles, comme \xe7a \xe0 la lecture on n'aura plus qu'\xe0 lire un ",(0,r.jsx)(n.strong,{children:"cache"})," (aussi appel\xe9 ",(0,r.jsx)(n.strong,{children:"materialized view"}),").","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si cr\xe9er l'ensemble des r\xe9sultats de recherche serait sans doute excessif, on peut tr\xe8s bien imaginer mettre en cache les r\xe9sultats des recherches les plus fr\xe9quentes."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"On voit qu'on retrouve aussi notre exemple de twitter qui avait choisi de mettre en cache toutes les timelines, sauf pour les c\xe9l\xe9brit\xe9s o\xf9 il faisait la recherche en BDD."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Autre exemple de lecture de donn\xe9es d\xe9riv\xe9es : les applications web sur mobile qui gagnent de plus de capacit\xe9 d'autonomie, y compris offline, peuvent stocker une forme de dataset d\xe9riv\xe9 au sein m\xeame du mobile, permettant au code sur le client d'en faire quelque chose offline.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les outils frontend comme le langage Elm et le framework React / Redux permettent de souscrire \xe0 des events de l'utilisateur, en mode event sourcing."}),"\n",(0,r.jsx)(n.li,{children:"Il serait tout \xe0 fait naturel de faire la m\xeame chose dans la relation client / serveur : permettre au client de faire une requ\xeate, puis de r\xe9ceptionner non pas une r\xe9ponse mais un stream de messages r\xe9guliers."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les log message brokers passent en g\xe9n\xe9ral leur contenu \xe0 une forme ou une autre de BDD sp\xe9cialis\xe9e, mais il y a aussi une certaine persistance des events eux-m\xeames (les logs) dans le message broker. En g\xe9n\xe9ral seuls les events d'\xe9criture y sont consign\xe9s, ce qui est raisonnable mais n'est pas la seule mani\xe8re de faire possible.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il est possible qu'en fonction du besoin applicatif, on ait aussi int\xe9r\xeat \xe0 consigner les events de lecture. \xc7a permet notamment de faire un stream-table join entre les lectures et les donn\xe9es existantes."}),"\n",(0,r.jsxs)(n.li,{children:["C'est utile en particulier dans le cas o\xf9 on a plusieurs partitions qu'il faut traverser pour obtenir notre r\xe9sultat.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La feature de ",(0,r.jsx)(n.em,{children:"distributed RPC"})," de ",(0,r.jsx)(l.U,{children:"Storm"})," impl\xe9mente cette fonctionnalit\xe9."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"\xc7a prend bien s\xfbr plus de place donc il faut y r\xe9fl\xe9chir."}),"\n",(0,r.jsx)(n.li,{children:"Un des avantages est que \xe7a permet aussi de r\xe9gler le probl\xe8me de causalit\xe9 vis-\xe0-vis d'\xe9critures sur des objets diff\xe9rents."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A la recherche des donn\xe9es correctes :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On a tendance \xe0 avoir un mouvement vers une plus grande performance, availability et scalability, avec une consistency qui est parfois d\xe9laiss\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Exemple : la r\xe9plication leaderless."}),"\n",(0,r.jsx)(n.li,{children:"On peut aussi noter le rapport hasardeux \xe0 l'isolation et l'impl\xe9mentation de faibles niveaux d'isolation dans beaucoup de BDD."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut r\xe9pondre \xe0 certaines probl\xe9matiques de corruption de donn\xe9es \xe0 l'aide de la serializability et des atomic commits, mais c'est vraiment co\xfbteux et \xe7a marche surtout sur un seul datacenter, avec des limites de scalabilit\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il y a aussi les transactions qui permettent de r\xe9gler certains probl\xe8mes, mais ce n'est pas la seule solution."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"N'oublions pas non plus les erreurs et bugs applicatifs qui peuvent endommager les donn\xe9es de mani\xe8re d\xe9finitive, m\xeame en pr\xe9sence de serializability…"}),"\n",(0,r.jsxs)(n.li,{children:["Pour lutter contre ces probl\xe8mes voici quelques solutions :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L'immutabilit\xe9 des donn\xe9es (du genre event sourcing et autres) permet d'\xeatre s\xfbr que m\xeame en \xe9crivant des donn\xe9es corrompues, on pourra toujours les annuler pour retrouver l'\xe9tat d'avant."}),"\n",(0,r.jsx)(n.li,{children:"Rendre les op\xe9rations idempotentes pour qu'elles ne puissent \xeatre ex\xe9cut\xe9es qu'une seule fois au plus est une forme de protection contre la corruption de donn\xe9es."}),"\n",(0,r.jsxs)(n.li,{children:["De mani\xe8re g\xe9n\xe9rale, il est int\xe9ressant d'impl\xe9menter des m\xe9canismes ",(0,r.jsx)(n.strong,{children:"end-to-end"})," qui vont suivre la requ\xeate de bout en bout. Par exemple TCP fournit ce genre de garanties \xe0 son niveau, mais une connexion TCP peut sauter et on peut en \xe9tablir une autre pour refaire la m\xeame transaction, on a alors besoin de quelque chose qui suit notre transaction.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Malheureusement, impl\xe9menter de tels m\xe9canismes end-to-end au niveau applicatif n'est pas simple. Pour l'auteur, il faudrait qu'on trouve la bonne abstraction pour rendre \xe7a facile, mais il y a de la recherche \xe0 faire."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Appliquer des contraintes :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La contrainte de uniqueness dans un syst\xe8me distribu\xe9 n\xe9cessite le consensus, et donc une forme de fonctionnement synchrone. Si les writes se faisaient de mani\xe8re asynchrone, alors on ne saurait pas imm\xe9diatement si on peut \xe9crire en respectant cette contrainte ou pas, et on aurait le conflit plus tard.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Un bon moyen pour garantir cette contrainte est de partitionner en fonction de la cl\xe9 qui doit avoir la contrainte d'unicit\xe9. Mais l\xe0 aussi bien s\xfbr on ne pourra pas \xe9crire dans la BDD de mani\xe8re asynchrone."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour les contraintes au sein des log-based message brokers il s'agit aussi de faire en sorte que les requ\xeates avec possibilit\xe9 de conflit soient dans la m\xeame partition, et de v\xe9rifier s\xe9quentiellement, message par message, que la requ\xeate respecte bien la contrainte vis-\xe0-vis de la BDD locale.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Dans le cas o\xf9 les entr\xe9es qui sont l'objet de contraintes sont localis\xe9es dans des partitions diff\xe9rentes \xe7a se complique un peu.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut utiliser un atomic commit (par exemple 2PC)."}),"\n",(0,r.jsxs)(n.li,{children:["Mais on peut aussi faire sans (exemple de d\xe9bit / cr\xe9dit d'un compte) :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On attribue un id \xe0 la requ\xeate."}),"\n",(0,r.jsx)(n.li,{children:"Le stream processor cr\xe9e 2 messages : un pour d\xe9cr\xe9menter le compte qui a un d\xe9bit, et un autre pour incr\xe9menter l'autre compte (qui sont chacun sur leur partition)."}),"\n",(0,r.jsx)(n.li,{children:"Les processors suivants consomment les messages, appliquent le d\xe9bit ou le cr\xe9dit, et d\xe9dupliquent en fonction de l'id de la transaction initiale."}),"\n",(0,r.jsx)(n.li,{children:"Vu qu'on est dans un log based broker avec l'ordre des messages pr\xe9serv\xe9s et de la persistance, en cas de crash de l'un des consommateurs, il red\xe9marre et r\xe9applique les messages non process\xe9s dans l'ordre pr\xe9vu."}),"\n",(0,r.jsx)(n.li,{children:"Nous avons donc r\xe9ussi \xe0 r\xe9aliser une transaction multi-partition sans utiliser de protocole de type atomic commit, en cassant la transaction en plusieurs morceaux s'ex\xe9cutant chacun sur leur partition, et en ayant un m\xe9canisme end-to-end (ici l'id) assurant l'int\xe9grit\xe9 du tout (le fait qu'un bout ne sera pas ex\xe9cut\xe9 2 fois)."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos de l'int\xe9grit\xe9 et de la relation au temps :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le terme consistency englobe en r\xe9alit\xe9 deux enjeux :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"timeliness"})," qui consiste \xe0 s'assurer que l'observateur voit une donn\xe9e \xe0 jour. C'est tout l'objet du terme eventual consistency quand la timeliness n'est pas respect\xe9e."]}),"\n",(0,r.jsxs)(n.li,{children:["L'",(0,r.jsx)(n.strong,{children:"integrity"})," qui consiste \xe0 pr\xe9server les donn\xe9es d'une corruption permanente des donn\xe9es, y compris d\xe9riv\xe9es. Pour la r\xe9gler il faudrait r\xe9parer et non pas juste attendre ou r\xe9essayer."]}),"\n",(0,r.jsx)(n.li,{children:"Si le non-respect de la timeliness est emb\xeatant, le non-respect de l'integrity peut \xeatre catastrophique."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Alors que dans les transactions ACID la timeliness et l'integrity sont confondues, on vient de voir que dans le stream processing on peut les d\xe9corr\xe9ler, et arriver \xe0 garantir l'integrity tout en ayant un fonctionnement asynchrone et donc ne garantissant pas la timeliness. Et le tout sans utiliser les transactions distribu\xe9es co\xfbteuses;","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Selon l'auteur, cette technique est particuli\xe8rement prometteuse."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut aussi se demander si toutes les applications ont vraiment besoin d'un respect intransigeant de la timeliness, et donc d'un respect de la linearizability (d\xe8s qu'une \xe9criture est faite, elle impacte les lecteurs) :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut tr\xe8s bien faire une ",(0,r.jsx)(n.strong,{children:"compensating transaction"})," dans le cas o\xf9 on a accept\xe9 une transaction c\xf4t\xe9 client mais qu'il se r\xe9v\xe8le qu'elle ne respecte pas les contraintes."]}),"\n",(0,r.jsx)(n.li,{children:"D'ailleurs un processus d'excuse et de compensation peut \xeatre pertinent dans de nombreux cas, par exemple pour la r\xe9servation, souvent on propose plus de places que disponibles en partant du principe qu'il y aura des d\xe9sistements. Et dans le cas o\xf9 on a mal pr\xe9vu, il faut pouvoir avoir un processus de compensation."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut cr\xe9er un syst\xe8me qui pour l'essentiel \xe9vite la coordination :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"1 - on pr\xe9serve l'int\xe9grit\xe9 des donn\xe9es dans les syst\xe8mes d\xe9riv\xe9s sans atomic commit, linearizability, ou coordination synchrone entre partitions."}),"\n",(0,r.jsx)(n.li,{children:"2 - la plupart des applications peuvent se passer de contraintes temporelles fortes pour la timeliness."}),"\n",(0,r.jsx)(n.li,{children:"Selon l'auteur, ce type de syst\xe8me sans coordination a beaucoup d'avantages. On peut tr\xe8s bien utiliser la coordination synchrone pour certaines op\xe9rations importantes qui ne permettent pas de retour en arri\xe8re, et garder le reste sans cette coordination."}),"\n",(0,r.jsx)(n.li,{children:"Finalement on peut voir la chose de cette mani\xe8re : avoir de fortes garanties synchrones du type transactions distribu\xe9es r\xe9duit le nombre d'excuses qu'il faudra faire pour les donn\xe9es inconsistantes pr\xe9sent\xe9es, mais ne pas les utiliser r\xe9duit le nombre d'excuses qu'il faudra faire pour toutes les indisponibilit\xe9s du syst\xe8me dues \xe0 la faible performance induite par la coordination."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Vis-\xe0-vis des erreurs mat\xe9rielles et logicielles :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il y a des corruptions probables contre lesquelles notre syst\xe8me model pr\xe9voit des parades, et des corruptions contre lesquelles non, comme par exemple faire confiance aux op\xe9rations du CPU. Pourtant tout peut arriver avec plus ou moins de probabilit\xe9."}),"\n",(0,r.jsx)(n.li,{children:"Il ne faut pas oublier non plus que les BDD ne sont que des logiciels qui peuvent avoir des bugs, et pour nos codes applicatifs c'est encore pire."}),"\n",(0,r.jsx)(n.li,{children:"La corruption des donn\xe9es finit par arriver qu'on le veuille ou non. Il faut une forme d'auto-auditabilit\xe9. Il faut v\xe9rifier r\xe9guli\xe8rement que nos donn\xe9es sont bien l\xe0 et int\xe8gres, de m\xeame que nos backups."}),"\n",(0,r.jsxs)(n.li,{children:["L'approche repr\xe9sent\xe9e par l'event sourcing permet d'auditer plus facilement les donn\xe9es.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Et si on a bien fait la s\xe9paration entre les donn\xe9es sources et d\xe9riv\xe9es c'est encore plus clair."}),"\n",(0,r.jsx)(n.li,{children:"On peut faire un checksum sur le log d'events pour le v\xe9rifier, et on peut rejouer les batchs pour recr\xe9er des donn\xe9es d\xe9riv\xe9es propres."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Une bonne pratique dans la v\xe9rification des donn\xe9es est de le faire sur des flows end-to-end. Cela permet d'inclure tout le hardware et le software dans ce qui est vraiment v\xe9rifi\xe9."}),"\n",(0,r.jsx)(n.li,{children:"Les techniques cryptographiques de v\xe9rification de l'int\xe9grit\xe9 introduites par la blockchain est un m\xe9canisme tr\xe8s int\xe9ressant pour l'avenir de l'int\xe9grit\xe9 des donn\xe9es."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}n.default=(0,i.j)({MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,t.a)(),e.components);return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(u,{...e})}):u(e)},pageOpts:{filePath:"pages/books/designing-data-intensive-applications.mdx",route:"/books/designing-data-intensive-applications",title:"Designing Data-Intensive Applications",headings:a},pageNextRoute:"/books/designing-data-intensive-applications"})},8397:function(e,n,s){"use strict";s.d(n,{U:function(){return i}});var r=s(5893);function i(e){let{children:n}=e;return(0,r.jsx)("em",{style:{color:"#3d85c6",fontWeight:"bold",fontStyle:"normal"},children:n})}}},function(e){e.O(0,[673,888,774,179],function(){return e(e.s=2869)}),_N_E=e.O()}]);